This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-02-04T20:06:32.854Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

================================================================
Directory Structure
================================================================
.github/
  actions/
    setup-project/
      action.yml
  workflows/
    npm.yml
    quality.yml
    test.yml
docs/
  design_decisions/
    auto-migrations.md
  CODE_OF_CONDUCT.md
  CONTRIBUTING.md
  RELEASE.md
examples/
  node-sequelize/
    config/
      HourlyPageViews.ts
      PageLoads.ts
      sequelize.js
      StockPrices.ts
    migrations/
      20250110064304-add-timescale-extension.js
      20250110064305-create-page-loads.js
      20250110064306-add-page-loads-hypertable.js
      20250110064307-add-continous-aggregate.js
      20250110064308-create-stock-prices.js
      20250110064309-create-stock-prices-hypertable.js
    src/
      models/
        HourlyPageView.ts
        PageLoad.ts
        StockPrice.ts
      routes/
        index.ts
      services/
        timescale.ts
      app.ts
      database.ts
      index.ts
      types.ts
    tests/
      candlestick.test.ts
      compression.test.ts
      hourly.test.ts
      integration.test.ts
      mock-request.ts
      page-view.test.ts
      setup.ts
      stats.test.ts
    .env.example
    .sequelizerc
    jest.config.js
    package.json
    README.md
    tsconfig.json
    tsconfig.test.json
  node-typeorm/
    migrations/
      1737173805840-create-page-loads.ts
      1738403699299-CreateStockPrice.ts
    src/
      models/
        HourlyPageViews.ts
        PageLoad.ts
        StockPrice.ts
      routes/
        index.ts
      app.ts
      data-source.ts
      index.ts
      types.ts
    tests/
      candlestick.test.ts
      compression.test.ts
      hourly.test.ts
      integration.test.ts
      mock-request.ts
      page-view.test.ts
      setup.ts
      stats.test.ts
    .env.example
    jest.config.js
    package.json
    README.md
    tsconfig.json
    tsconfig.test.json
packages/
  core/
    src/
      candlestick.ts
      compression.ts
      continuous-aggregate.ts
      errors.ts
      extension.ts
      hypertable.ts
      index.ts
      time-bucket.ts
    tests/
      __snapshots__/
        candlestick.test.ts.snap
        compression.test.ts.snap
        continuous-aggregate.test.ts.snap
        extension.test.ts.snap
        hypertable.test.ts.snap
        timebucket.test.ts.snap
      candlestick.test.ts
      compression.test.ts
      continuous-aggregate.test.ts
      extension.test.ts
      hypertable.test.ts
      timebucket.test.ts
    babel.config.js
    jest.config.js
    package.json
    README.md
    tsconfig.json
    tsconfig.test.json
  schemas/
    src/
      by-range.ts
      candlestick.ts
      compression.ts
      continuous-aggregate.ts
      extension.ts
      hypertable.ts
      index.ts
      time-bucket.ts
      time-range.ts
      where.ts
    package.json
    README.md
    tsconfig.json
  typeorm/
    src/
      decorators/
        AggregateColumn.ts
        BucketColumn.ts
        ContinuousAggregate.ts
        Hypertable.ts
      hooks/
        migration.ts
      repository/
        get-candlesticks.ts
        get-compression-stats.ts
        get-time-bucket.ts
        TimescaleRepository.ts
      index.ts
    babel.config.js
    jest.config.js
    package.json
    README.md
    tsconfig.json
    tsconfig.test.json
  utils/
    src/
      build-where.ts
      bump-versions.ts
      index.ts
      release.ts
      sql.ts
    tests/
      sql.test.ts
    babel.config.js
    jest.config.js
    package.json
    README.md
    tsconfig.json
    tsconfig.test.json
.eslintrc.js
.gitignore
.prettierignore
.prettierrc
LICENSE
package.json
pnpm-workspace.yaml
README.md

================================================================
Files
================================================================

================
File: .github/actions/setup-project/action.yml
================
name: Setup Project
description: 'Sets up the project by installing dependencies and building the project.'

inputs:
  pnpm-version:
    description: 'The version of pnpm to use for installing dependencies.'
    required: false
    default: 9.15.3
  node-version:
    description: 'The version of Node.js to use for building the project.'
    required: false
    default: '22.13.0'

runs:
  using: composite
  steps:
    - uses: pnpm/action-setup@v4
      with:
        version: ${{ inputs.pnpm-version }}
    - uses: actions/setup-node@v4
      with:
        node-version: ${{ inputs.node-version }}
        cache: 'pnpm'
    - name: Install dependencies
      run: pnpm install
      shell: bash
    - name: Build project
      run: pnpm build
      shell: bash

================
File: .github/workflows/npm.yml
================
name: Publish to npm

on:
  push:
    tags:
      - '*'

jobs:
  publish-npm:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/setup-project
      - run: pnpm config set //registry.npmjs.org/:_authToken ${NPM_TOKEN}
        env:
          NPM_TOKEN: ${{secrets.npm_token}}
      - run: START_PATH="." node ./packages/utils/dist/bump-versions.js
        env:
          VERSION: ${{github.ref_name}}
      - run: pnpm publish -r --filter '!@timescaledb/example-node-sequelize' --filter '!@timescaledb/example-node-typeorm' --filter '!@timescaledb/monorepo' --no-git-checks

================
File: .github/workflows/quality.yml
================
name: Qualty Checks
on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  quality-checks:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/setup-project
      - name: Lint
        run: pnpm lint
      - name: Format Check
        run: pnpm format:check

================
File: .github/workflows/test.yml
================
name: Tests

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest

    services:
      timescaledb:
        image: timescale/timescaledb-ha:pg17
        env:
          POSTGRES_PASSWORD: password
          POSTGRES_USER: postgres
          POSTGRES_DB: postgres
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - uses: actions/checkout@v4

      - uses: ./.github/actions/setup-project

      - name: Install PostgreSQL client
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client

      - name: Wait for TimescaleDB
        run: |
          timeout=30
          counter=0
          until PGPASSWORD=password psql -h localhost -U postgres -c '\dx' postgres | grep timescaledb; do
            counter=$((counter + 1))
            if [ $counter -gt $timeout ]; then
              echo "Timeout waiting for TimescaleDB"
              exit 1
            fi
            echo "Waiting for TimescaleDB... ($counter/$timeout)"
            sleep 1
          done

      - name: Create Databases
        run: |
          PGPASSWORD=password psql -h localhost -U postgres -c 'CREATE DATABASE sequelize;' postgres
          PGPASSWORD=password psql -h localhost -U postgres -c 'CREATE DATABASE typeorm;' postgres

      - name: Run Core Package Tests
        run: pnpm run --filter @timescaledb/core test

      - name: Run Sequelize Migration
        env:
          DATABASE_URL: postgres://postgres:password@localhost:5432/sequelize
        run: pnpm run --filter @timescaledb/example-node-sequelize migrate

      - name: Run TypeORM Migration
        env:
          DATABASE_URL: postgres://postgres:password@localhost:5432/typeorm
        run: pnpm run --filter @timescaledb/example-node-typeorm migrate

      - name: Run Sequelize Tests
        env:
          DATABASE_URL: postgres://postgres:password@localhost:5432/sequelize
        run: pnpm run --filter @timescaledb/example-node-sequelize test

      - name: Run TypeORM Tests
        env:
          DATABASE_URL: postgres://postgres:password@localhost:5432/typeorm
        run: pnpm run --filter @timescaledb/example-node-typeorm test

================
File: docs/design_decisions/auto-migrations.md
================
# Design Decision: Auto Migrations

- [`@timescaledb/typeorm`](../../packages/typeorm/README.md)

The TypeORM integration for TimescaleDB will automatically generate the necessary SQL for TimescaleDB. This means that the user will not have to worry about the TimescaleDB SQL at all, and just work with the TypeORM entities.

## Context

Our goal is to make this library as easy to integrate into TypeORM as possible. This means that we should make sure that the migrations are as easy to use as possible or non-existent from the user's perspective.

### Assumptions

1. Users are familiar with TypeORM's entity and decorator patterns but may not be familiar with TimescaleDB

2. Schema changes to hypertables happen infrequently after initial creation

3. Most users want a simple declarative way to work with TimescaleDB features

4. Migration automation is more valuable than having fine-grained control over TimescaleDB SQL

5. Users prefer working with TypeScript classes and decorators over writing raw SQL

6. When schema changes are needed, users can handle them manually using the builder API

## Decision

**The Timescale SQL is hidden from the user.** You won't see generated Timescale SQL in the migrations. Instead, it will be generated and pushed on the fly. For example:

```typescript
@Entity('page_loads')
@Hypertable({
  by_range: { column_name: 'time' },
  compression: {
    compress: true,
    compress_orderby: 'time',
  },
})
export class PageLoad {
  @PrimaryColumn({ type: 'timestamp' })
  time!: Date;
}
```

The above entity will automatically generate and execute the necessary TimescaleDB SQL during migrations:

```sql
SELECT create_hypertable('page_loads', by_range('time'));
ALTER TABLE "page_loads" SET (timescaledb.compress, timescaledb.compress_orderby = "time");
```

## Limitations

### Versioning

Schema changes are not versioned. This means that if you change the schema, you will have to manually update the database. This is a limitation of the TypeORM integration, but can be worked around using the builder manually.

## Benefits

### Control over the SQL

We can control and update the SQL generation without requiring user changes. For example, when creating hypertables:

```typescript
// Internal SQL generation can be updated
const sql = hypertable.up().build();
await dataSource.query(sql);
```

### Push newer versions of the SQL on the fly

SQL updates can be pushed without user intervention, allowing seamless updates to TimescaleDB features.

### No knowledge needed of TimescaleDB SQL

Users can work purely with TypeORM entities and decorators without understanding the underlying TimescaleDB SQL.

## Workarounds

### Use the builder manually

For more control, you can use the SQL builder directly:

```typescript
const hypertable = TimescaleDB.createHypertable('my_table', {
  by_range: { column_name: 'time' },
});
const sql = hypertable.up().build();
await queryRunner.query(sql);
```

See the [core tests](https://github.com/timescale/timescaledb-ts/tree/main/packages/core/tests) for more builder examples.

================
File: docs/CODE_OF_CONDUCT.md
================
# Contributor Covenant Code of Conduct

## Our Pledge

In the interest of fostering an open and welcoming environment, we as
contributors and maintainers pledge to making participation in our project and
our community a harassment-free experience for everyone, regardless of age, body
size, disability, ethnicity, gender identity and expression, level of experience,
nationality, personal appearance, race, religion, or sexual identity and
orientation.

## Our Standards

Examples of behavior that contributes to creating a positive environment
include:

- Using welcoming and inclusive language
- Being respectful of differing viewpoints and experiences
- Gracefully accepting constructive criticism
- Focusing on what is best for the community
- Showing empathy towards other community members

Examples of unacceptable behavior by participants include:

- The use of sexualized language or imagery and unwelcome sexual attention or
  advances
- Trolling, insulting/derogatory comments, and personal or political attacks
- Public or private harassment
- Publishing others' private information, such as a physical or electronic
  address, without explicit permission
- Other conduct which could reasonably be considered inappropriate in a
  professional setting

## Our Responsibilities

Project maintainers are responsible for clarifying the standards of acceptable
behavior and are expected to take appropriate and fair corrective action in
response to any instances of unacceptable behavior.

Project maintainers have the right and responsibility to remove, edit, or
reject comments, commits, code, wiki edits, issues, and other contributions
that are not aligned to this Code of Conduct, or to ban temporarily or
permanently any contributor for other behaviors that they deem inappropriate,
threatening, offensive, or harmful.

## Scope

This Code of Conduct applies both within project spaces and in public spaces
when an individual is representing the project or its community. Examples of
representing a project or community include using an official project e-mail
address, posting via an official social media account, or acting as an appointed
representative at an online or offline event. Representation of a project may be
further defined and clarified by project maintainers.

## Enforcement

Instances of abusive, harassing, or otherwise unacceptable behavior may be
reported by contacting the project team at jonatasdp@gmail.com. All
complaints will be reviewed and investigated and will result in a response that
is deemed necessary and appropriate to the circumstances. The project team is
obligated to maintain confidentiality with regard to the reporter of an incident.
Further details of specific enforcement policies may be posted separately.

Project maintainers who do not follow or enforce the Code of Conduct in good
faith may face temporary or permanent repercussions as determined by other
members of the project's leadership.

## Attribution

This Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4,
available at [https://contributor-covenant.org/version/1/4][version]

[homepage]: https://contributor-covenant.org
[version]: https://contributor-covenant.org/version/1/4/

================
File: docs/CONTRIBUTING.md
================
# Contribute to timescaledb-ts

This is a Typescript source monorepo managed by pnpm. To get started you will need the following installed:

- [Node.js >= 22.13.0](https://nodejs.org/en/)
- [pnpm >= 9.15.3](https://pnpm.io/installation)

Once you have cloned the repo, you can use `pnpm <command>` to manage the monorepo. The following commands you should get familiar with:

- `pnpm install` - Install all dependencies
- `pnpm build` - Build all packages
- `pnpm test` - Test all packages
- `pnpm lint` - Lint all packages
- `pnpm format` - Format all packages
- `pnpm clean` - Factory reset the monorepo(debugging purposes)

## Release

Checkout the [RELEASE.md](./RELEASE.md) file for information on how to release a new version of the packages.

================
File: docs/RELEASE.md
================
# Releasing timescaledb-ts

The `timescaledb-ts` project is a monorepo that contains multiple packages. Each package is published to npm separately. The packages are versioned together and are released together.

## Rules

- Dont publish a package from your local machine.
- Never change a version of a package manually.
- Dont change the `"workspace:^"` version in a `package.json` file.
- All packages should have the same version.
- Check the changes before pushing them to GitHub.
- Manually check the deployed packages on npm after the release.

## Releasing a new version

To release a new version of the packages make sure that you are on the `main` branch and that you have the latest changes. Then, you can bump all the packages to the new version:

```bash
$ VERSION=__VERSION__ START_PATH=. pnpm run release
```

This will change all the packages to the given version and will create a commit and tag with the changes.

> Note that the release command will not modify the monorepo `"workspace:^"` version in the `package.json` files. It will only change the version of the packages. **Changes to the workspace settings are done in the pipelines and are not part of this release.**

After the release command is finished, it is wize to check the changes and make sure that everything is as expected.

You can do that by running:

```bash
$ git log --name-status HEAD^..HEAD

(HEAD -> main, tag: 0.0.0-alpha.53)

M       packages/core
M       packages/schemas
M       packages/utils
M       ...
(END)
```

This will output the contents of the last commit. Make sure that the changes are as expected(only package versions should be changed).

Then, make sure that the tag is created:

```bash
$ git tag

0.0.0-alpha.38
0.0.0-alpha.39
0.0.0-alpha.4
0.0.0-alpha.40
0.0.0-alpha.41
0.0.0-alpha.42
0.0.0-alpha.43
0.0.0-alpha.44
0.0.0-alpha.45
0.0.0-alpha.46
0.0.0-alpha.47
0.0.0-alpha.48
0.0.0-alpha.53 <--- This is the new tag
```

Finally, push the changes to GitHub:

```bash
$ git push && git push --tags
```

This will trigger a release pipeline on GitHub Actions that will publish the packages to npm.

From here you should create a write-up of the changes in a new Github release associated with the tag you just created.

================
File: examples/node-sequelize/config/HourlyPageViews.ts
================
import { TimescaleDB } from '@timescaledb/core';
import { AggregateType } from '@timescaledb/schemas';

export const HourlyPageViews = TimescaleDB.createContinuousAggregate('hourly_page_views', 'page_loads', {
  bucket_interval: '1 hour',
  time_column: 'time',
  aggregates: {
    total_views: {
      type: AggregateType.Count,
      column_alias: 'total_views',
    },
    unique_users: {
      type: AggregateType.CountDistinct,
      column: 'user_agent',
      column_alias: 'unique_users',
    },
  },
  refresh_policy: {
    start_offset: '3 days',
    end_offset: '1 hour',
    schedule_interval: '1 hour',
  },
});

================
File: examples/node-sequelize/config/PageLoads.ts
================
import { TimescaleDB } from '@timescaledb/core';

export const PageLoads = TimescaleDB.createHypertable('page_loads', {
  by_range: {
    column_name: 'time',
  },
  compression: {
    compress: true,
    compress_orderby: 'time',
    compress_segmentby: 'user_agent',
    policy: {
      schedule_interval: '7 days',
    },
  },
});

================
File: examples/node-sequelize/config/sequelize.js
================
// eslint-disable-next-line @typescript-eslint/no-require-imports
require('dotenv').config();

module.exports = {
  development: {
    url: process.env.DATABASE_URL,
    dialect: 'postgres',
    dialectOptions: {
      ssl: false,
    },
    define: {
      underscored: true,
    },
    logging: console.log,
  },
  test: {
    url: process.env.DATABASE_URL,
    dialect: 'postgres',
    dialectOptions: {
      ssl: false,
    },
    define: {
      underscored: true,
    },
    logging: false,
  },
  migrationStorageTableName: 'sequelize_migrations', // Table to store migration history
  seederStorageTableName: 'sequelize_seeds', // Table to store seeder history
};

================
File: examples/node-sequelize/config/StockPrices.ts
================
import { TimescaleDB } from '@timescaledb/core';

export const StockPrices = TimescaleDB.createHypertable('stock_prices', {
  by_range: {
    column_name: 'timestamp',
  },
  compression: {
    compress: true,
    compress_orderby: 'timestamp',
    compress_segmentby: 'symbol',
    policy: {
      schedule_interval: '7 days',
    },
  },
});

================
File: examples/node-sequelize/migrations/20250110064304-add-timescale-extension.js
================
'use strict';

const { TimescaleDB } = require('@timescaledb/core');

const extension = TimescaleDB.createExtension();

/** @type {import('sequelize-cli').Migration} */
module.exports = {
  async up(queryInterface) {
    const sql = extension.up().build();

    await queryInterface.sequelize.query(sql);
  },

  async down(queryInterface) {
    const sql = extension.down().build();

    await queryInterface.sequelize.query(sql);
  },
};

================
File: examples/node-sequelize/migrations/20250110064305-create-page-loads.js
================
'use strict';

// eslint-disable-next-line @typescript-eslint/no-require-imports
const { DataTypes } = require('sequelize');

/** @type {import('sequelize-cli').Migration} */
module.exports = {
  async up(queryInterface) {
    await queryInterface.createTable('page_loads', {
      user_agent: {
        type: DataTypes.TEXT,
        primaryKey: true,
        allowNull: false,
      },
      time: {
        type: DataTypes.DATE,
        primaryKey: true,
        allowNull: false,
      },
    });
  },

  async down(queryInterface) {
    await queryInterface.dropTable('page_loads');
  },
};

================
File: examples/node-sequelize/migrations/20250110064306-add-page-loads-hypertable.js
================
'use strict';

const path = require('path');
const { PageLoads } = require(path.join(__dirname, '../dist/config/PageLoads'));

/** @type {import('sequelize-cli').Migration} */
module.exports = {
  async up(queryInterface) {
    const sql = PageLoads.up().build();

    await queryInterface.sequelize.query(sql);
  },

  async down(queryInterface) {
    const sql = PageLoads.down().build();

    await queryInterface.sequelize.query(sql);
  },
};

================
File: examples/node-sequelize/migrations/20250110064307-add-continous-aggregate.js
================
'use strict';

const path = require('path');
const { HourlyPageViews } = require(path.join(__dirname, '../dist/config/HourlyPageViews'));

/** @type {import('sequelize-cli').Migration} */
module.exports = {
  async up(queryInterface) {
    const sql = HourlyPageViews.up().build();

    await queryInterface.sequelize.query(sql);
  },

  async down(queryInterface) {
    const statements = HourlyPageViews.down().build();

    for await (const statment of statements) {
      await queryInterface.sequelize.query(statment);
    }
  },
};

================
File: examples/node-sequelize/migrations/20250110064308-create-stock-prices.js
================
'use strict';

const { DataTypes } = require('sequelize');

/** @type {import('sequelize-cli').Migration} */
module.exports = {
  async up(queryInterface) {
    await queryInterface.createTable('stock_prices', {
      symbol: {
        type: DataTypes.STRING,
        primaryKey: true,
        allowNull: false,
      },
      timestamp: {
        type: DataTypes.DATE,
        primaryKey: true,
        allowNull: false,
      },
      price: {
        type: DataTypes.DECIMAL(10, 2),
        allowNull: false,
      },
      volume: {
        type: DataTypes.DECIMAL(10, 2),
        allowNull: false,
      },
    });
  },

  async down(queryInterface) {
    await queryInterface.dropTable('stock_prices');
  },
};

================
File: examples/node-sequelize/migrations/20250110064309-create-stock-prices-hypertable.js
================
'use strict';

const path = require('path');
const { StockPrices } = require(path.join(__dirname, '../dist/config/StockPrices'));

/** @type {import('sequelize-cli').Migration} */
module.exports = {
  async up(queryInterface) {
    const sql = StockPrices.up().build();
    await queryInterface.sequelize.query(sql);
  },

  async down(queryInterface) {
    const sql = StockPrices.down().build();
    await queryInterface.sequelize.query(sql);
  },
};

================
File: examples/node-sequelize/src/models/HourlyPageView.ts
================
import { Model, DataTypes } from 'sequelize';
import sequelize from '../database';

class HourlyPageView extends Model {
  public bucket!: Date;
  public totalViews!: number;
  public uniqueUsers!: number;
}

HourlyPageView.init(
  {
    bucket: {
      type: DataTypes.DATE,
      primaryKey: true,
    },
    totalViews: {
      type: DataTypes.INTEGER,
      field: 'total_views',
    },
    uniqueUsers: {
      type: DataTypes.INTEGER,
      field: 'unique_users',
    },
  },
  {
    sequelize,
    tableName: 'hourly_page_views',
    timestamps: false,
    underscored: true,
  },
);

export default HourlyPageView;

================
File: examples/node-sequelize/src/models/PageLoad.ts
================
import { Model, DataTypes } from 'sequelize';
import sequelize from '../database';

class PageLoad extends Model {
  public userAgent!: string;
  public time!: Date;
}

PageLoad.init(
  {
    userAgent: {
      type: DataTypes.TEXT,
      primaryKey: true,
      field: 'user_agent',
    },
    time: {
      type: DataTypes.DATE,
      primaryKey: true,
    },
  },
  {
    sequelize,
    tableName: 'page_loads',
    timestamps: false,
    underscored: true,
  },
);

export default PageLoad;

================
File: examples/node-sequelize/src/models/StockPrice.ts
================
import { Model, DataTypes } from 'sequelize';
import sequelize from '../database';

class StockPrice extends Model {
  public symbol!: string;
  public timestamp!: Date;
  public price!: number;
  public volume!: number;
}

StockPrice.init(
  {
    symbol: {
      type: DataTypes.STRING,
      primaryKey: true,
    },
    timestamp: {
      type: DataTypes.DATE,
      primaryKey: true,
    },
    price: {
      type: DataTypes.DECIMAL(10, 2),
    },
    volume: {
      type: DataTypes.DECIMAL(10, 2),
    },
  },
  {
    sequelize,
    tableName: 'stock_prices',
    timestamps: false,
    underscored: true,
  },
);

export default StockPrice;

================
File: examples/node-sequelize/src/routes/index.ts
================
import { Router } from 'express';
import PageLoad from '../models/PageLoad';
import { getPageViewStats, getCompressionStats, getCandlestickData } from '../services/timescale';
import HourlyPageView from '../models/HourlyPageView';
import { Op } from 'sequelize';
import { WhereClauseSchema } from '@timescaledb/schemas';

const router = Router();

router.post('/pageview', async (req, res) => {
  try {
    const userAgent = req.get('user-agent') || 'unknown';
    const time = new Date();

    await PageLoad.create({ userAgent, time });
    res.json({ message: 'Page view recorded' });
  } catch (error) {
    console.error(error);
    res.status(500).json({ error: 'Failed to record page view' });
  }
});

router.get('/stats', async (req, res) => {
  try {
    const start = new Date(req.query.start as string);
    const end = new Date(req.query.end as string);
    const where = req.query.where as string;
    const whereClause = where ? WhereClauseSchema.parse(JSON.parse(where)) : undefined;

    const stats = await getPageViewStats({
      where: whereClause,
      range: {
        start,
        end,
      },
    });
    res.json(stats);
  } catch (error) {
    console.error(error);
    res.status(500).json({ error: 'Failed to get stats' });
  }
});

router.get('/compression', async (req, res) => {
  try {
    const stats = await getCompressionStats();
    res.json(stats);
  } catch (error) {
    console.error(error);
    res.status(500).json({ error: 'Failed to get compression stats' });
  }
});

router.get('/hourly', async (req, res) => {
  try {
    const start = new Date(req.query.start as string);
    const end = new Date(req.query.end as string);

    const hourlyViews = await HourlyPageView.findAll({
      where: {
        bucket: {
          [Op.between]: [start, end],
        },
      },
      order: [['bucket', 'DESC']],
    });

    res.json(hourlyViews);
  } catch (error) {
    console.error(error);
    res.status(500).json({ error: 'Failed to get hourly stats' });
  }
});

router.get('/candlestick', async (req, res) => {
  try {
    const start = new Date(req.query.start as string);
    const end = new Date(req.query.end as string);
    const interval = req.query.interval as string;

    const where = req.query.where as string;
    const whereClause = where ? WhereClauseSchema.parse(JSON.parse(where)) : undefined;

    const candlesticks = await getCandlestickData({ start, end, interval, where: whereClause });

    res.json(candlesticks);
  } catch (error) {
    console.error(error);
    res.status(500).json({ error: 'Failed to get candlestick data' });
  }
});

export default router;

================
File: examples/node-sequelize/src/services/timescale.ts
================
import sequelize from '../database';
import { PageViewStats } from '../types';
import { CompressionStats, TimeRange, WhereClause } from '@timescaledb/schemas';
import { PageLoads } from '../../config/PageLoads';
import { QueryTypes } from 'sequelize';
import { TimescaleDB } from '@timescaledb/core';

export async function getPageViewStats({
  range,
  where,
}: {
  range: TimeRange;
  where?: WhereClause;
}): Promise<PageViewStats[]> {
  const { sql, params } = PageLoads.timeBucket({
    interval: '1 hour',
    metrics: [
      { type: 'count', alias: 'count' },
      { type: 'distinct_count', column: 'user_agent', alias: 'unique_users' },
    ],
  }).build({
    range,
    where,
  });

  const results = await sequelize.query(sql, {
    bind: params,
    type: QueryTypes.SELECT,
  });

  return results as PageViewStats[];
}

export async function getCompressionStats(): Promise<CompressionStats> {
  try {
    const sql = PageLoads.compression()
      .stats({
        select: {
          total_chunks: true,
          compressed_chunks: true,
        },
      })
      .build();

    const [stats] = (await sequelize.query(sql, {
      type: QueryTypes.SELECT,
    })) as [CompressionStats];

    return {
      compressed_chunks: Number(stats?.compressed_chunks || 0),
      total_chunks: Number(stats?.total_chunks || 0),
    };
  } catch (error) {
    console.error('Error getting compression stats:', error);
    return {
      compressed_chunks: 0,
      total_chunks: 0,
    };
  }
}

export async function getCandlestickData({
  start,
  end,
  interval = '1 hour',
  where,
}: {
  start: Date;
  end: Date;
  interval?: string;
  where?: WhereClause;
}) {
  const candlestick = TimescaleDB.createCandlestickAggregate('stock_prices', {
    time_column: 'timestamp',
    price_column: 'price',
    volume_column: 'volume',
    bucket_interval: interval,
  });

  const { sql, params } = candlestick.build({
    range: { start, end },
    where,
  });

  const results = await sequelize.query(sql, {
    type: QueryTypes.SELECT,
    bind: params,
  });

  return results.map((row: any) => ({
    bucket_time: new Date(row.bucket_time),
    open: Number(row.open),
    high: Number(row.high),
    low: Number(row.low),
    close: Number(row.close),
    volume: Number(row.volume),
    vwap: Number(row.vwap),
    open_time: new Date(row.open_time),
    high_time: new Date(row.high_time),
    low_time: new Date(row.low_time),
    close_time: new Date(row.close_time),
  }));
}

================
File: examples/node-sequelize/src/app.ts
================
import express from 'express';
import dotenv from 'dotenv';
import routes from './routes';

dotenv.config();

export const app = express();
export const port = process.env.PORT as string;

app.use(express.json());
app.use('/api', routes);

================
File: examples/node-sequelize/src/database.ts
================
import { Sequelize } from 'sequelize';
import dotenv from 'dotenv';

dotenv.config();

const sequelize = new Sequelize(process.env.DATABASE_URL as string, {
  dialect: 'postgres',
  logging: false,
  dialectOptions: {
    ssl: false,
  },
});

export async function initializeDatabase() {
  try {
    await sequelize.authenticate();
    console.log('Connection to database has been established successfully.');
    return sequelize;
  } catch (error) {
    console.error('Unable to connect to the database:', error);
    throw error;
  }
}

export default sequelize;

================
File: examples/node-sequelize/src/index.ts
================
import dotenv from 'dotenv';
import { initializeDatabase } from './database';
import { app, port } from './app';

dotenv.config();

async function bootstrap() {
  try {
    await initializeDatabase();

    app.listen(port, () => {
      console.info(`Server is running at http://localhost:${port}`);
    });
  } catch (error) {
    console.error('Failed to initialize application', error);
    process.exit(1);
  }
}

bootstrap().catch((error) => {
  console.error('Unhandled error during startup', error);
  process.exit(1);
});

================
File: examples/node-sequelize/src/types.ts
================
export interface PageViewStats {
  interval: string;
  count: number;
  unique_users: number;
}

================
File: examples/node-sequelize/tests/candlestick.test.ts
================
import { describe, it, expect, beforeEach, afterAll } from '@jest/globals';
import { request } from './mock-request';
import sequelize from '../src/database';
import StockPrice from '../src/models/StockPrice';

describe('GET /api/candlestick', () => {
  beforeEach(async () => {
    await StockPrice.destroy({ where: {} });
  });

  afterAll(async () => {
    await sequelize.close();
  });

  it('should return candlestick data for a given time range', async () => {
    const baseTime = new Date('2025-01-01T00:00:00Z');
    const symbol = 'BTC';
    const otherSymbol = 'OTHER';

    const testData = [
      { symbol, timestamp: new Date(baseTime.getTime() + 5 * 60000), price: 102000, volume: 1.5 }, // Opening price
      { symbol, timestamp: new Date(baseTime.getTime() + 15 * 60000), price: 104000, volume: 2.0 }, // High
      { symbol, timestamp: new Date(baseTime.getTime() + 25 * 60000), price: 101500, volume: 1.0 }, // Low
      { symbol, timestamp: new Date(baseTime.getTime() + 55 * 60000), price: 103500, volume: 1.8 }, // Close

      { symbol, timestamp: new Date(baseTime.getTime() + 65 * 60000), price: 103600, volume: 1.2 },
      { symbol, timestamp: new Date(baseTime.getTime() + 75 * 60000), price: 105000, volume: 2.5 },
      { symbol, timestamp: new Date(baseTime.getTime() + 85 * 60000), price: 104000, volume: 1.7 },
      { symbol, timestamp: new Date(baseTime.getTime() + 115 * 60000), price: 104500, volume: 1.9 },

      { symbol: otherSymbol, timestamp: new Date(baseTime.getTime() + 125 * 60000), price: 420, volume: 1.2 },
    ];

    await Promise.all(testData.map((data) => StockPrice.create(data)));

    const start = baseTime;
    const end = new Date(baseTime.getTime() + 3 * 3600000); // 3 hours later

    const response = await request()
      .get('/api/candlestick')
      .query({
        start: start.toISOString(),
        end: end.toISOString(),
        interval: '1 hour',
        where: JSON.stringify({ symbol }),
      });

    expect(response.status).toBe(200);
    expect(response.body).toHaveLength(2);

    const firstCandle = response.body[0];
    expect(firstCandle).toHaveProperty('bucket_time');
    expect(firstCandle).toHaveProperty('open');
    expect(firstCandle).toHaveProperty('high');
    expect(firstCandle).toHaveProperty('low');
    expect(firstCandle).toHaveProperty('close');
    expect(firstCandle).toHaveProperty('volume');
    expect(firstCandle).toHaveProperty('vwap');

    // Verify first candlestick values
    expect(Number(firstCandle.open)).toBe(102000);
    expect(Number(firstCandle.high)).toBe(104000);
    expect(Number(firstCandle.low)).toBe(101500);
    expect(Number(firstCandle.close)).toBe(103500);
    expect(Number(firstCandle.volume)).toBeCloseTo(6.3, 1);

    // Verify second candlestick values
    const secondCandle = response.body[1];
    expect(Number(secondCandle.open)).toBe(103600);
    expect(Number(secondCandle.high)).toBe(105000);
    expect(Number(secondCandle.low)).toBe(103600);
    expect(Number(secondCandle.close)).toBe(104500);
    expect(Number(secondCandle.volume)).toBeCloseTo(7.3, 1);
  });
});

================
File: examples/node-sequelize/tests/compression.test.ts
================
import { describe, it, expect, beforeEach, afterAll } from '@jest/globals';
import { request } from './mock-request';
import sequelize from '../src/database';
import PageLoad from '../src/models/PageLoad';
import { faker } from '@faker-js/faker';
import { QueryTypes } from 'sequelize';
import { CompressionStats } from '@timescaledb/schemas';

describe('GET /api/compression', () => {
  beforeEach(async () => {
    await PageLoad.destroy({ where: {} });
  });

  afterAll(async () => {
    await sequelize.close();
  });

  it('should show accurate compression stats after data insertion', async () => {
    const userAgents = Array.from({ length: 1000 }, () => faker.internet.userAgent());
    const startTime = new Date(Date.now() - 8 * 24 * 60 * 60 * 1000); // 8 days ago

    for (const userAgent of userAgents) {
      await PageLoad.create({
        userAgent,
        time: new Date(startTime.getTime() + Math.random() * 7 * 24 * 60 * 60 * 1000), // Within the last 7 days
      });
    }

    await new Promise((resolve) => setTimeout(resolve, 2000));

    const response = await request().get('/api/compression');
    expect(response.status).toBe(200);

    expect(response.body).toEqual({
      total_chunks: expect.any(Number),
      compressed_chunks: expect.any(Number),
    });

    expect(response.body.total_chunks).toBeGreaterThan(0);
    expect(response.body.compressed_chunks).toBeGreaterThanOrEqual(0);

    const dbStats = (
      await sequelize.query(
        `
          SELECT * FROM hypertable_compression_stats('page_loads');
        `,
        {
          type: QueryTypes.SELECT,
        },
      )
    )[0] as unknown as CompressionStats;

    expect(response.body).toEqual(
      expect.objectContaining({
        total_chunks: Number(dbStats.total_chunks),
        compressed_chunks: Number(dbStats.number_compressed_chunks),
      }),
    );
  });
});

================
File: examples/node-sequelize/tests/hourly.test.ts
================
import { describe, it, expect, beforeEach, afterAll } from '@jest/globals';
import { request } from './mock-request';
import sequelize from '../src/database';
import PageLoad from '../src/models/PageLoad';
import { faker } from '@faker-js/faker';

describe('GET /api/hourly', () => {
  beforeEach(async () => {
    await PageLoad.destroy({ where: {} });
  });

  afterAll(async () => {
    await sequelize.close();
  });

  it('should return hourly stats for a given time range', async () => {
    const baseTime = new Date();
    baseTime.setMinutes(0, 0, 0);

    // Create test data across 3 hours
    for (let hour = 0; hour < 3; hour++) {
      const time = new Date(baseTime.getTime() - hour * 3600000);

      // Create multiple records per hour
      for (let i = 0; i < 5; i++) {
        await PageLoad.create({
          userAgent: faker.internet.userAgent(),
          time: new Date(time.getTime() + i * 60000), // Spread over minutes
        });
      }
    }

    // Manually refresh the continuous aggregate
    await sequelize.query(`CALL refresh_continuous_aggregate('hourly_page_views', null, null);`);

    // Wait for refresh to complete
    await new Promise((resolve) => setTimeout(resolve, 3000));

    const start = new Date(baseTime.getTime() - 4 * 3600000); // 4 hours ago
    const end = baseTime;

    const response = await request().get('/api/hourly').query({
      start: start.toISOString(),
      end: end.toISOString(),
    });

    expect(response.status).toBe(200);
    expect(response.body).toHaveLength(3);

    const firstHour = response.body[0];
    expect(firstHour).toHaveProperty('bucket');
    expect(firstHour).toHaveProperty('totalViews');
    expect(firstHour).toHaveProperty('uniqueUsers');

    response.body.forEach((hour: any) => {
      expect(Number(hour.totalViews)).toBe(5); // 5 views per hour
      expect(Number(hour.uniqueUsers)).toBe(5); // 5 unique users per hour
    });
  });
});

================
File: examples/node-sequelize/tests/integration.test.ts
================
import { describe, it, expect, beforeEach, afterAll } from '@jest/globals';
import { request } from './mock-request';
import sequelize from '../src/database';
import { faker } from '@faker-js/faker';
import PageLoad from '../src/models/PageLoad';

describe('API Integration Tests', () => {
  beforeEach(async () => {
    await PageLoad.destroy({ where: {} });
  });

  afterAll(async () => {
    await sequelize.close();
  });

  it('should record page view and reflect in stats', async () => {
    const baseTime = new Date();
    baseTime.setMinutes(30, 0, 0); // Set to XX:30:00
    const userAgent = faker.internet.userAgent();

    const viewResponse = await request().post('/api/pageview').set('User-Agent', userAgent);
    expect(viewResponse.status).toBe(200);

    // Poll for the record to appear in the database
    const maxAttempts = 5;
    const pollInterval = 1000; // 1 second
    let pageLoadRecord: PageLoad | null = null;

    for (let attempt = 0; attempt < maxAttempts; attempt++) {
      await new Promise((resolve) => setTimeout(resolve, pollInterval));

      pageLoadRecord = await PageLoad.findOne({
        where: { userAgent },
      });

      if (pageLoadRecord) {
        break;
      }
    }

    expect(pageLoadRecord).not.toBeNull();
    expect(pageLoadRecord?.userAgent).toBe(userAgent);

    const startTime = new Date(baseTime.getTime() - 3600000); // 1 hour ago
    const endTime = new Date(baseTime.getTime() + 3600000); // 1 hour ahead

    const statsResponse = await request().get('/api/stats').query({
      start: startTime.toISOString(),
      end: endTime.toISOString(),
    });

    expect(statsResponse.status).toBe(200);
    expect(statsResponse.body).toHaveLength(1);

    const stats = statsResponse.body[0];
    expect(Number(stats.count)).toBeGreaterThanOrEqual(1);
    expect(Number(stats.unique_users)).toBeGreaterThanOrEqual(1);
    expect(stats.interval).toBeTruthy();

    const dbRecord = await PageLoad.findOne({
      where: { userAgent },
    });
    expect(dbRecord).not.toBeNull();
  });
});

================
File: examples/node-sequelize/tests/mock-request.ts
================
import supertest from 'supertest';
import { app } from '../src/app';

export const request = () => {
  return supertest(app);
};

================
File: examples/node-sequelize/tests/page-view.test.ts
================
import { describe, it, expect, beforeEach, afterAll } from '@jest/globals';
import { request } from './mock-request';
import PageLoad from '../src/models/PageLoad';
import sequelize from '../src/database';

describe('POST /api/pageview', () => {
  beforeEach(async () => {
    await PageLoad.destroy({ where: {} });
  });

  afterAll(async () => {
    await sequelize.close();
  });

  it('should record a page view and verify database record', async () => {
    const mockUserAgent = 'Mozilla/5.0 Test Browser';
    const beforeInsert = new Date();

    const response = await request().post('/api/pageview').set('User-Agent', mockUserAgent);

    const afterInsert = new Date();

    expect(response.status).toBe(200);
    expect(response.body).toEqual({ message: 'Page view recorded' });

    const record = await PageLoad.findOne({
      where: { userAgent: mockUserAgent },
    });

    expect(record).not.toBeNull();
    expect(record?.userAgent).toBe(mockUserAgent);
    expect(record?.time.getTime()).toBeGreaterThanOrEqual(beforeInsert.getTime());
    expect(record?.time.getTime()).toBeLessThanOrEqual(afterInsert.getTime());
  });
});

================
File: examples/node-sequelize/tests/setup.ts
================
import { beforeAll, afterAll } from '@jest/globals';
import dotenv from 'dotenv';
import sequelize from '../src/database';

dotenv.config({ path: '.env' });

process.env.NODE_ENV = 'test';
process.env.PORT = '4000';

beforeAll(async () => {
  try {
    await sequelize.authenticate();

    const [results] = await sequelize.query("SELECT EXISTS(SELECT 1 FROM pg_extension WHERE extname = 'timescaledb')");

    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    const hasTimescaleDB = (results[0] as unknown as any).exists;
    if (!hasTimescaleDB) {
      throw new Error('TimescaleDB extension is not enabled in the database');
    }
  } catch (error) {
    console.error('Test setup failed:', error);
    throw error;
  }
});

afterAll(async () => {
  await sequelize.close();
});

================
File: examples/node-sequelize/tests/stats.test.ts
================
import { describe, it, expect, beforeEach, afterAll } from '@jest/globals';
import { request } from './mock-request';
import PageLoad from '../src/models/PageLoad';
import sequelize from '../src/database';

describe('GET /api/stats', () => {
  beforeEach(async () => {
    await PageLoad.destroy({ where: {} });
  });

  afterAll(async () => {
    await sequelize.close();
  });

  it('should return accurate stats for a given time range', async () => {
    const baseTime = new Date();
    baseTime.setMinutes(30, 0, 0); // Set to XX:30:00

    const testData = [
      { userAgent: 'UA1', time: new Date(baseTime.getTime() - 10 * 60000) }, // XX:20:00
      { userAgent: 'UA2', time: new Date(baseTime.getTime() - 15 * 60000) }, // XX:15:00
      { userAgent: 'UA1', time: new Date(baseTime.getTime() - 20 * 60000) }, // XX:10:00
    ];

    await Promise.all(testData.map((data) => PageLoad.create(data)));

    const start = new Date(baseTime.getTime() - 60 * 60000);
    const end = baseTime;

    const response = await request().get('/api/stats').query({
      start: start.toISOString(),
      end: end.toISOString(),
    });

    expect(response.status).toBe(200);
    expect(response.body).toHaveLength(1);

    const stats = response.body[0];
    expect(Number(stats.count)).toBe(3);
    expect(Number(stats.unique_users)).toBe(2);
    expect(stats.interval).toBeTruthy();

    const dbStats = (await sequelize.query(
      `
        SELECT 
          count(*) as total_views,
          count(distinct user_agent) as unique_users
        FROM page_loads
        WHERE time BETWEEN :start AND :end
      `,
      {
        replacements: { start, end },
      },
    )) as unknown as { total_views: string; unique_users: string }[][];

    const rawStats = dbStats[0][0];
    expect(Number(rawStats.total_views)).toBe(3);
    expect(Number(rawStats.unique_users)).toBe(2);
  });

  it('should return accurate stats for a given time range with where json param filter', async () => {
    const baseTime = new Date();
    baseTime.setMinutes(30, 0, 0); // Set to XX:30:00

    const testData = [
      { userAgent: 'UA1', time: new Date(baseTime.getTime() - 10 * 60000) }, // XX:20:00
      { userAgent: 'UA2', time: new Date(baseTime.getTime() - 15 * 60000) }, // XX:15:00
      { userAgent: 'UA1', time: new Date(baseTime.getTime() - 20 * 60000) }, // XX:10:00
    ];

    await Promise.all(testData.map((data) => PageLoad.create(data)));

    const start = new Date(baseTime.getTime() - 60 * 60000);
    const end = baseTime;

    const response = await request()
      .get('/api/stats')
      .query({
        start: start.toISOString(),
        end: end.toISOString(),
        where: JSON.stringify({ user_agent: 'UA1' }),
      });

    expect(response.status).toBe(200);
    expect(response.body).toHaveLength(1);

    const stats = response.body[0];
    expect(Number(stats.count)).toBe(2);
    expect(Number(stats.unique_users)).toBe(1);
    expect(stats.interval).toBeTruthy();

    const dbStats = (await sequelize.query(
      `
        SELECT 
          count(*) as total_views,
          count(distinct user_agent) as unique_users
        FROM page_loads
        WHERE time BETWEEN :start AND :end
        AND user_agent = :userAgent
      `,
      {
        replacements: { start, end, userAgent: 'UA1' },
      },
    )) as unknown as { total_views: string; unique_users: string }[][];

    const rawStats = dbStats[0][0];
    expect(Number(rawStats.total_views)).toBe(2);
    expect(Number(rawStats.unique_users)).toBe(1);
  });

  it('should handle multiple hour buckets correctly', async () => {
    const baseTime = new Date();
    baseTime.setMinutes(30, 0, 0); // Set to XX:30:00

    const testData = [
      { userAgent: 'UA1', time: new Date(baseTime.getTime() - 15 * 60000) }, // Current hour
      { userAgent: 'UA2', time: new Date(baseTime.getTime() - 75 * 60000) }, // Previous hour
    ];

    await Promise.all(testData.map((data) => PageLoad.create(data)));

    const start = new Date(baseTime.getTime() - 120 * 60000); // 2 hours ago
    const end = baseTime;

    const response = await request().get('/api/stats').query({
      start: start.toISOString(),
      end: end.toISOString(),
    });

    expect(response.status).toBe(200);
    expect(response.body).toHaveLength(2);

    const sortedStats = response.body.sort(
      (a: any, b: any) => new Date(b.interval).getTime() - new Date(a.interval).getTime(),
    );

    expect(Number(sortedStats[0].count)).toBe(1);
    expect(Number(sortedStats[0].unique_users)).toBe(1);

    expect(Number(sortedStats[1].count)).toBe(1);
    expect(Number(sortedStats[1].unique_users)).toBe(1);
  });
});

================
File: examples/node-sequelize/.env.example
================
PORT=4000
DATABASE_URL=postgres://postgres:password@localhost:5432/postgres

================
File: examples/node-sequelize/.sequelizerc
================
const path = require('path');

module.exports = {
  config: path.resolve('config', 'sequelize.js'),
  'migrations-path': path.resolve('migrations'),
  'models-path': path.resolve('src', 'models'),
};

================
File: examples/node-sequelize/jest.config.js
================
/** @type {import('jest').Config} */
module.exports = {
  preset: 'ts-jest',
  testEnvironment: 'node',
  roots: ['<rootDir>/tests'],
  transform: {
    '^.+\\.tsx?$': [
      'ts-jest',
      {
        tsconfig: 'tsconfig.test.json',
      },
    ],
  },
  moduleFileExtensions: ['ts', 'tsx', 'js', 'jsx', 'json', 'node'],
  testMatch: ['**/tests/**/*.test.ts', '**/tests/**/*-tests.ts'],
  setupFilesAfterEnv: ['<rootDir>/tests/setup.ts'],
  verbose: true,
  testTimeout: 10000,
  clearMocks: true,
  restoreMocks: true,
};

================
File: examples/node-sequelize/package.json
================
{
  "name": "@timescaledb/example-node-sequelize",
  "version": "0.0.0-alpha.1",
  "scripts": {
    "build": "tsc",
    "start": "tsx src/index.ts",
    "test": "jest --runInBand",
    "migrate": "sequelize-cli db:migrate",
    "migrate:reset": "sequelize-cli db:migrate:undo:all && sequelize-cli db:migrate"
  },
  "dependencies": {
    "@timescaledb/core": "workspace:^",
    "@timescaledb/schemas": "workspace:^",
    "express": "^4.18.2",
    "pg": "^8.11.3",
    "pg-hstore": "^2.3.4",
    "sequelize": "^6.37.1",
    "sequelize-typescript": "^2.1.6"
  },
  "devDependencies": {
    "@faker-js/faker": "^9.3.0",
    "@types/sequelize": "^4.28.20",
    "sequelize-cli": "^6.6.2"
  }
}

================
File: examples/node-sequelize/README.md
================
# Node Sequelize Example

Example of using TimescaleDB with Node.js and [Sequelize](https://sequelize.org/). Based on the legacy [Node.js Quick Start](https://docs.timescale.com/quick-start/latest/node/) but updated with TypeScript and better practices + tests.

## What it does

- Tracks page views with user agent data
- Uses hypertables for time-series data
- Handles data compression automatically
- Provides stats endpoints with time bucketing

## Quick Start

```bash
# Setup
cp .env.example .env  # Update DATABASE_URL
pnpm install
pnpm build
pnpm migrate

# Run
pnpm start

# or

# Test
pnpm test
```

## API

```bash
# Record page view
POST /api/pageview

# Get stats for time range
GET /api/stats?start=2025-01-01&end=2025-01-02

# Check compression status
GET /api/compression
```

## Note

This example uses the legacy approach with raw SQL queries. Check back for the new `@timescaledb/core` package that will make this much simpler.

================
File: examples/node-sequelize/tsconfig.json
================
{
  "compilerOptions": {
    "target": "ES2020",
    "lib": ["esnext"],
    "allowJs": true,
    "sourceMap": true,
    "skipLibCheck": true,
    "esModuleInterop": true,
    "allowSyntheticDefaultImports": true,
    "strict": true,
    "module": "CommonJS",
    "moduleResolution": "node",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "noEmit": false,
    "outDir": "./dist",
    "baseUrl": ".",
    "noImplicitAny": false,
    "paths": {
      "@timescaledb/core": ["../../packages/core/dist"],
      "@timescaledb/schemas": ["../../packages/schemas/dist"]
    }
  },
  "include": ["src", "config", "migrations"]
}

================
File: examples/node-sequelize/tsconfig.test.json
================
{
  "extends": "./tsconfig.json",
  "compilerOptions": {
    "types": ["jest", "node"],
    "module": "commonjs",
    "target": "ES2020",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "moduleResolution": "node",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "noEmit": true,
    "outDir": "./dist-test"
  },
  "include": ["src/**/*.ts", "tests/**/*.ts"],
  "exclude": ["node_modules"]
}

================
File: examples/node-typeorm/migrations/1737173805840-create-page-loads.ts
================
import { MigrationInterface, QueryRunner } from 'typeorm';

export class CreatePageLoads1737173805840 implements MigrationInterface {
  name = 'CreatePageLoads1737173805840';

  public async up(queryRunner: QueryRunner): Promise<void> {
    await queryRunner.query(
      `CREATE TABLE "page_loads" ("user_agent" character varying NOT NULL, "time" TIMESTAMP NOT NULL, CONSTRAINT "PK_648dbdfc9ed8d6f2490f61ca49d" PRIMARY KEY ("user_agent", "time"))`,
    );
  }

  public async down(queryRunner: QueryRunner): Promise<void> {
    await queryRunner.query(`DROP TABLE "page_loads"`);
  }
}

================
File: examples/node-typeorm/migrations/1738403699299-CreateStockPrice.ts
================
import { MigrationInterface, QueryRunner } from 'typeorm';

export class CreateStockPrice1738403699299 implements MigrationInterface {
  name = 'CreateStockPrice1738403699299';

  public async up(queryRunner: QueryRunner): Promise<void> {
    await queryRunner.query(
      `CREATE TABLE "stock_prices" ("symbol" character varying NOT NULL, "timestamp" TIMESTAMP NOT NULL, "price" numeric(10,2) NOT NULL, "volume" numeric(10,2) NOT NULL, CONSTRAINT "PK_a42eff6e746633cc0a65fa01bce" PRIMARY KEY ("symbol", "timestamp"))`,
    );
  }

  public async down(queryRunner: QueryRunner): Promise<void> {
    await queryRunner.query(`DROP TABLE "stock_prices"`);
  }
}

================
File: examples/node-typeorm/src/models/HourlyPageViews.ts
================
import { ContinuousAggregate, AggregateColumn, BucketColumn } from '@timescaledb/typeorm';
import { PageLoad } from './PageLoad';
import { AggregateType } from '@timescaledb/schemas';

@ContinuousAggregate(PageLoad, {
  name: 'hourly_page_views',
  bucket_interval: '1 hour',
  refresh_policy: {
    start_offset: '3 days',
    end_offset: '1 hour',
    schedule_interval: '1 hour',
  },
})
export class HourlyPageViews {
  @BucketColumn({
    source_column: 'time',
  })
  bucket!: Date;

  @AggregateColumn({
    type: AggregateType.Count,
  })
  total_views!: number;

  @AggregateColumn({
    type: AggregateType.CountDistinct,
    column: 'user_agent',
  })
  unique_users!: number;
}

================
File: examples/node-typeorm/src/models/PageLoad.ts
================
import { Entity, PrimaryColumn } from 'typeorm';
import { Hypertable } from '@timescaledb/typeorm';

@Entity('page_loads')
@Hypertable({
  by_range: {
    column_name: 'time',
  },
  compression: {
    compress: true,
    compress_orderby: 'time',
    compress_segmentby: 'user_agent',
    policy: {
      schedule_interval: '7 days',
    },
  },
})
export class PageLoad {
  @PrimaryColumn({ name: 'user_agent', type: 'varchar' })
  userAgent!: string;

  @PrimaryColumn({ type: 'timestamp' })
  time!: Date;
}

================
File: examples/node-typeorm/src/models/StockPrice.ts
================
import { Entity, PrimaryColumn, Column } from 'typeorm';
import { Hypertable } from '@timescaledb/typeorm';

@Entity('stock_prices')
@Hypertable({
  by_range: {
    column_name: 'timestamp',
  },
  compression: {
    compress: true,
    compress_orderby: 'timestamp',
    compress_segmentby: 'symbol',
    policy: {
      schedule_interval: '7 days',
    },
  },
})
export class StockPrice {
  @PrimaryColumn({ type: 'varchar' })
  symbol!: string;

  @PrimaryColumn({ type: 'timestamp' })
  timestamp!: Date;

  @Column({ type: 'decimal', precision: 10, scale: 2 })
  price!: number;

  @Column({ type: 'decimal', precision: 10, scale: 2 })
  volume!: number;
}

================
File: examples/node-typeorm/src/routes/index.ts
================
import { Router } from 'express';
import { AppDataSource } from '../data-source';
import { PageLoad } from '../models/PageLoad';
import { HourlyPageViews } from '../models/HourlyPageViews';
import { StockPrice } from '../models/StockPrice';
import { WhereClauseSchema } from '@timescaledb/schemas';

const router = Router();

router.post('/pageview', async (req, res) => {
  try {
    const userAgent = req.get('user-agent') || 'unknown';
    const time = new Date();

    const pageLoadRepository = AppDataSource.getRepository(PageLoad);
    await pageLoadRepository.save({ userAgent, time });

    res.json({ message: 'Page view recorded' });
  } catch (error) {
    console.error(error);
    res.status(500).json({ error: 'Failed to record page view' });
  }
});

router.get('/stats', async (req, res) => {
  try {
    const start = new Date(req.query.start as string);
    const end = new Date(req.query.end as string);
    const where = req.query.where as string;
    const whereClause = where ? WhereClauseSchema.parse(JSON.parse(where)) : undefined;

    const repository = AppDataSource.getRepository(PageLoad);

    const stats = await repository.getTimeBucket({
      timeRange: {
        start,
        end,
      },
      where: whereClause,
      bucket: {
        interval: '1 hour',
        metrics: [
          { type: 'count', alias: 'count' },
          { type: 'distinct_count', column: 'user_agent', alias: 'unique_users' },
        ],
      },
    });

    res.json(stats);
  } catch (error) {
    console.error(error);
    res.status(500).json({ error: 'Failed to get stats' });
  }
});

router.get('/compression', async (req, res) => {
  try {
    const repository = AppDataSource.getRepository(PageLoad);
    const stats = await repository.getCompressionStats();
    res.json(stats);
  } catch (error) {
    console.error(error);
    res.status(500).json({ error: 'Failed to get compression stats' });
  }
});

router.get('/hourly', async (req, res) => {
  try {
    const start = new Date(req.query.start as string);
    const end = new Date(req.query.end as string);

    const query = AppDataSource.getRepository(HourlyPageViews)
      .createQueryBuilder()
      .where('bucket >= :start', { start })
      .andWhere('bucket <= :end', { end })
      .orderBy('bucket', 'DESC');

    const hourlyViews = await query.getMany();

    res.json(hourlyViews);
  } catch (error) {
    console.error(error);
    res.status(500).json({ error: 'Failed to get hourly stats' });
  }
});

router.get('/candlestick', async (req, res) => {
  try {
    const start = new Date(req.query.start as string);
    const end = new Date(req.query.end as string);
    const where = req.query.where as string;
    const whereClause = where ? WhereClauseSchema.parse(JSON.parse(where)) : undefined;

    const repository = AppDataSource.getRepository(StockPrice);
    const candlesticks = await repository.getCandlesticks({
      timeRange: { start, end },
      config: {
        time_column: 'timestamp',
        price_column: 'price',
        volume_column: 'volume',
        bucket_interval: '1 hour',
      },
      where: whereClause,
    });

    res.json(candlesticks);
  } catch (error) {
    console.error(error);
    res.status(500).json({ error: 'Failed to get candlestick data' });
  }
});

export default router;

================
File: examples/node-typeorm/src/app.ts
================
import express from 'express';
import dotenv from 'dotenv';
import routes from './routes';

dotenv.config();

export const app = express();
export const port = process.env.PORT as string;

app.use(express.json());
app.use('/api', routes);

================
File: examples/node-typeorm/src/data-source.ts
================
import '@timescaledb/typeorm';
import { DataSource } from 'typeorm';
import { PageLoad } from './models/PageLoad';

import dotenv from 'dotenv';
import { HourlyPageViews } from './models/HourlyPageViews';
import { StockPrice } from './models/StockPrice';

dotenv.config();

export const AppDataSource = new DataSource({
  type: 'postgres',
  url: process.env.DATABASE_URL,
  synchronize: false,
  logging: process.env.NODE_ENV === 'development',
  entities: [PageLoad, HourlyPageViews, StockPrice],
  migrations: ['migrations/*.ts'],
});

================
File: examples/node-typeorm/src/index.ts
================
import 'reflect-metadata';
import dotenv from 'dotenv';
import { AppDataSource } from './data-source';
import { app, port } from './app';

dotenv.config();

async function bootstrap() {
  try {
    await AppDataSource.initialize();
    await AppDataSource.synchronize();
    console.log('Data Source has been initialized');

    app.listen(port, () => {
      console.info(`Server is running at http://localhost:${port}`);
    });
  } catch (error) {
    console.error('Error during initialization:', error);
    process.exit(1);
  }
}

bootstrap().catch((error) => {
  console.error('Unhandled error during startup:', error);
  process.exit(1);
});

================
File: examples/node-typeorm/src/types.ts
================
export interface PageViewStats {
  interval: string;
  count: number;
  unique_users: number;
}

================
File: examples/node-typeorm/tests/candlestick.test.ts
================
import { describe, it, expect, beforeEach, afterAll } from '@jest/globals';
import { request } from './mock-request';
import { AppDataSource } from '../src/data-source';
import { StockPrice } from '../src/models/StockPrice';

describe('GET /api/candlestick', () => {
  beforeEach(async () => {
    const repository = AppDataSource.getRepository(StockPrice);
    await repository.clear();
  });

  afterAll(async () => {
    await AppDataSource.destroy();
  });

  it('should return candlestick data for a given time range', async () => {
    const repository = AppDataSource.getRepository(StockPrice);
    const baseTime = new Date('2025-01-01T00:00:00Z');
    const symbol = 'BTC';
    const otherSymbol = 'OTHER';

    const testData = [
      { symbol, timestamp: new Date(baseTime.getTime() + 5 * 60000), price: 102000, volume: 1.5 }, // Opening price
      { symbol, timestamp: new Date(baseTime.getTime() + 15 * 60000), price: 104000, volume: 2.0 }, // High
      { symbol, timestamp: new Date(baseTime.getTime() + 25 * 60000), price: 101500, volume: 1.0 }, // Low
      { symbol, timestamp: new Date(baseTime.getTime() + 55 * 60000), price: 103500, volume: 1.8 }, // Close

      { symbol, timestamp: new Date(baseTime.getTime() + 65 * 60000), price: 103600, volume: 1.2 },
      { symbol, timestamp: new Date(baseTime.getTime() + 75 * 60000), price: 105000, volume: 2.5 },
      { symbol, timestamp: new Date(baseTime.getTime() + 85 * 60000), price: 104000, volume: 1.7 },
      { symbol, timestamp: new Date(baseTime.getTime() + 115 * 60000), price: 104500, volume: 1.9 },

      { symbol: otherSymbol, timestamp: new Date(baseTime.getTime() + 125 * 60000), price: 420, volume: 1.2 },
    ];

    await Promise.all(testData.map((data) => repository.save(data)));

    const start = baseTime;
    const end = new Date(baseTime.getTime() + 3 * 3600000); // 3 hours later

    const response = await request()
      .get('/api/candlestick')
      .query({
        start: start.toISOString(),
        end: end.toISOString(),
        where: JSON.stringify({ symbol }),
      });

    expect(response.status).toBe(200);
    expect(response.body).toHaveLength(2);

    const firstCandle = response.body[0];
    expect(firstCandle).toHaveProperty('bucket_time');
    expect(firstCandle).toHaveProperty('open');
    expect(firstCandle).toHaveProperty('high');
    expect(firstCandle).toHaveProperty('low');
    expect(firstCandle).toHaveProperty('close');
    expect(firstCandle).toHaveProperty('volume');
    expect(firstCandle).toHaveProperty('vwap');

    // Verify first candlestick values
    expect(Number(firstCandle.open)).toBe(102000);
    expect(Number(firstCandle.high)).toBe(104000);
    expect(Number(firstCandle.low)).toBe(101500);
    expect(Number(firstCandle.close)).toBe(103500);
    expect(Number(firstCandle.volume)).toBeCloseTo(6.3, 1);

    // Verify second candlestick values
    const secondCandle = response.body[1];
    expect(Number(secondCandle.open)).toBe(103600);
    expect(Number(secondCandle.high)).toBe(105000);
    expect(Number(secondCandle.low)).toBe(103600);
    expect(Number(secondCandle.close)).toBe(104500);
    expect(Number(secondCandle.volume)).toBeCloseTo(7.3, 1);
  });
});

================
File: examples/node-typeorm/tests/compression.test.ts
================
import { afterAll, beforeEach, describe, it } from '@jest/globals';
import { AppDataSource } from '../src/data-source';
import { PageLoad } from '../src/models/PageLoad';
import { request } from './mock-request';
import { faker } from '@faker-js/faker';

describe('GET /api/compression', () => {
  beforeEach(async () => {
    const repository = AppDataSource.getRepository(PageLoad);
    await repository.clear();
  });

  afterAll(async () => {
    await AppDataSource.destroy();
  });

  it('should show accurate compression stats after data insertion', async () => {
    const repository = AppDataSource.getRepository(PageLoad);
    const userAgents = Array.from({ length: 1000 }, () => faker.internet.userAgent());
    const startTime = new Date(Date.now() - 8 * 24 * 60 * 60 * 1000); // 8 days ago

    for (const userAgent of userAgents) {
      await repository.save({
        userAgent,
        time: new Date(startTime.getTime() + Math.random() * 7 * 24 * 60 * 60 * 1000), // Within the last 7 days
      });
    }

    await new Promise((resolve) => setTimeout(resolve, 2000));

    const response = await request().get('/api/compression');
    expect(response.status).toBe(200);

    const [dbStats] = await AppDataSource.query(`
      SELECT 
        COALESCE(total_chunks, 0)::integer as total_chunks,
        COALESCE(number_compressed_chunks, 0)::integer as compressed_chunks
      FROM hypertable_compression_stats('page_loads');
    `);

    expect(response.body).toEqual({
      total_chunks: dbStats.total_chunks,
      compressed_chunks: dbStats.compressed_chunks,
    });

    expect(response.body.total_chunks).toBeGreaterThan(0);
    expect(response.body.compressed_chunks).toBeGreaterThanOrEqual(0);
  });
});

================
File: examples/node-typeorm/tests/hourly.test.ts
================
import { describe, it, expect, beforeEach, afterAll } from '@jest/globals';
import { request } from './mock-request';
import { AppDataSource } from '../src/data-source';
import { PageLoad } from '../src/models/PageLoad';
import { faker } from '@faker-js/faker';

describe('GET /api/hourly', () => {
  beforeEach(async () => {
    const repository = AppDataSource.getRepository(PageLoad);
    await repository.clear();
  });

  afterAll(async () => {
    await AppDataSource.destroy();
  });

  it('should return hourly stats for a given time range', async () => {
    const repository = AppDataSource.getRepository(PageLoad);
    const baseTime = new Date();
    baseTime.setMinutes(0, 0, 0);

    // Create test data across 3 hours
    for (let hour = 0; hour < 3; hour++) {
      const time = new Date(baseTime.getTime() - hour * 3600000);

      // Create multiple records per hour
      for (let i = 0; i < 5; i++) {
        await repository.save({
          userAgent: faker.internet.userAgent(),
          time: new Date(time.getTime() + i * 60000), // Spread over minutes
        });
      }
    }

    // Manually refresh the continuous aggregate
    await AppDataSource.query(`CALL refresh_continuous_aggregate('hourly_page_views', null, null);`);

    // Wait for refresh to complete
    await new Promise((resolve) => setTimeout(resolve, 3000));

    const start = new Date(baseTime.getTime() - 4 * 3600000); // 4 hours ago
    const end = baseTime;

    const response = await request().get('/api/hourly').query({
      start: start.toISOString(),
      end: end.toISOString(),
    });

    expect(response.status).toBe(200);
    expect(response.body).toHaveLength(3);

    const firstHour = response.body[0];
    expect(firstHour).toHaveProperty('bucket');
    expect(firstHour).toHaveProperty('total_views');
    expect(firstHour).toHaveProperty('unique_users');

    response.body.forEach((hour: any) => {
      expect(hour.total_views).toBe(5);
      expect(hour.unique_users).toBe(5);
    });
  });
});

================
File: examples/node-typeorm/tests/integration.test.ts
================
import { describe, it, expect, beforeEach, afterAll } from '@jest/globals';
import { request } from './mock-request';
import { faker } from '@faker-js/faker';
import { AppDataSource } from '../src/data-source';
import { PageLoad } from '../src/models/PageLoad';

describe('API Integration Tests', () => {
  beforeEach(async () => {
    const repository = AppDataSource.getRepository(PageLoad);
    await repository.clear();
  });

  afterAll(async () => {
    await AppDataSource.destroy();
  });

  it('should record page view and reflect in stats', async () => {
    const baseTime = new Date();
    baseTime.setMinutes(30, 0, 0); // Set to XX:30:00
    const userAgent = faker.internet.userAgent();

    const viewResponse = await request().post('/api/pageview').set('User-Agent', userAgent);
    expect(viewResponse.status).toBe(200);

    // Poll for the record to appear in the database
    const repository = AppDataSource.getRepository(PageLoad);
    const maxAttempts = 5;
    const pollInterval = 1000; // 1 second
    let pageLoadRecord: PageLoad | null = null;

    for (let attempt = 0; attempt < maxAttempts; attempt++) {
      await new Promise((resolve) => setTimeout(resolve, pollInterval));

      pageLoadRecord = await repository.findOne({
        where: { userAgent },
      });

      if (pageLoadRecord) {
        break;
      }
    }

    expect(pageLoadRecord).not.toBeNull();
    expect(pageLoadRecord?.userAgent).toBe(userAgent);

    const startTime = new Date(baseTime.getTime() - 3600000); // 1 hour ago
    const endTime = new Date(baseTime.getTime() + 3600000); // 1 hour ahead

    const statsResponse = await request().get('/api/stats').query({
      start: startTime.toISOString(),
      end: endTime.toISOString(),
    });

    expect(statsResponse.status).toBe(200);
    expect(statsResponse.body).toHaveLength(1);

    const stats = statsResponse.body[0];
    expect(Number(stats.count)).toBeGreaterThanOrEqual(1);
    expect(Number(stats.unique_users)).toBeGreaterThanOrEqual(1);
    expect(stats.interval).toBeTruthy();

    const dbRecord = await repository.findOne({
      where: { userAgent },
    });
    expect(dbRecord).not.toBeNull();
  });
});

================
File: examples/node-typeorm/tests/mock-request.ts
================
import supertest from 'supertest';
import { app } from '../src/app';

export const request = () => {
  return supertest(app);
};

================
File: examples/node-typeorm/tests/page-view.test.ts
================
import { describe, it, expect, beforeEach, afterAll } from '@jest/globals';
import { request } from './mock-request';
import { AppDataSource } from '../src/data-source';
import { PageLoad } from '../src/models/PageLoad';

describe('POST /api/pageview', () => {
  beforeEach(async () => {
    const repository = AppDataSource.getRepository(PageLoad);
    await repository.clear();
  });

  afterAll(async () => {
    await AppDataSource.destroy();
  });

  it('should record a page view and verify database record', async () => {
    const mockUserAgent = 'Mozilla/5.0 Test Browser';
    const beforeInsert = new Date();

    const response = await request().post('/api/pageview').set('User-Agent', mockUserAgent);

    const afterInsert = new Date();

    expect(response.status).toBe(200);
    expect(response.body).toEqual({ message: 'Page view recorded' });

    const repository = AppDataSource.getRepository(PageLoad);
    const record = await repository.findOne({
      where: { userAgent: mockUserAgent },
    });

    expect(record).not.toBeNull();
    expect(record?.userAgent).toBe(mockUserAgent);
    expect(record?.time.getTime()).toBeGreaterThanOrEqual(beforeInsert.getTime());
    expect(record?.time.getTime()).toBeLessThanOrEqual(afterInsert.getTime());
  });
});

================
File: examples/node-typeorm/tests/setup.ts
================
import { beforeAll } from '@jest/globals';
import dotenv from 'dotenv';
import { AppDataSource } from '../src/data-source';

dotenv.config({ path: '.env' });

process.env.NODE_ENV = 'test';
process.env.PORT = '4100';

beforeAll(async () => {
  try {
    await AppDataSource.initialize();
    await AppDataSource.runMigrations();
  } catch (error) {
    console.error('Test setup failed:', error);
    throw error;
  }
});

================
File: examples/node-typeorm/tests/stats.test.ts
================
import { AppDataSource } from '../src/data-source';
import { PageLoad } from '../src/models/PageLoad';
import { request } from './mock-request';

describe('GET /api/stats', () => {
  beforeEach(async () => {
    const repository = AppDataSource.getRepository(PageLoad);
    await repository.clear();
  });

  afterAll(async () => {
    await AppDataSource.destroy();
  });

  it('should return accurate stats for a given time range', async () => {
    const baseTime = new Date();
    baseTime.setMinutes(30, 0, 0); // Set to XX:30:00

    const repository = AppDataSource.getRepository(PageLoad);
    const testData = [
      { userAgent: 'UA1', time: new Date(baseTime.getTime() - 10 * 60000) }, // XX:20:00
      { userAgent: 'UA2', time: new Date(baseTime.getTime() - 15 * 60000) }, // XX:15:00
      { userAgent: 'UA1', time: new Date(baseTime.getTime() - 20 * 60000) }, // XX:10:00
    ];

    await Promise.all(testData.map((data) => repository.save(data)));

    const start = new Date(baseTime.getTime() - 60 * 60000);
    const end = baseTime;

    const response = await request().get('/api/stats').query({
      start: start.toISOString(),
      end: end.toISOString(),
    });

    expect(response.status).toBe(200);
    expect(response.body).toHaveLength(1);

    const stats = response.body[0];
    expect(Number(stats.count)).toBe(3);
    expect(Number(stats.unique_users)).toBe(2);
    expect(stats.interval).toBeTruthy();
  });

  it('should return accurate stats for a given time range with where json param filter', async () => {
    const baseTime = new Date();
    baseTime.setMinutes(30, 0, 0); // Set to XX:30:00

    const repository = AppDataSource.getRepository(PageLoad);
    const testData = [
      { userAgent: 'UA1', time: new Date(baseTime.getTime() - 10 * 60000) }, // XX:20:00
      { userAgent: 'UA2', time: new Date(baseTime.getTime() - 15 * 60000) }, // XX:15:00
      { userAgent: 'UA1', time: new Date(baseTime.getTime() - 20 * 60000) }, // XX:10:00
    ];

    await Promise.all(testData.map((data) => repository.save(data)));

    const start = new Date(baseTime.getTime() - 60 * 60000);
    const end = baseTime;

    const response = await request()
      .get('/api/stats')
      .query({
        start: start.toISOString(),
        end: end.toISOString(),
        where: JSON.stringify({ user_agent: 'UA1' }),
      });

    expect(response.status).toBe(200);
    expect(response.body).toHaveLength(1);

    const stats = response.body[0];
    expect(Number(stats.count)).toBe(2);
    expect(Number(stats.unique_users)).toBe(1);
    expect(stats.interval).toBeTruthy();
  });
});

================
File: examples/node-typeorm/.env.example
================
PORT=4100
DATABASE_URL=postgres://postgres:password@localhost:5432/postgres

================
File: examples/node-typeorm/jest.config.js
================
/** @type {import('jest').Config} */
module.exports = {
  preset: 'ts-jest',
  testEnvironment: 'node',
  roots: ['<rootDir>/tests'],
  transform: {
    '^.+\\.tsx?$': [
      'ts-jest',
      {
        tsconfig: 'tsconfig.test.json',
      },
    ],
  },
  moduleFileExtensions: ['ts', 'tsx', 'js', 'jsx', 'json', 'node'],
  testMatch: ['**/tests/**/*.test.ts', '**/tests/**/*-tests.ts'],
  setupFilesAfterEnv: ['<rootDir>/tests/setup.ts'],
  verbose: true,
  testTimeout: 10000,
  clearMocks: true,
  restoreMocks: true,
};

================
File: examples/node-typeorm/package.json
================
{
  "name": "@timescaledb/example-node-typeorm",
  "version": "0.0.0-alpha.1",
  "scripts": {
    "build": "tsc",
    "start": "tsx src/index.ts",
    "test": "jest --runInBand",
    "migrate": "typeorm-ts-node-commonjs migration:run -d src/data-source.ts",
    "migrate:reset": "typeorm-ts-node-commonjs migration:revert -d src/data-source.ts && typeorm-ts-node-commonjs migration:run -d src/data-source.ts"
  },
  "dependencies": {
    "@timescaledb/core": "workspace:^",
    "@timescaledb/schemas": "workspace:^",
    "@timescaledb/typeorm": "workspace:^",
    "express": "^4.18.2",
    "pg": "^8.11.3",
    "typeorm": "^0.3.20"
  },
  "devDependencies": {
    "@faker-js/faker": "^9.3.0"
  }
}

================
File: examples/node-typeorm/README.md
================
# Node TypeORM Example

Example of using TimescaleDB with Node.js and [TypeORM](https://typeorm.io/).

## What it does

- Tracks page views with user agent data
- Uses hypertables for time-series data
- Handles data compression automatically

## Quick Start

```bash
# Setup
cp .env.example .env  # Update DATABASE_URL
pnpm install
pnpm build
pnpm migrate

# Run
pnpm start

# or

# Test
pnpm test
```

## API

```bash
# Record page view
POST /api/pageview

# Get stats for time range
GET /api/stats?start=2025-01-01&end=2025-01-02

# Check compression status
GET /api/compression
```

## Note

This example uses the legacy approach with raw SQL queries. Check back for the new `@timescaledb/core` package that will make this much simpler.

================
File: examples/node-typeorm/tsconfig.json
================
{
  "compilerOptions": {
    "target": "ES2020",
    "lib": ["esnext"],
    "module": "commonjs",
    "moduleResolution": "node",
    "outDir": "./dist",
    "esModuleInterop": true,
    "experimentalDecorators": true,
    "emitDecoratorMetadata": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "strict": true,
    "paths": {
      "@timescaledb/*": ["../../packages/*/src"]
    }
  },
  "include": ["src", "migrations"],
  "exclude": ["node_modules", "dist"]
}

================
File: examples/node-typeorm/tsconfig.test.json
================
{
  "extends": "./tsconfig.json",
  "compilerOptions": {
    "types": ["jest", "node"],
    "module": "commonjs",
    "target": "ES2020",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "moduleResolution": "node",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "noEmit": true,
    "outDir": "./dist-test"
  },
  "include": ["src/**/*.ts", "tests/**/*.ts"],
  "exclude": ["node_modules"]
}

================
File: packages/core/src/candlestick.ts
================
import {
  CandlestickAggregateOptions,
  CandlestickAggregateOptionsSchema,
  TimeRange,
  WhereClause,
} from '@timescaledb/schemas';
import { buildWhereClause, escapeIdentifier } from '@timescaledb/utils';

export class CandlestickAggregateBuilder {
  private statements: string[] = [];
  private options: CandlestickAggregateOptions;
  private tableName: string;

  constructor(tableName: string, options: CandlestickAggregateOptions) {
    this.tableName = tableName;
    this.options = CandlestickAggregateOptionsSchema.parse(options);
  }

  private buildWhere(where: WhereClause, paramOffset = 1): { sql: string; params: any[] } {
    if (!where) {
      return { sql: '', params: [] };
    }

    const { sql, params } = buildWhereClause(where, paramOffset);

    return { sql: ` AND ${sql}`, params };
  }

  public build({ where, range }: { where?: WhereClause; range?: TimeRange } = {}): { sql: string; params: any[] } {
    const tableName = escapeIdentifier(this.tableName);
    const timeColumn = escapeIdentifier(this.options.time_column);
    const priceColumn = escapeIdentifier(this.options.price_column);
    const volumeColumn = this.options.volume_column ? escapeIdentifier(this.options.volume_column) : null;
    const interval = '$1::interval';

    this.statements = [];

    this.statements.push(`SELECT`);
    this.statements.push(`  time_bucket(${interval}, ${timeColumn}) as bucket_time,`);
    this.statements.push(
      `  open(candlestick_agg(${timeColumn}, ${priceColumn}${volumeColumn ? `, ${volumeColumn}` : ''})) as open,`,
    );
    this.statements.push(
      `  high(candlestick_agg(${timeColumn}, ${priceColumn}${volumeColumn ? `, ${volumeColumn}` : ''})) as high,`,
    );
    this.statements.push(
      `  low(candlestick_agg(${timeColumn}, ${priceColumn}${volumeColumn ? `, ${volumeColumn}` : ''})) as low,`,
    );
    this.statements.push(
      `  close(candlestick_agg(${timeColumn}, ${priceColumn}${volumeColumn ? `, ${volumeColumn}` : ''})) as close,`,
    );
    this.statements.push(
      `  open_time(candlestick_agg(${timeColumn}, ${priceColumn}${volumeColumn ? `, ${volumeColumn}` : ''})) as open_time,`,
    );
    this.statements.push(
      `  high_time(candlestick_agg(${timeColumn}, ${priceColumn}${volumeColumn ? `, ${volumeColumn}` : ''})) as high_time,`,
    );
    this.statements.push(
      `  low_time(candlestick_agg(${timeColumn}, ${priceColumn}${volumeColumn ? `, ${volumeColumn}` : ''})) as low_time,`,
    );
    this.statements.push(
      `  close_time(candlestick_agg(${timeColumn}, ${priceColumn}${volumeColumn ? `, ${volumeColumn}` : ''})) as close_time`,
    );

    if (volumeColumn) {
      this.statements.push(`  ,volume(candlestick_agg(${timeColumn}, ${priceColumn}, ${volumeColumn})) as volume,`);
      this.statements.push(`  vwap(candlestick_agg(${timeColumn}, ${priceColumn}, ${volumeColumn})) as vwap`);
    }

    this.statements.push(`FROM ${tableName}`);

    const params: (string | Date)[] = [this.options.bucket_interval || '1 hour'];
    if (range) {
      params.push(range.start, range.end);
    }

    const whereClause = this.buildWhere(where as WhereClause, params.length + 1);
    const timeRangeWhere = range ? `WHERE ${timeColumn} >= $2 AND ${timeColumn} <= $3` : '';
    const fullWhere = timeRangeWhere + whereClause.sql;

    if (fullWhere) {
      this.statements.push(fullWhere);
    }

    params.push(...whereClause.params);

    this.statements.push(`GROUP BY bucket_time`);
    this.statements.push(`ORDER BY bucket_time ASC;`);

    return {
      sql: this.statements.join('\n'),
      params,
    };
  }
}

================
File: packages/core/src/compression.ts
================
import { CompressionSelect, CompressionSelectSchema, CreateHypertableOptions } from '@timescaledb/schemas';
import { escapeLiteral } from '@timescaledb/utils';

class CompressionStatsBuilder {
  private statements: string[] = [];

  private name: string;
  private options: CompressionSelect;

  constructor(name: string, select: CompressionSelect) {
    this.name = name;
    this.options = select;
  }

  public build(): string {
    this.statements.push(`SELECT`);

    const columns: string[] = [];

    if (this.options.total_chunks) {
      columns.push(`COALESCE(total_chunks, 0)::integer as total_chunks`);
    }

    if (this.options.compressed_chunks) {
      columns.push(`COALESCE(number_compressed_chunks, 0)::integer as compressed_chunks`);
    }

    if (columns.length === 0) {
      this.statements.push(`*`);
    } else {
      this.statements.push(columns.join(',\n'));
    }

    const literalName = escapeLiteral(this.name);

    this.statements.push(`FROM hypertable_compression_stats(${literalName});`);

    return this.statements.join('\n');
  }
}

export class CompressionBuilder {
  private name: string;
  private options: CreateHypertableOptions;

  constructor(name: string, options: CreateHypertableOptions) {
    this.name = name;
    this.options = options;
  }

  public stats(statOpts: { select: CompressionSelect }): CompressionStatsBuilder {
    const select = CompressionSelectSchema.parse(statOpts.select);
    return new CompressionStatsBuilder(this.name, select);
  }
}

================
File: packages/core/src/continuous-aggregate.ts
================
import {
  AggregateColumnOptions,
  AggregateType,
  CreateContinuousAggregateOptions,
  CreateContinuousAggregateOptionsSchema,
} from '@timescaledb/schemas';
import { escapeIdentifier, escapeLiteral } from '@timescaledb/utils';

class ContinuousAggregateInspectBuilder {
  constructor(private name: string) {}

  public build(): string {
    const literalName = escapeLiteral(this.name);

    return `SELECT EXISTS (
      SELECT FROM timescaledb_information.continuous_aggregates
      WHERE view_name = ${literalName}
    ) as hypertable_exists;`;
  }
}

class ContinuousAggregateUpBuilder {
  constructor(
    private name: string,
    private source: string,
    private options: CreateContinuousAggregateOptions,
  ) {}

  private generateAggregate(config: AggregateColumnOptions): string {
    const alias = escapeIdentifier(config.column_alias!);

    switch (config.type) {
      case 'count':
        return `COUNT(*) as ${alias}`;
      case 'count_distinct': {
        if (!config.column) {
          throw new Error('Column is required for count_distinct aggregate');
        }
        const column = escapeIdentifier(config.column);
        return `COUNT(DISTINCT ${column}) as ${alias}`;
      }
      case 'sum': {
        if (!config.column) {
          throw new Error('Column is required for sum aggregate');
        }
        const sumColumn = escapeIdentifier(config.column);
        return `SUM(${sumColumn}) as ${alias}`;
      }
      case 'avg': {
        if (!config.column) {
          throw new Error('Column is required for avg aggregate');
        }
        const avgColumn = escapeIdentifier(config.column);
        return `AVG(${avgColumn}) as ${alias}`;
      }
      case 'min': {
        if (!config.column) {
          throw new Error('Column is required for min aggregate');
        }
        const minColumn = escapeIdentifier(config.column);
        return `MIN(${minColumn}) as ${alias}`;
      }
      case 'max': {
        if (!config.column) {
          throw new Error('Column is required for max aggregate');
        }
        const maxColumn = escapeIdentifier(config.column);
        return `MAX(${maxColumn}) as ${alias}`;
      }
      case 'bucket': {
        if (!config.column) {
          throw new Error('Column is required for bucket aggregate');
        }
        const interval = escapeLiteral(this.options.bucket_interval);
        const bucketColumn = escapeIdentifier(config.column);

        return `time_bucket(${interval}, ${bucketColumn}) as ${alias}`;
      }
      default:
        throw new Error(`Unsupported aggregate type: ${config.type}`);
    }
  }

  private generateSelect(): string {
    const sourceName = escapeIdentifier(this.source);

    const aggregates = Object.entries(this.options.aggregates || [])
      .map(([, config]) => {
        return config.type === AggregateType.Bucket ? false : this.generateAggregate(config);
      })
      .filter(Boolean) as string[];

    const bucketAggregate = Object.entries(this.options.aggregates || []).find(
      ([, config]) => config.type === AggregateType.Bucket,
    );

    const bucketColumnAlias = escapeIdentifier(bucketAggregate?.[1].column_alias || 'bucket');

    const generatedBucketStr = bucketAggregate
      ? this.generateAggregate(bucketAggregate[1])
      : this.generateAggregate({
          type: AggregateType.Bucket,
          column: this.options.time_column,
          column_alias: 'bucket',
        });

    return `
      SELECT
        ${[generatedBucketStr, ...aggregates].join(',\n        ')}
      FROM ${sourceName}
      GROUP BY ${bucketColumnAlias}
    `;
  }

  public getRefreshPolicy(): string | null {
    if (!this.options.refresh_policy) return null;

    const policy = this.options.refresh_policy;
    const viewName = escapeLiteral(this.name);
    return `SELECT add_continuous_aggregate_policy(${viewName},
      start_offset => INTERVAL ${escapeLiteral(policy.start_offset)},
      end_offset => INTERVAL ${escapeLiteral(policy.end_offset)},
      schedule_interval => INTERVAL ${escapeLiteral(policy.schedule_interval)}
    );`;
  }

  public build(): string {
    const viewName = escapeIdentifier(this.name);
    return `CREATE MATERIALIZED VIEW ${viewName} WITH (timescaledb.continuous) AS ${this.generateSelect()} WITH NO DATA;`;
  }
}

class ContinuousAggregateDownBuilder {
  constructor(
    private name: string,
    private options: CreateContinuousAggregateOptions,
  ) {}

  public build(): string[] {
    const statements: string[] = [];
    const viewName = this.name;

    if (this.options.refresh_policy) {
      statements.push(`SELECT remove_continuous_aggregate_policy(${escapeLiteral(viewName)}, if_exists => true);`);
    }

    statements.push(`DROP MATERIALIZED VIEW IF EXISTS ${escapeIdentifier(viewName)};`);

    return statements;
  }
}

export class ContinuousAggregate {
  private name: string;
  private source: string;
  private options: CreateContinuousAggregateOptions;

  constructor(name: string, source: string, options: CreateContinuousAggregateOptions) {
    this.name = name;
    this.source = source;
    this.options = CreateContinuousAggregateOptionsSchema.parse(options);
  }

  public up(): ContinuousAggregateUpBuilder {
    return new ContinuousAggregateUpBuilder(this.name, this.source, this.options);
  }

  public down(): ContinuousAggregateDownBuilder {
    return new ContinuousAggregateDownBuilder(this.name, this.options);
  }

  public inspect(): ContinuousAggregateInspectBuilder {
    return new ContinuousAggregateInspectBuilder(this.name);
  }
}

================
File: packages/core/src/errors.ts
================
export enum HypertableErrors {
  NAME_REQUIRED = 'Hypertable name is required',
  OPTIONS_REQUIRED = 'Hypertable options are required',
  INVALID_OPTIONS = 'Invalid hypertable options',
  INVALID_NAME = 'Invalid hypertable name',
}

export enum ExtensionErrors {
  INVALID_OPTIONS = 'Invalid extension options',
}

export enum CompressionErrors {
  INVALID_OPTIONS = 'Invalid compression options',
}

================
File: packages/core/src/extension.ts
================
import { CreateExtensionOptions, CreateExtensionOptionsSchema } from '@timescaledb/schemas';
import { ExtensionErrors } from './errors';

class ExtensionUpBuilder {
  private options?: CreateExtensionOptions;
  private statements: string[] = [];

  constructor(options?: CreateExtensionOptions) {
    this.options = options;
  }

  public build(): string {
    const stmt = `CREATE EXTENSION IF NOT EXISTS timescaledb${this?.options?.should_cascade ? ' CASCADE' : ''};`;
    this.statements.push(stmt);

    return this.statements.join('\n');
  }
}

class ExtensionDownBuilder {
  private options?: CreateExtensionOptions;
  private statements: string[] = [];

  constructor(options?: CreateExtensionOptions) {
    this.options = options;
  }

  public build(): string {
    const stmt = `DROP EXTENSION IF EXISTS timescaledb${this?.options?.should_cascade ? ' CASCADE' : ''};`;
    this.statements.push(stmt);

    return this.statements.join('\n');
  }
}

export class Extension {
  private options?: CreateExtensionOptions;

  constructor(options?: CreateExtensionOptions) {
    if (options) {
      try {
        this.options = CreateExtensionOptionsSchema.parse(options);
      } catch (error) {
        const e = error as Error;
        throw new Error(ExtensionErrors.INVALID_OPTIONS + ' ' + e.message);
      }
    }
  }

  public up(): ExtensionUpBuilder {
    return new ExtensionUpBuilder(this.options);
  }

  public down(): ExtensionDownBuilder {
    return new ExtensionDownBuilder(this.options);
  }
}

================
File: packages/core/src/hypertable.ts
================
import { CreateHypertableOptions, CreateHypertableOptionsSchema, TimeBucketConfig } from '@timescaledb/schemas';
import { HypertableErrors } from './errors';
import { escapeIdentifier, escapeLiteral, validateIdentifier } from '@timescaledb/utils';
import { CompressionBuilder } from './compression';
import { TimeBucketBuilder } from './time-bucket';

class HypertableUpBuilder {
  private options: CreateHypertableOptions;
  private name: string;
  private statements: string[] = [];

  constructor(name: string, options: CreateHypertableOptions) {
    this.name = name;
    this.options = options;
  }

  public build(): string {
    const tableName = escapeIdentifier(this.name);

    this.statements.push(
      `SELECT create_hypertable(${escapeLiteral(this.name)}, by_range(${escapeLiteral(this.options.by_range.column_name)}));`,
    );

    if (this.options.compression?.compress) {
      const orderBy = escapeIdentifier(this.options.compression.compress_orderby);
      const segmentBy = escapeIdentifier(this.options.compression.compress_segmentby);

      const alter = `ALTER TABLE ${tableName} SET (
        timescaledb.compress,
        timescaledb.compress_orderby = ${orderBy},
        timescaledb.compress_segmentby = ${segmentBy}
      );`;
      this.statements.push(alter);

      if (this.options.compression.policy) {
        const interval = escapeLiteral(this.options.compression.policy.schedule_interval);
        const policy = `SELECT add_compression_policy(${escapeLiteral(this.name)}, INTERVAL ${interval});`;
        this.statements.push(policy);
      }
    }

    return this.statements.join('\n');
  }
}

class HypertableDownBuilder {
  private name: string;
  private options: CreateHypertableOptions;
  private statements: string[] = [];

  constructor(name: string, options: CreateHypertableOptions) {
    this.name = name;
    this.options = options;
  }

  public build(): string {
    const tableName = escapeIdentifier(this.name);
    const literalName = escapeLiteral(this.name);

    if (this.options.compression?.compress) {
      this.statements.push(`ALTER TABLE ${tableName} SET (timescaledb.compress = false);`);
    }

    if (this.options.compression?.policy) {
      this.statements.push(`SELECT remove_compression_policy(${literalName}, if_exists => true);`);
    }

    this.statements.push(`SELECT drop_chunks(${literalName}, NOW()::timestamp without time zone);`);

    return this.statements.join('\n');
  }
}

export class HypertableInspectBuilder {
  private name: string;
  private statements: string[] = [];

  constructor(name: string) {
    this.name = name;
  }

  public build(): string {
    const literalName = escapeLiteral(this.name);

    this.statements.push('SELECT');

    this.statements.push(`  EXISTS (
    SELECT FROM information_schema.tables 
    WHERE table_schema = 'public' 
    AND table_name = ${literalName}
  ) AS table_exists,`);

    this.statements.push(`  EXISTS (
    SELECT FROM timescaledb_information.hypertables
    WHERE hypertable_name = ${literalName}
  ) AS is_hypertable`);

    return this.statements.join('\n');
  }
}

export class Hypertable {
  private options: CreateHypertableOptions;
  private name: string;

  constructor(name: string, options: CreateHypertableOptions) {
    if (!name) {
      throw new Error(HypertableErrors.NAME_REQUIRED);
    }

    try {
      validateIdentifier(name, true);
      this.name = name;
    } catch (error) {
      throw new Error(HypertableErrors.INVALID_NAME + ' ' + (error as Error).message);
    }

    if (!options) {
      throw new Error(HypertableErrors.OPTIONS_REQUIRED);
    }

    try {
      this.options = CreateHypertableOptionsSchema.parse(options);
    } catch (error) {
      const e = error as Error;
      throw new Error(HypertableErrors.INVALID_OPTIONS + ' ' + e.message);
    }
  }

  public up(): HypertableUpBuilder {
    return new HypertableUpBuilder(this.name, this.options);
  }

  public down(): HypertableDownBuilder {
    return new HypertableDownBuilder(this.name, this.options);
  }

  public inspect(): HypertableInspectBuilder {
    return new HypertableInspectBuilder(this.name);
  }

  public compression(): CompressionBuilder {
    return new CompressionBuilder(this.name, this.options);
  }

  public timeBucket(config: TimeBucketConfig): TimeBucketBuilder {
    return new TimeBucketBuilder(this.name, this.options.by_range.column_name, config);
  }
}

================
File: packages/core/src/index.ts
================
import {
  CandlestickAggregateOptions,
  CreateContinuousAggregateOptions,
  CreateExtensionOptions,
  CreateHypertableOptions,
} from '@timescaledb/schemas';
import { Hypertable } from './hypertable';
import { Extension } from './extension';
import { ContinuousAggregate } from './continuous-aggregate';
import { CandlestickAggregateBuilder } from './candlestick';

export const name = '@timescaledb/core';

export class TimescaleDB {
  public static Hypertable: Hypertable;

  public static createHypertable(tableName: string, options: CreateHypertableOptions): Hypertable {
    const hypertable = new Hypertable(tableName, options);

    return hypertable;
  }

  public static createExtension(options?: CreateExtensionOptions): Extension {
    const extension = new Extension(options);

    return extension;
  }

  public static createContinuousAggregate(
    name: string,
    source: string,
    options: Omit<CreateContinuousAggregateOptions, 'name'>,
  ): ContinuousAggregate {
    return new ContinuousAggregate(name, source, { ...options, name });
  }

  public static createCandlestickAggregate(
    tableName: string,
    options: CandlestickAggregateOptions,
  ): CandlestickAggregateBuilder {
    return new CandlestickAggregateBuilder(tableName, options);
  }
}

export * from './errors';

================
File: packages/core/src/time-bucket.ts
================
import { MetricConfig, TimeBucketConfig, TimeRange, WhereClause } from '@timescaledb/schemas';
import { buildWhereClause, escapeIdentifier } from '@timescaledb/utils';

export class TimeBucketBuilder {
  private statements: string[] = [];
  private metricStatements: string[] = [];
  private tableName: string;
  private timeColumn: string;
  private interval: string;
  private metrics: MetricConfig[];
  private params: any[] = [];

  constructor(tableName: string, timeColumn: string, config: TimeBucketConfig) {
    this.tableName = tableName;
    this.timeColumn = timeColumn;
    this.interval = config.interval;
    this.metrics = config.metrics;
  }

  private buildMetrics(): void {
    this.metrics.forEach((metric, index) => {
      const alias = metric.alias || `metric_${index}`;
      const column = metric.column ? escapeIdentifier(metric.column) : '*';

      switch (metric.type) {
        case 'count':
          this.metricStatements.push(`COUNT(${column}) as ${escapeIdentifier(alias)}`);
          break;
        case 'distinct_count':
          this.metricStatements.push(`COUNT(DISTINCT ${column}) as ${escapeIdentifier(alias)}`);
          break;
        default:
          throw new Error(`Unsupported metric type: ${metric.type}`);
      }
    });
  }

  private buildWhere(where: WhereClause, paramOffset = 1): { sql: string; params: any[] } {
    if (!where) {
      return { sql: '', params: [] };
    }

    const { sql, params } = buildWhereClause(where, paramOffset);

    return { sql: ` AND ${sql}`, params };
  }

  public build({ where, range }: { where?: WhereClause; range: TimeRange }): { sql: string; params: any[] } {
    if (!range) {
      throw new Error('TimeRange is required');
    }

    this.params = [];
    this.statements = [];
    this.metricStatements = [];

    this.buildMetrics();

    const tableName = escapeIdentifier(this.tableName);
    const timeColumn = escapeIdentifier(this.timeColumn);

    // First parameter is always the interval
    this.params.push(this.interval);
    const intervalParam = '$1';

    this.params.push(range.start, range.end);

    this.statements.push(`WITH time_buckets AS (`);
    this.statements.push(`  SELECT`);
    this.statements.push(`    time_bucket(${intervalParam}::interval, ${timeColumn}) AS interval,`);
    this.statements.push(`    ${this.metricStatements.join(',\n    ')}`);
    this.statements.push(`  FROM ${tableName}`);

    // Build WHERE clause starting from parameter index 4 (after interval and time range)
    const whereClause = this.buildWhere(where as WhereClause, 4);
    const whereStatement = `  WHERE ${timeColumn} >= $2 AND ${timeColumn} <= $3${whereClause.sql}`;
    this.statements.push(whereStatement);

    this.params.push(...whereClause.params);

    this.statements.push(`  GROUP BY interval`);
    this.statements.push(`  ORDER BY interval DESC`);
    this.statements.push(`)`);
    this.statements.push(`SELECT`);
    this.statements.push(`  TO_CHAR(interval, 'YYYY-MM-DD"T"HH24:MI:SS"Z"') as interval,`);

    const metricAliases = this.metrics.map((metric, index) => {
      const alias = metric.alias || `metric_${index}`;
      const escapedAlias = escapeIdentifier(alias);
      return `  ${escapedAlias} as ${escapedAlias}`;
    });

    this.statements.push(metricAliases.join(',\n'));
    this.statements.push(`FROM time_buckets;`);

    return {
      sql: this.statements.join('\n'),
      params: this.params,
    };
  }
}

================
File: packages/core/tests/__snapshots__/candlestick.test.ts.snap
================
// Jest Snapshot v1, https://goo.gl/fbAQLP

exports[`Candlestick Aggregation Candlestick Builder with Where Clause should generate candlestick query with time range and where clause 1`] = `
{
  "params": [
    "1 hour",
    2025-01-01T00:00:00.000Z,
    2025-01-02T00:00:00.000Z,
    "AAPL",
    1000000,
  ],
  "sql": "SELECT
  time_bucket($1::interval, "timestamp") as bucket_time,
  open(candlestick_agg("timestamp", "price", "volume")) as open,
  high(candlestick_agg("timestamp", "price", "volume")) as high,
  low(candlestick_agg("timestamp", "price", "volume")) as low,
  close(candlestick_agg("timestamp", "price", "volume")) as close,
  open_time(candlestick_agg("timestamp", "price", "volume")) as open_time,
  high_time(candlestick_agg("timestamp", "price", "volume")) as high_time,
  low_time(candlestick_agg("timestamp", "price", "volume")) as low_time,
  close_time(candlestick_agg("timestamp", "price", "volume")) as close_time
  ,volume(candlestick_agg("timestamp", "price", "volume")) as volume,
  vwap(candlestick_agg("timestamp", "price", "volume")) as vwap
FROM "stock_prices"
WHERE "timestamp" >= $2 AND "timestamp" <= $3 AND "symbol" = $4 AND "volume" > $5
GROUP BY bucket_time
ORDER BY bucket_time ASC;",
}
`;

exports[`Candlestick Aggregation Candlestick Builder with Where Clause should work without where clause 1`] = `
{
  "params": [
    "1 hour",
    2025-01-01T00:00:00.000Z,
    2025-01-02T00:00:00.000Z,
  ],
  "sql": "SELECT
  time_bucket($1::interval, "timestamp") as bucket_time,
  open(candlestick_agg("timestamp", "price")) as open,
  high(candlestick_agg("timestamp", "price")) as high,
  low(candlestick_agg("timestamp", "price")) as low,
  close(candlestick_agg("timestamp", "price")) as close,
  open_time(candlestick_agg("timestamp", "price")) as open_time,
  high_time(candlestick_agg("timestamp", "price")) as high_time,
  low_time(candlestick_agg("timestamp", "price")) as low_time,
  close_time(candlestick_agg("timestamp", "price")) as close_time
FROM "stock_prices"
WHERE "timestamp" >= $2 AND "timestamp" <= $3
GROUP BY bucket_time
ORDER BY bucket_time ASC;",
}
`;

exports[`Candlestick Aggregation should generate basic candlestick query 1`] = `
{
  "params": [
    "1 hour",
  ],
  "sql": "SELECT
  time_bucket($1::interval, "timestamp") as bucket_time,
  open(candlestick_agg("timestamp", "price")) as open,
  high(candlestick_agg("timestamp", "price")) as high,
  low(candlestick_agg("timestamp", "price")) as low,
  close(candlestick_agg("timestamp", "price")) as close,
  open_time(candlestick_agg("timestamp", "price")) as open_time,
  high_time(candlestick_agg("timestamp", "price")) as high_time,
  low_time(candlestick_agg("timestamp", "price")) as low_time,
  close_time(candlestick_agg("timestamp", "price")) as close_time
FROM "stock_prices"
GROUP BY bucket_time
ORDER BY bucket_time ASC;",
}
`;

exports[`Candlestick Aggregation should properly escape identifiers 1`] = `
{
  "params": [
    "1 hour",
  ],
  "sql": "SELECT
  time_bucket($1::interval, "time""stamp") as bucket_time,
  open(candlestick_agg("time""stamp", "price""value")) as open,
  high(candlestick_agg("time""stamp", "price""value")) as high,
  low(candlestick_agg("time""stamp", "price""value")) as low,
  close(candlestick_agg("time""stamp", "price""value")) as close,
  open_time(candlestick_agg("time""stamp", "price""value")) as open_time,
  high_time(candlestick_agg("time""stamp", "price""value")) as high_time,
  low_time(candlestick_agg("time""stamp", "price""value")) as low_time,
  close_time(candlestick_agg("time""stamp", "price""value")) as close_time
FROM "stock_prices"
GROUP BY bucket_time
ORDER BY bucket_time ASC;",
}
`;

================
File: packages/core/tests/__snapshots__/compression.test.ts.snap
================
// Jest Snapshot v1, https://goo.gl/fbAQLP

exports[`Compression stats should generate stats query with all fields 1`] = `
"SELECT
COALESCE(total_chunks, 0)::integer as total_chunks,
COALESCE(number_compressed_chunks, 0)::integer as compressed_chunks
FROM hypertable_compression_stats('my_table');"
`;

exports[`Compression stats should generate stats query with no fields selected 1`] = `
"SELECT
*
FROM hypertable_compression_stats('my_table');"
`;

exports[`Compression stats should generate stats query with only compressed_chunks 1`] = `
"SELECT
COALESCE(number_compressed_chunks, 0)::integer as compressed_chunks
FROM hypertable_compression_stats('my_table');"
`;

exports[`Compression stats should generate stats query with only total_chunks 1`] = `
"SELECT
COALESCE(total_chunks, 0)::integer as total_chunks
FROM hypertable_compression_stats('my_table');"
`;

================
File: packages/core/tests/__snapshots__/continuous-aggregate.test.ts.snap
================
// Jest Snapshot v1, https://goo.gl/fbAQLP

exports[`ContinuousAggregate aggregate functions should create view with average aggregate 1`] = `
"CREATE MATERIALIZED VIEW "avg_view" WITH (timescaledb.continuous) AS 
      SELECT
        time_bucket('1 hour', "time") as "bucket",
        AVG("amount") as "avg_amount"
      FROM "source_table"
      GROUP BY "bucket"
     WITH NO DATA;"
`;

exports[`ContinuousAggregate aggregate functions should create view with min/max aggregates 1`] = `
"CREATE MATERIALIZED VIEW "minmax_view" WITH (timescaledb.continuous) AS 
      SELECT
        time_bucket('1 hour', "time") as "bucket",
        MIN("amount") as "min_amount",
        MAX("amount") as "max_amount"
      FROM "source_table"
      GROUP BY "bucket"
     WITH NO DATA;"
`;

exports[`ContinuousAggregate aggregate functions should create view with sum aggregate 1`] = `
"CREATE MATERIALIZED VIEW "sum_view" WITH (timescaledb.continuous) AS 
      SELECT
        time_bucket('1 hour', "time") as "bucket",
        SUM("amount") as "total_amount"
      FROM "source_table"
      GROUP BY "bucket"
     WITH NO DATA;"
`;

exports[`ContinuousAggregate refresh policy should generate refresh policy SQL 1`] = `
"SELECT add_continuous_aggregate_policy('policy_view',
      start_offset => INTERVAL '2 days',
      end_offset => INTERVAL '1 hour',
      schedule_interval => INTERVAL '1 hour'
    );"
`;

exports[`ContinuousAggregate refresh policy should properly escape interval values in refresh policy 1`] = `
"SELECT add_continuous_aggregate_policy('policy_view',
      start_offset => INTERVAL '2 days''--injection',
      end_offset => INTERVAL '1 hour',
      schedule_interval => INTERVAL '1 hour'
    );"
`;

exports[`ContinuousAggregate refresh policy should remove refresh policy on down migration 1`] = `
[
  "SELECT remove_continuous_aggregate_policy('policy_view', if_exists => true);",
  "DROP MATERIALIZED VIEW IF EXISTS "policy_view";",
]
`;

================
File: packages/core/tests/__snapshots__/extension.test.ts.snap
================
// Jest Snapshot v1, https://goo.gl/fbAQLP

exports[`Extension down should drop an extension 1`] = `"DROP EXTENSION IF EXISTS timescaledb;"`;

exports[`Extension down should drop an extension with cascade 1`] = `"DROP EXTENSION IF EXISTS timescaledb CASCADE;"`;

exports[`Extension up should create an extension 1`] = `"CREATE EXTENSION IF NOT EXISTS timescaledb;"`;

exports[`Extension up should create an extension with cascade 1`] = `"CREATE EXTENSION IF NOT EXISTS timescaledb CASCADE;"`;

================
File: packages/core/tests/__snapshots__/hypertable.test.ts.snap
================
// Jest Snapshot v1, https://goo.gl/fbAQLP

exports[`Hypertable SQL Escaping should properly escape column names with special characters 1`] = `"SELECT create_hypertable('my_table', by_range('time-stamp"field'));"`;

exports[`Hypertable SQL Escaping should properly escape compression fields with special characters 1`] = `
"SELECT create_hypertable('my_table', by_range('time'));
ALTER TABLE "my_table" SET (
        timescaledb.compress,
        timescaledb.compress_orderby = "timestamp""field",
        timescaledb.compress_segmentby = "user-agent""field"
      );"
`;

exports[`Hypertable SQL Escaping should properly escape interval values with special characters 1`] = `
"SELECT create_hypertable('my_table', by_range('time'));
ALTER TABLE "my_table" SET (
        timescaledb.compress,
        timescaledb.compress_orderby = "time",
        timescaledb.compress_segmentby = "user_agent"
      );
SELECT add_compression_policy('my_table', INTERVAL '7 days''--injection');"
`;

exports[`Hypertable down should drop a hypertable 1`] = `"SELECT drop_chunks('my_table', NOW()::timestamp without time zone);"`;

exports[`Hypertable down should drop a hypertable with compression 1`] = `
"ALTER TABLE "my_table" SET (timescaledb.compress = false);
SELECT drop_chunks('my_table', NOW()::timestamp without time zone);"
`;

exports[`Hypertable down should drop a hypertable with compression policy 1`] = `
"ALTER TABLE "my_table" SET (timescaledb.compress = false);
SELECT remove_compression_policy('my_table', if_exists => true);
SELECT drop_chunks('my_table', NOW()::timestamp without time zone);"
`;

exports[`Hypertable inspect should inspect a hypertable 1`] = `
"SELECT
  EXISTS (
    SELECT FROM information_schema.tables 
    WHERE table_schema = 'public' 
    AND table_name = 'my_table'
  ) AS table_exists,
  EXISTS (
    SELECT FROM timescaledb_information.hypertables
    WHERE hypertable_name = 'my_table'
  ) AS is_hypertable"
`;

exports[`Hypertable up should create and build a hypertable 1`] = `"SELECT create_hypertable('my_table', by_range('time'));"`;

exports[`Hypertable up should create and build a hypertable with compression 1`] = `
"SELECT create_hypertable('my_table', by_range('time'));
ALTER TABLE "my_table" SET (
        timescaledb.compress,
        timescaledb.compress_orderby = "time",
        timescaledb.compress_segmentby = "user_agent"
      );"
`;

exports[`Hypertable up should create and build a hypertable with compression policy 1`] = `
"SELECT create_hypertable('my_table', by_range('time'));
ALTER TABLE "my_table" SET (
        timescaledb.compress,
        timescaledb.compress_orderby = "time",
        timescaledb.compress_segmentby = "user_agent"
      );
SELECT add_compression_policy('my_table', INTERVAL '1d');"
`;

================
File: packages/core/tests/__snapshots__/timebucket.test.ts.snap
================
// Jest Snapshot v1, https://goo.gl/fbAQLP

exports[`TimeBucket build should generate query with count metric 1`] = `
{
  "params": [
    "1 hour",
    2025-01-01T00:00:00.000Z,
    2025-01-02T00:00:00.000Z,
  ],
  "sql": "WITH time_buckets AS (
  SELECT
    time_bucket($1::interval, "time") AS interval,
    COUNT(*) as "total_count"
  FROM "my_table"
  WHERE "time" >= $2 AND "time" <= $3
  GROUP BY interval
  ORDER BY interval DESC
)
SELECT
  TO_CHAR(interval, 'YYYY-MM-DD"T"HH24:MI:SS"Z"') as interval,
  "total_count" as "total_count"
FROM time_buckets;",
}
`;

exports[`TimeBucket build should generate query with distinct count metric 1`] = `
{
  "params": [
    "1 hour",
    2025-01-01T00:00:00.000Z,
    2025-01-02T00:00:00.000Z,
  ],
  "sql": "WITH time_buckets AS (
  SELECT
    time_bucket($1::interval, "time") AS interval,
    COUNT(DISTINCT "user_id") as "unique_users"
  FROM "my_table"
  WHERE "time" >= $2 AND "time" <= $3
  GROUP BY interval
  ORDER BY interval DESC
)
SELECT
  TO_CHAR(interval, 'YYYY-MM-DD"T"HH24:MI:SS"Z"') as interval,
  "unique_users" as "unique_users"
FROM time_buckets;",
}
`;

exports[`TimeBucket build should generate query with interval 1 day 1`] = `
{
  "interval": "1 day",
  "params": [
    "1 day",
    2025-01-01T00:00:00.000Z,
    2025-01-02T00:00:00.000Z,
  ],
  "sql": "WITH time_buckets AS (
  SELECT
    time_bucket($1::interval, "time") AS interval,
    COUNT(*) as "total_count"
  FROM "my_table"
  WHERE "time" >= $2 AND "time" <= $3
  GROUP BY interval
  ORDER BY interval DESC
)
SELECT
  TO_CHAR(interval, 'YYYY-MM-DD"T"HH24:MI:SS"Z"') as interval,
  "total_count" as "total_count"
FROM time_buckets;",
}
`;

exports[`TimeBucket build should generate query with interval 1 hour 1`] = `
{
  "interval": "1 hour",
  "params": [
    "1 hour",
    2025-01-01T00:00:00.000Z,
    2025-01-02T00:00:00.000Z,
  ],
  "sql": "WITH time_buckets AS (
  SELECT
    time_bucket($1::interval, "time") AS interval,
    COUNT(*) as "total_count"
  FROM "my_table"
  WHERE "time" >= $2 AND "time" <= $3
  GROUP BY interval
  ORDER BY interval DESC
)
SELECT
  TO_CHAR(interval, 'YYYY-MM-DD"T"HH24:MI:SS"Z"') as interval,
  "total_count" as "total_count"
FROM time_buckets;",
}
`;

exports[`TimeBucket build should generate query with interval 1 minute 1`] = `
{
  "interval": "1 minute",
  "params": [
    "1 minute",
    2025-01-01T00:00:00.000Z,
    2025-01-02T00:00:00.000Z,
  ],
  "sql": "WITH time_buckets AS (
  SELECT
    time_bucket($1::interval, "time") AS interval,
    COUNT(*) as "total_count"
  FROM "my_table"
  WHERE "time" >= $2 AND "time" <= $3
  GROUP BY interval
  ORDER BY interval DESC
)
SELECT
  TO_CHAR(interval, 'YYYY-MM-DD"T"HH24:MI:SS"Z"') as interval,
  "total_count" as "total_count"
FROM time_buckets;",
}
`;

exports[`TimeBucket build should generate query with interval 1 month 1`] = `
{
  "interval": "1 month",
  "params": [
    "1 month",
    2025-01-01T00:00:00.000Z,
    2025-01-02T00:00:00.000Z,
  ],
  "sql": "WITH time_buckets AS (
  SELECT
    time_bucket($1::interval, "time") AS interval,
    COUNT(*) as "total_count"
  FROM "my_table"
  WHERE "time" >= $2 AND "time" <= $3
  GROUP BY interval
  ORDER BY interval DESC
)
SELECT
  TO_CHAR(interval, 'YYYY-MM-DD"T"HH24:MI:SS"Z"') as interval,
  "total_count" as "total_count"
FROM time_buckets;",
}
`;

exports[`TimeBucket build should generate query with interval 1 week 1`] = `
{
  "interval": "1 week",
  "params": [
    "1 week",
    2025-01-01T00:00:00.000Z,
    2025-01-02T00:00:00.000Z,
  ],
  "sql": "WITH time_buckets AS (
  SELECT
    time_bucket($1::interval, "time") AS interval,
    COUNT(*) as "total_count"
  FROM "my_table"
  WHERE "time" >= $2 AND "time" <= $3
  GROUP BY interval
  ORDER BY interval DESC
)
SELECT
  TO_CHAR(interval, 'YYYY-MM-DD"T"HH24:MI:SS"Z"') as interval,
  "total_count" as "total_count"
FROM time_buckets;",
}
`;

exports[`TimeBucket build should generate query with multiple metrics 1`] = `
{
  "params": [
    "1 hour",
    2025-01-01T00:00:00.000Z,
    2025-01-02T00:00:00.000Z,
  ],
  "sql": "WITH time_buckets AS (
  SELECT
    time_bucket($1::interval, "time") AS interval,
    COUNT(*) as "total_events",
    COUNT(DISTINCT "user_id") as "unique_users",
    COUNT(DISTINCT "session_id") as "unique_sessions"
  FROM "my_table"
  WHERE "time" >= $2 AND "time" <= $3
  GROUP BY interval
  ORDER BY interval DESC
)
SELECT
  TO_CHAR(interval, 'YYYY-MM-DD"T"HH24:MI:SS"Z"') as interval,
  "total_events" as "total_events",
  "unique_users" as "unique_users",
  "unique_sessions" as "unique_sessions"
FROM time_buckets;",
}
`;

exports[`TimeBucket error handling should fail with invalid interval format: Invalid interval format 1`] = `
{
  "params": [
    "invalid interval",
    2025-01-01T00:00:00.000Z,
    2025-01-02T00:00:00.000Z,
  ],
  "sql": "WITH time_buckets AS (
  SELECT
    time_bucket($1::interval, "time") AS interval,
    COUNT(*) as "total_count"
  FROM "my_table"
  WHERE "time" >= $2 AND "time" <= $3
  GROUP BY interval
  ORDER BY interval DESC
)
SELECT
  TO_CHAR(interval, 'YYYY-MM-DD"T"HH24:MI:SS"Z"') as interval,
  "total_count" as "total_count"
FROM time_buckets;",
}
`;

exports[`TimeBucket where clause should generate query with comparison operator 1`] = `
{
  "params": [
    "1 hour",
    2025-01-01T00:00:00.000Z,
    2025-01-02T00:00:00.000Z,
    25,
  ],
  "sql": "WITH time_buckets AS (
  SELECT
    time_bucket($1::interval, "time") AS interval,
    COUNT(*) as "total_count"
  FROM "my_table"
  WHERE "time" >= $2 AND "time" <= $3 AND "temperature" > $4
  GROUP BY interval
  ORDER BY interval DESC
)
SELECT
  TO_CHAR(interval, 'YYYY-MM-DD"T"HH24:MI:SS"Z"') as interval,
  "total_count" as "total_count"
FROM time_buckets;",
}
`;

exports[`TimeBucket where clause should generate query with simple where condition 1`] = `
{
  "params": [
    "1 hour",
    2025-01-01T00:00:00.000Z,
    2025-01-02T00:00:00.000Z,
    "123",
  ],
  "sql": "WITH time_buckets AS (
  SELECT
    time_bucket($1::interval, "time") AS interval,
    COUNT(*) as "total_count"
  FROM "my_table"
  WHERE "time" >= $2 AND "time" <= $3 AND "user_id" = $4
  GROUP BY interval
  ORDER BY interval DESC
)
SELECT
  TO_CHAR(interval, 'YYYY-MM-DD"T"HH24:MI:SS"Z"') as interval,
  "total_count" as "total_count"
FROM time_buckets;",
}
`;

================
File: packages/core/tests/candlestick.test.ts
================
import { describe, it, expect } from '@jest/globals';
import { TimescaleDB } from '../src';

describe('Candlestick Aggregation', () => {
  it('should generate basic candlestick query', () => {
    const candlestick = TimescaleDB.createCandlestickAggregate('stock_prices', {
      time_column: 'timestamp',
      price_column: 'price',
      bucket_interval: '1 hour',
    });

    const sql = candlestick.build({});
    expect(sql).toMatchSnapshot();
  });

  it('should properly escape identifiers', () => {
    const candlestick = TimescaleDB.createCandlestickAggregate('stock_prices', {
      time_column: 'time"stamp',
      price_column: 'price"value',
      bucket_interval: '1 hour',
    });

    const sql = candlestick.build();
    expect(sql).toMatchSnapshot();
  });

  describe('Candlestick Builder with Where Clause', () => {
    it('should generate candlestick query with time range and where clause', () => {
      const builder = TimescaleDB.createCandlestickAggregate('stock_prices', {
        time_column: 'timestamp',
        price_column: 'price',
        volume_column: 'volume',
        bucket_interval: '1 hour',
      });

      const range = {
        start: new Date('2025-01-01T00:00:00Z'),
        end: new Date('2025-01-02T00:00:00Z'),
      };

      const where = {
        symbol: 'AAPL',
        volume: { '>': 1000000 },
      };

      const sql = builder.build({ range, where });
      expect(sql).toMatchSnapshot();
    });

    it('should work without where clause', () => {
      const builder = TimescaleDB.createCandlestickAggregate('stock_prices', {
        time_column: 'timestamp',
        price_column: 'price',
        bucket_interval: '1 hour',
      });

      const range = {
        start: new Date('2025-01-01T00:00:00Z'),
        end: new Date('2025-01-02T00:00:00Z'),
      };

      const sql = builder.build({ range });
      expect(sql).toMatchSnapshot();
    });
  });
});

================
File: packages/core/tests/compression.test.ts
================
import { describe, it, expect } from '@jest/globals';
import { TimescaleDB } from '../src';
import { CreateHypertableOptions } from '@timescaledb/schemas';

describe('Compression', () => {
  const defaultOptions: CreateHypertableOptions = {
    by_range: {
      column_name: 'time',
    },
  };

  describe('stats', () => {
    it('should generate stats query with all fields', () => {
      const hypertable = TimescaleDB.createHypertable('my_table', defaultOptions);
      const sql = hypertable
        .compression()
        .stats({
          select: {
            total_chunks: true,
            compressed_chunks: true,
          },
        })
        .build();

      expect(sql).toMatchSnapshot();
    });

    it('should generate stats query with only total_chunks', () => {
      const hypertable = TimescaleDB.createHypertable('my_table', defaultOptions);
      const sql = hypertable
        .compression()
        .stats({
          select: {
            total_chunks: true,
          },
        })
        .build();

      expect(sql).toMatchSnapshot();
    });

    it('should generate stats query with only compressed_chunks', () => {
      const hypertable = TimescaleDB.createHypertable('my_table', defaultOptions);
      const sql = hypertable
        .compression()
        .stats({
          select: {
            compressed_chunks: true,
          },
        })
        .build();

      expect(sql).toMatchSnapshot();
    });

    it('should generate stats query with no fields selected', () => {
      const hypertable = TimescaleDB.createHypertable('my_table', defaultOptions);
      const sql = hypertable
        .compression()
        .stats({
          select: {},
        })
        .build();

      expect(sql).toMatchSnapshot();
    });

    it('should fail when no stats options provided', () => {
      const hypertable = TimescaleDB.createHypertable('my_table', defaultOptions);
      expect(() => {
        // @ts-expect-error - Testing runtime error
        hypertable.compression().stats().build();
      }).toThrow();
    });

    it('should fail with invalid select options', () => {
      const hypertable = TimescaleDB.createHypertable('my_table', defaultOptions);
      expect(() => {
        hypertable
          .compression()
          .stats({
            select: {
              // @ts-ignore
              invalid_field: true,
            },
          })
          .build();
      }).toThrow();
    });
  });
});

================
File: packages/core/tests/continuous-aggregate.test.ts
================
import { describe, it, expect } from '@jest/globals';
import { TimescaleDB } from '../src';
import { CreateContinuousAggregateOptions, AggregateType } from '@timescaledb/schemas';

describe('ContinuousAggregate', () => {
  describe('aggregate functions', () => {
    it('should create view with sum aggregate', () => {
      const options: CreateContinuousAggregateOptions = {
        name: 'sum_view',
        bucket_interval: '1 hour',
        time_column: 'time',
        aggregates: {
          total_amount: {
            type: AggregateType.Sum,
            column: 'amount',
            column_alias: 'total_amount',
          },
        },
      };

      const cagg = TimescaleDB.createContinuousAggregate('sum_view', 'source_table', options);
      const sql = cagg.up().build();
      expect(sql).toMatchSnapshot();
    });

    it('should create view with average aggregate', () => {
      const options: CreateContinuousAggregateOptions = {
        name: 'avg_view',
        bucket_interval: '1 hour',
        time_column: 'time',
        aggregates: {
          avg_amount: {
            type: AggregateType.Avg,
            column: 'amount',
            column_alias: 'avg_amount',
          },
        },
      };

      const cagg = TimescaleDB.createContinuousAggregate('avg_view', 'source_table', options);
      const sql = cagg.up().build();
      expect(sql).toMatchSnapshot();
    });

    it('should create view with min/max aggregates', () => {
      const options: CreateContinuousAggregateOptions = {
        name: 'minmax_view',
        bucket_interval: '1 hour',
        time_column: 'time',
        aggregates: {
          min_amount: {
            type: AggregateType.Min,
            column: 'amount',
            column_alias: 'min_amount',
          },
          max_amount: {
            type: AggregateType.Max,
            column: 'amount',
            column_alias: 'max_amount',
          },
        },
      };

      const cagg = TimescaleDB.createContinuousAggregate('minmax_view', 'source_table', options);
      const sql = cagg.up().build();
      expect(sql).toMatchSnapshot();
    });
  });

  describe('refresh policy', () => {
    const baseOptions: CreateContinuousAggregateOptions = {
      name: 'test_view',
      bucket_interval: '1 hour',
      time_column: 'time',
      aggregates: {
        count: {
          type: AggregateType.Count,
          column_alias: 'total_count',
        },
      },
      refresh_policy: {
        start_offset: '2 days',
        end_offset: '1 hour',
        schedule_interval: '1 hour',
      },
    };

    it('should generate refresh policy SQL', () => {
      const cagg = TimescaleDB.createContinuousAggregate('policy_view', 'source_table', baseOptions);
      const policy = cagg.up().getRefreshPolicy();
      expect(policy).toMatchSnapshot();
    });

    it('should not generate refresh policy when not configured', () => {
      const options = {
        name: 'no_policy_view',
        bucket_interval: '1 hour',
        time_column: 'time',
        aggregates: {
          count: {
            type: AggregateType.Count,
            column_alias: 'total_count',
          },
        },
      };
      const cagg = TimescaleDB.createContinuousAggregate(
        'no_policy_view',
        'source_table',
        options as CreateContinuousAggregateOptions,
      );
      const policy = cagg.up().getRefreshPolicy();
      expect(policy).toBeNull();
    });

    it('should remove refresh policy on down migration', () => {
      const cagg = TimescaleDB.createContinuousAggregate('policy_view', 'source_table', baseOptions);
      const sql = cagg.down().build();
      expect(sql).toMatchSnapshot();
    });

    it('should properly escape interval values in refresh policy', () => {
      const options = {
        ...baseOptions,
        refresh_policy: {
          start_offset: "2 days'--injection",
          end_offset: '1 hour',
          schedule_interval: '1 hour',
        },
      };

      const cagg = TimescaleDB.createContinuousAggregate('policy_view', 'source_table', options);
      const policy = cagg.up().getRefreshPolicy();
      expect(policy).toMatchSnapshot();
    });
  });
});

================
File: packages/core/tests/extension.test.ts
================
import { describe, it } from '@jest/globals';
import { TimescaleDB, ExtensionErrors } from '../src';

describe('Extension', () => {
  it('should fail when creating an extension without invalid options', () => {
    expect(() => {
      TimescaleDB.createExtension({
        // @ts-ignore
        invalidOption: 'invalid',
      });
    }).toThrow(ExtensionErrors.INVALID_OPTIONS);
  });

  describe('up', () => {
    it('should create an extension', () => {
      const extension = TimescaleDB.createExtension();

      const sql = extension.up().build();
      expect(sql).toMatchSnapshot();
    });

    it('should create an extension with cascade', () => {
      const extension = TimescaleDB.createExtension({
        should_cascade: true,
      });

      const sql = extension.up().build();
      expect(sql).toMatchSnapshot();
    });
  });

  describe('down', () => {
    it('should drop an extension', () => {
      const extension = TimescaleDB.createExtension();

      const sql = extension.down().build();
      expect(sql).toMatchSnapshot();
    });

    it('should drop an extension with cascade', () => {
      const extension = TimescaleDB.createExtension({
        should_cascade: true,
      });

      const sql = extension.down().build();
      expect(sql).toMatchSnapshot();
    });
  });
});

================
File: packages/core/tests/hypertable.test.ts
================
import { describe, it } from '@jest/globals';
import { TimescaleDB, HypertableErrors } from '../src';
import { CreateHypertableOptions } from '@timescaledb/schemas';

describe('Hypertable', () => {
  it('should fail when creating a hypertable without a name', () => {
    expect(() => {
      // @ts-ignore
      TimescaleDB.createHypertable('');
    }).toThrow(HypertableErrors.NAME_REQUIRED);
  });

  it('should fail when creating a hypertable without options', () => {
    expect(() => {
      // @ts-ignore
      TimescaleDB.createHypertable('my_table');
    }).toThrow(HypertableErrors.OPTIONS_REQUIRED);
  });

  it('should fail when creating a hypertable with invalid options', () => {
    expect(() => {
      // @ts-ignore
      TimescaleDB.createHypertable('my_table', {});
    }).toThrow(HypertableErrors.INVALID_OPTIONS);
  });

  describe('should validate table names correctly', () => {
    // Invalid names
    const invalidNames = [
      '2invalid',
      'invalid-name',
      'invalid.name.table',
      'invalid$name',
      'some-2rand}}(*&^name',
      '_invalidstart',
    ];

    const validNames = ['valid_table_name', 'schema1.table1'];

    it.each(invalidNames)('should fail when creating a hypertable with invalid name: %s', (name) => {
      expect(() =>
        TimescaleDB.createHypertable(name, {
          by_range: { column_name: 'time' },
        }),
      ).toThrow(HypertableErrors.INVALID_NAME);
    });

    it.each(validNames)('should create a hypertable with valid name: %s', (name) => {
      expect(() =>
        TimescaleDB.createHypertable(name, {
          by_range: { column_name: 'time' },
        }),
      ).not.toThrow();
    });
  });

  describe('up', () => {
    it('should create and build a hypertable', () => {
      const options: CreateHypertableOptions = {
        by_range: {
          column_name: 'time',
        },
      };

      const sql = TimescaleDB.createHypertable('my_table', options).up().build();
      expect(sql).toMatchSnapshot();
    });

    it('should create and build a hypertable with compression', () => {
      const options: CreateHypertableOptions = {
        by_range: {
          column_name: 'time',
        },
        compression: {
          compress: true,
          compress_orderby: 'time',
          compress_segmentby: 'user_agent',
        },
      };

      const sql = TimescaleDB.createHypertable('my_table', options).up().build();
      expect(sql).toMatchSnapshot();
    });

    it('should create and build a hypertable with compression policy', () => {
      const options: CreateHypertableOptions = {
        by_range: {
          column_name: 'time',
        },
        compression: {
          compress: true,
          compress_orderby: 'time',
          compress_segmentby: 'user_agent',
          policy: {
            schedule_interval: '1d',
          },
        },
      };

      const sql = TimescaleDB.createHypertable('my_table', options).up().build();
      expect(sql).toMatchSnapshot();
    });
  });

  describe('inspect', () => {
    it('should inspect a hypertable', () => {
      const sql = TimescaleDB.createHypertable('my_table', {
        by_range: {
          column_name: 'time',
        },
      })
        .inspect()
        .build();

      expect(sql).toMatchSnapshot();
    });
  });

  describe('down', () => {
    it('should drop a hypertable', () => {
      const options: CreateHypertableOptions = {
        by_range: {
          column_name: 'time',
        },
      };

      const sql = TimescaleDB.createHypertable('my_table', options).down().build();
      expect(sql).toMatchSnapshot();
    });

    it('should drop a hypertable with compression', () => {
      const options: CreateHypertableOptions = {
        by_range: {
          column_name: 'time',
        },
        compression: {
          compress: true,
          compress_orderby: 'time',
          compress_segmentby: 'user_agent',
        },
      };

      const sql = TimescaleDB.createHypertable('my_table', options).down().build();
      expect(sql).toMatchSnapshot();
    });

    it('should drop a hypertable with compression policy', () => {
      const options: CreateHypertableOptions = {
        by_range: {
          column_name: 'time',
        },
        compression: {
          compress: true,
          compress_orderby: 'time',
          compress_segmentby: 'user_agent',
          policy: {
            schedule_interval: '1d',
          },
        },
      };

      const sql = TimescaleDB.createHypertable('my_table', options).down().build();
      expect(sql).toMatchSnapshot();
    });
  });

  describe('SQL Escaping', () => {
    it('should properly escape column names with special characters', () => {
      const options: CreateHypertableOptions = {
        by_range: {
          column_name: 'time-stamp"field',
        },
      };

      const sql = TimescaleDB.createHypertable('my_table', options).up().build();
      expect(sql).toMatchSnapshot();
    });

    it('should properly escape compression fields with special characters', () => {
      const options: CreateHypertableOptions = {
        by_range: {
          column_name: 'time',
        },
        compression: {
          compress: true,
          compress_orderby: 'timestamp"field',
          compress_segmentby: 'user-agent"field',
        },
      };

      const sql = TimescaleDB.createHypertable('my_table', options).up().build();
      expect(sql).toMatchSnapshot();
    });

    it('should properly escape interval values with special characters', () => {
      const options: CreateHypertableOptions = {
        by_range: {
          column_name: 'time',
        },
        compression: {
          compress: true,
          compress_orderby: 'time',
          compress_segmentby: 'user_agent',
          policy: {
            schedule_interval: "7 days'--injection",
          },
        },
      };

      const sql = TimescaleDB.createHypertable('my_table', options).up().build();
      expect(sql).toMatchSnapshot();
    });
  });
});

================
File: packages/core/tests/timebucket.test.ts
================
import { describe, it, expect } from '@jest/globals';
import { TimescaleDB } from '../src';
import { CreateHypertableOptions } from '@timescaledb/schemas';

describe('TimeBucket', () => {
  const defaultOptions: CreateHypertableOptions = {
    by_range: {
      column_name: 'time',
    },
  };

  const baseTime = new Date('2025-01-01T00:00:00Z');
  const timeRange = {
    start: baseTime,
    end: new Date(baseTime.getTime() + 24 * 60 * 60 * 1000), // 1 day later
  };

  describe('build', () => {
    it('should generate query with count metric', () => {
      const hypertable = TimescaleDB.createHypertable('my_table', defaultOptions);
      const { sql, params } = hypertable
        .timeBucket({
          interval: '1 hour',
          metrics: [
            {
              type: 'count',
              alias: 'total_count',
            },
          ],
        })
        .build({
          range: timeRange,
        });

      expect({ sql, params }).toMatchSnapshot();
    });

    it('should generate query with distinct count metric', () => {
      const hypertable = TimescaleDB.createHypertable('my_table', defaultOptions);
      const { sql, params } = hypertable
        .timeBucket({
          interval: '1 hour',
          metrics: [
            {
              type: 'distinct_count',
              column: 'user_id',
              alias: 'unique_users',
            },
          ],
        })
        .build({
          range: timeRange,
        });

      expect({ sql, params }).toMatchSnapshot();
    });

    it('should generate query with multiple metrics', () => {
      const hypertable = TimescaleDB.createHypertable('my_table', defaultOptions);
      const { sql, params } = hypertable
        .timeBucket({
          interval: '1 hour',
          metrics: [
            {
              type: 'count',
              alias: 'total_events',
            },
            {
              type: 'distinct_count',
              column: 'user_id',
              alias: 'unique_users',
            },
            {
              type: 'distinct_count',
              column: 'session_id',
              alias: 'unique_sessions',
            },
          ],
        })
        .build({
          range: timeRange,
        });

      expect({ sql, params }).toMatchSnapshot();
    });

    it.each(['1 minute', '1 hour', '1 day', '1 week', '1 month'])(
      'should generate query with interval %s',
      (interval) => {
        const hypertable = TimescaleDB.createHypertable('my_table', defaultOptions);

        const { sql, params } = hypertable
          .timeBucket({
            interval,
            metrics: [
              {
                type: 'count',
                alias: 'total_count',
              },
            ],
          })
          .build({
            range: timeRange,
          });

        expect({ sql, params, interval }).toMatchSnapshot();
      },
    );
  });

  describe('where clause', () => {
    it('should generate query with simple where condition', () => {
      const hypertable = TimescaleDB.createHypertable('my_table', defaultOptions);
      const { sql, params } = hypertable
        .timeBucket({
          interval: '1 hour',
          metrics: [
            {
              type: 'count',
              alias: 'total_count',
            },
          ],
        })
        .build({
          range: timeRange,
          where: {
            user_id: '123',
          },
        });

      expect({ sql, params }).toMatchSnapshot();
      expect(params).toHaveLength(4); // interval, start, end, user_id
    });

    it('should generate query with comparison operator', () => {
      const hypertable = TimescaleDB.createHypertable('my_table', defaultOptions);
      const { sql, params } = hypertable
        .timeBucket({
          interval: '1 hour',
          metrics: [
            {
              type: 'count',
              alias: 'total_count',
            },
          ],
        })
        .build({
          range: timeRange,
          where: {
            temperature: { '>': 25 },
          },
        });

      expect({ sql, params }).toMatchSnapshot();
      expect(params).toHaveLength(4); // interval, start, end, temperature value
    });
  });

  describe('error handling', () => {
    it('should throw error for invalid metric type', () => {
      const hypertable = TimescaleDB.createHypertable('my_table', defaultOptions);

      expect(() => {
        hypertable
          .timeBucket({
            interval: '1 hour',
            metrics: [
              {
                // @ts-ignore
                type: 'invalid_type',
                alias: 'invalid_metric',
              },
            ],
          })
          .build({
            range: timeRange,
          });
      }).toThrow('Unsupported metric type: invalid_type');
    });

    it('should fail with invalid interval format', () => {
      const hypertable = TimescaleDB.createHypertable('my_table', defaultOptions);

      // This will fail at runtime when PostgreSQL tries to parse the interval
      const { sql, params } = hypertable
        .timeBucket({
          interval: 'invalid interval',
          metrics: [
            {
              type: 'count',
              alias: 'total_count',
            },
          ],
        })
        .build({
          range: timeRange,
        });

      expect({ sql, params }).toMatchSnapshot('Invalid interval format');
    });
  });
});

================
File: packages/core/babel.config.js
================
module.exports = {
  presets: [['@babel/preset-env', { targets: { node: 'current' } }], '@babel/preset-typescript'],
};

================
File: packages/core/jest.config.js
================
/** @type {import('jest').Config} */
module.exports = {
  preset: 'ts-jest',
  testEnvironment: 'node',
  roots: ['<rootDir>/tests'],
  transform: {
    '^.+\\.tsx?$': [
      'ts-jest',
      {
        tsconfig: 'tsconfig.test.json',
      },
    ],
  },
  moduleFileExtensions: ['ts', 'tsx', 'js', 'jsx', 'json', 'node'],
  testMatch: ['**/tests/**/*.test.ts', '**/tests/**/*-tests.ts'],
  verbose: true,
  testTimeout: 10000,
  clearMocks: true,
  restoreMocks: true,
};

================
File: packages/core/package.json
================
{
  "name": "@timescaledb/core",
  "version": "0.0.0-alpha.1",
  "main": "dist/index.js",
  "types": "dist/index.d.ts",
  "homepage": "https://github.com/timescale/timescaledb-ts",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/timescale/timescaledb-ts.git"
  },
  "keywords": [
    "timescaledb",
    "timeseries",
    "database",
    "query",
    "typescript",
    "core",
    "genration",
    "builder"
  ],
  "author": "Timescale",
  "license": "MIT",
  "bugs": {
    "url": "https://github.com/timescale/timescaledb-ts/issues"
  },
  "typesVersions": {
    "*": {
      "*": [
        "src/*"
      ]
    }
  },
  "files": [
    "dist"
  ],
  "scripts": {
    "build": "tsc",
    "test": "jest --runInBand"
  },
  "dependencies": {
    "@timescaledb/schemas": "workspace:^",
    "@timescaledb/utils": "workspace:^"
  },
  "devDependencies": {}
}

================
File: packages/core/README.md
================
# @timescaledb/core

The `@timescaledb/core` package provides fundamental building blocks for working with TimescaleDB in TypeScript/JavaScript applications. It includes SQL query builders and utilities for managing hypertables, continuous aggregates, compression, and other TimescaleDB-specific features.

## Installation

```bash
npm install @timescaledb/core
```

## Quick Start

```typescript
import { TimescaleDB } from '@timescaledb/core';

// Create a hypertable
const hypertable = TimescaleDB.createHypertable('measurements', {
  by_range: { column_name: 'time' },
});

// Generate SQL to create the hypertable
const sql = hypertable.up().build();
// SELECT create_hypertable('measurements', by_range('time'));
```

## API Reference

### TimescaleDB Class

The main entry point for all functionality.

#### Creating a Hypertable

```typescript
const hypertable = TimescaleDB.createHypertable('table_name', {
  by_range: {
    column_name: 'time',
  },
  compression: {
    compress: true,
    compress_orderby: 'time',
    compress_segmentby: 'device_id',
    policy: {
      schedule_interval: '7 days',
    },
  },
});

// Generate creation SQL
const createSql = hypertable.up().build();

// Generate drop SQL
const dropSql = hypertable.down().build();

// Check if hypertable exists
const checkSql = hypertable.inspect().build();
```

#### Creating a Continuous Aggregate

```typescript
const aggregate = TimescaleDB.createContinuousAggregate('daily_summary', 'raw_data', {
  bucket_interval: '1 day',
  time_column: 'time',
  aggregates: {
    avg_temp: {
      type: 'avg',
      column: 'temperature',
      column_alias: 'average_temperature',
    },
    max_temp: {
      type: 'max',
      column: 'temperature',
      column_alias: 'max_temperature',
    },
  },
  refresh_policy: {
    start_offset: '3 days',
    end_offset: '1 hour',
    schedule_interval: '1 hour',
  },
});

// Generate creation SQL
const createSql = aggregate.up().build();

// Generate drop SQL
const dropSql = aggregate.down().build();
```

#### Managing Compression

```typescript
const hypertable = TimescaleDB.createHypertable('measurements', {
  by_range: { column_name: 'time' },
  compression: {
    compress: true,
    compress_orderby: 'time',
    compress_segmentby: 'device_id',
  },
});

// Get compression statistics
const statsSql = hypertable
  .compression()
  .stats({
    select: {
      total_chunks: true,
      compressed_chunks: true,
    },
  })
  .build();
```

#### Time Bucket Queries

```typescript
const hypertable = TimescaleDB.createHypertable('measurements', {
  by_range: { column_name: 'time' },
});

// Basic time bucket query
const { sql, params } = hypertable
  .timeBucket({
    interval: '1 hour',
    metrics: [
      { type: 'count', alias: 'total' },
      { type: 'distinct_count', column: 'device_id', alias: 'unique_devices' },
    ],
  })
  .build({
    range: {
      start: new Date('2025-01-01'),
      end: new Date('2025-02-01'),
    },
  });

// With where clause filtering
const { sql: filteredSql, params: filteredParams } = hypertable
  .timeBucket({
    interval: '1 hour',
    metrics: [
      { type: 'count', alias: 'total' },
      { type: 'distinct_count', column: 'device_id', alias: 'unique_devices' },
    ],
  })
  .build({
    range: {
      start: new Date('2025-01-01'),
      end: new Date('2025-02-01'),
    },
    where: {
      device_id: 'sensor-123', // Simple equality
      temperature: { '>': 25 }, // Comparison operator
      status: { IN: ['active', 'warning'] }, // IN clause
      location: { 'NOT IN': ['zone-a', 'zone-b'] }, // NOT IN clause
    },
  });
```

#### Creating Candlestick Aggregates

```typescript
const candlestick = TimescaleDB.createCandlestickAggregate('stock_prices', {
  time_column: 'timestamp',
  price_column: 'price',
  volume_column: 'volume', // optional
  bucket_interval: '1 hour', // defaults to '1 hour'
});

// Basic candlestick query
const { sql, params } = candlestick.build({
  range: {
    start: new Date('2025-01-01'),
    end: new Date('2025-01-02'),
  },
});

// With where clause filtering
const { sql: filteredSql, params: filteredParams } = candlestick.build({
  range: {
    start: new Date('2025-01-01'),
    end: new Date('2025-01-02'),
  },
  where: {
    symbol: 'AAPL',
    volume: { '>': 1000000 },
    exchange: { IN: ['NYSE', 'NASDAQ'] },
  },
});

// Returns candlestick data:
// bucket_time, open, high, low, close, volume, vwap, etc.
const results = await query(sql, params);
```

## Examples

Check out our example projects:

- [Node.js + TypeORM Example](https://github.com/timescale/timescaledb-ts/tree/main/examples/node-typeorm)
- [Node.js + Sequelize Example](https://github.com/timescale/timescaledb-ts/tree/main/examples/node-sequelize)

## Advanced Usage

### Custom SQL Generation

All builders support granular SQL generation:

```typescript
const hypertable = TimescaleDB.createHypertable('measurements', {
  by_range: { column_name: 'time' },
});

// Generate only the hypertable creation SQL
const createSql = hypertable.up().build();

// Generate only the compression SQL
const compressionSql = hypertable
  .compression()
  .stats({ select: { total_chunks: true } })
  .build();
```

### Migration Integration

The package works well with migration systems:

```typescript
// In a migration file
import { TimescaleDB } from '@timescaledb/core';

export async function up(queryRunner) {
  // Create extension
  const extension = TimescaleDB.createExtension();
  await queryRunner.query(extension.up().build());

  // Create hypertable
  const hypertable = TimescaleDB.createHypertable('measurements', {
    by_range: { column_name: 'time' },
  });
  await queryRunner.query(hypertable.up().build());
}

export async function down(queryRunner) {
  // Drop hypertable
  const hypertable = TimescaleDB.createHypertable('measurements', {
    by_range: { column_name: 'time' },
  });
  await queryRunner.query(hypertable.down().build());

  // Drop extension
  const extension = TimescaleDB.createExtension();
  await queryRunner.query(extension.down().build());
}
```

================
File: packages/core/tsconfig.json
================
{
  "compilerOptions": {
    "target": "ES2020",
    "lib": ["esnext"],
    "allowJs": true,
    "sourceMap": true,
    "declaration": true,
    "skipLibCheck": true,
    "esModuleInterop": true,
    "allowSyntheticDefaultImports": true,
    "strict": true,
    "module": "commonjs",
    "moduleResolution": "node",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "noEmit": false,
    "outDir": "./dist",
    "baseUrl": ".",
    "paths": {
      "@timescaledb/schemas": ["../schemas/dist"],
      "@timescaledb/utils": ["../utils/dist"]
    }
  },
  "include": ["src"],
  "exclude": ["node_modules", "dist"]
}

================
File: packages/core/tsconfig.test.json
================
{
  "extends": "./tsconfig.json",
  "compilerOptions": {
    "types": ["jest", "node"],
    "module": "commonjs",
    "target": "ES2020",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "moduleResolution": "node",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "noEmit": true,
    "outDir": "./dist-test",
    "paths": {
      "@timescaledb/schemas": ["../schemas/dist"],
      "@timescaledb/utils": ["../utils/dist"]
    }
  },
  "include": ["src/**/*.ts", "tests/**/*.ts"],
  "exclude": ["node_modules"]
}

================
File: packages/schemas/src/by-range.ts
================
import { z } from 'zod';

export const ByRangeSchema = z.object({
  column_name: z.string(),
});
export type ByRange = z.infer<typeof ByRangeSchema>;

================
File: packages/schemas/src/candlestick.ts
================
import { z } from 'zod';
import { TimeRangeSchema } from './time-range';
import { WhereClauseSchema } from './where';

export const CandlestickAggregateOptionsSchema = z.object({
  price_column: z.string(),
  time_column: z.string(),
  volume_column: z.string().optional(),
  bucket_interval: z.string().optional().default('1 hour'),
});

export type CandlestickAggregateOptions = z.infer<typeof CandlestickAggregateOptionsSchema>;

export const CandlesticksResultSchema = z.object({
  bucket_time: z.date(),
  open: z.number(),
  high: z.number(),
  low: z.number(),
  close: z.number(),
  volume: z.number().optional(),
  vwap: z.number().optional(),
  open_time: z.date(),
  high_time: z.date(),
  low_time: z.date(),
  close_time: z.date(),
});

export type CandlesticksResult = z.infer<typeof CandlesticksResultSchema>;

export type GetCandlesticksOptions = z.infer<typeof GetCandlesticksOptionsSchema>;

export const GetCandlesticksOptionsSchema = z.object({
  timeRange: TimeRangeSchema,
  config: CandlestickAggregateOptionsSchema,
  where: WhereClauseSchema.optional(),
});

================
File: packages/schemas/src/compression.ts
================
import { z } from 'zod';

// https://docs.timescale.com/api/latest/compression/hypertable_compression_stats/
export const CompressionStatsSchema = z.object({
  total_chunks: z.number().optional(),
  compressed_chunks: z.number().optional(),
  number_compressed_chunks: z.number().optional(),
  // ... TODO: add the rest of the fields
});
export type CompressionStats = z.infer<typeof CompressionStatsSchema>;

export const CompressionSelectSchema = z
  .object({
    total_chunks: z.boolean().optional(),
    compressed_chunks: z.boolean().optional(),
  })
  .strict();
export type CompressionSelect = z.infer<typeof CompressionSelectSchema>;

// https://docs.timescale.com/api/latest/compression/add_compression_policy/
export const SetCompressionPolicyOptionsSchema = z.object({
  schedule_interval: z.string(),
});

// https://docs.timescale.com/api/latest/compression/alter_table_compression/
export const SetCompressionOptionsSchema = z.object({
  compress: z.boolean(),
  compress_orderby: z.string(),
  compress_segmentby: z.string(),
  policy: SetCompressionPolicyOptionsSchema.optional(),
});
export type SetCompressionOptions = z.infer<typeof SetCompressionOptionsSchema>;

================
File: packages/schemas/src/continuous-aggregate.ts
================
import { z } from 'zod';

export enum AggregateType {
  Count = 'count',
  CountDistinct = 'count_distinct',
  Sum = 'sum',
  Avg = 'avg',
  Min = 'min',
  Max = 'max',
  Bucket = 'bucket',
}
export const AggregateTypeSchema = z.nativeEnum(AggregateType);

export const AggregateColumnOptionsSchema = z.object({
  type: AggregateTypeSchema,
  column: z.string().optional(),
  column_alias: z.string().optional(),
});
export type AggregateColumnOptions = z.infer<typeof AggregateColumnOptionsSchema>;

export const RefreshPolicySchema = z.object({
  start_offset: z.string(),
  end_offset: z.string(),
  schedule_interval: z.string(),
});

export const CreateContinuousAggregateOptionsSchema = z
  .object({
    name: z.string(),
    bucket_interval: z.string(),
    time_column: z.string().optional(),
    refresh_policy: RefreshPolicySchema.optional(),
    aggregates: z.record(AggregateColumnOptionsSchema).optional(),
  })
  .strict();

export type CreateContinuousAggregateOptions = z.infer<typeof CreateContinuousAggregateOptionsSchema>;

================
File: packages/schemas/src/extension.ts
================
import { z } from 'zod';

export const CreateExtensionOptionsSchema = z
  .object({
    should_cascade: z.boolean().optional(),
    version: z.string().optional(),
  })
  .strict();
export type CreateExtensionOptions = z.infer<typeof CreateExtensionOptionsSchema>;

================
File: packages/schemas/src/hypertable.ts
================
import { z } from 'zod';
import { ByRangeSchema } from './by-range';
import { SetCompressionOptionsSchema } from './compression';

export const CreateHypertableOptionsSchema = z.object({
  by_range: ByRangeSchema.required(),
  compression: SetCompressionOptionsSchema.optional(),
});
export type CreateHypertableOptions = z.infer<typeof CreateHypertableOptionsSchema>;

================
File: packages/schemas/src/index.ts
================
export * from './compression';
export * from './time-range';
export * from './hypertable';
export * from './by-range';
export * from './extension';
export * from './time-bucket';
export * from './continuous-aggregate';
export * from './candlestick';
export * from './where';

================
File: packages/schemas/src/time-bucket.ts
================
import { z } from 'zod';
import { ByRangeSchema } from './by-range';
import { TimeRange } from './time-range';
import { WhereClause } from './where';

export const TimeBucketMetricTypeSchema = z.enum(['count', 'distinct_count']);
export type TimeBucketMetricType = z.infer<typeof TimeBucketMetricTypeSchema>;

export const MetricConfigSchema = z.object({
  type: TimeBucketMetricTypeSchema,
  column: z.string().optional(),
  alias: z.string().optional(),
});
export type MetricConfig = z.infer<typeof MetricConfigSchema>;

export const TimeBucketConfigSchema = z.object({
  interval: z.string(),
  metrics: z.array(MetricConfigSchema),
});
export type TimeBucketConfig = z.infer<typeof TimeBucketConfigSchema>;

export const TimeBucketRowSchema = z
  .object({
    interval: z.string(),
  })
  .and(z.record(z.string(), z.union([z.number(), z.string()])));
export type TimeBucketRow = z.infer<typeof TimeBucketRowSchema>;

export const TimeBucketResultSchema = z.array(TimeBucketRowSchema);
export type TimeBucketResult = z.infer<typeof TimeBucketResultSchema>;

export const GetTimeBucketOptionsSchema = z.object({
  range: ByRangeSchema.required(),
  where: z.string().optional(),
  config: TimeBucketConfigSchema.required(),
});

export type EntityColumns<T> = {
  [K in keyof T]: T[K] extends Function ? never : K;
}[keyof T];

export interface TimeBucketMetric<T> {
  type: TimeBucketMetricType;
  column?: EntityColumns<T>;
  alias?: string;
}

export interface TimeBucketOptions<T> {
  timeRange: TimeRange;
  bucket: {
    interval: string;
    metrics: TimeBucketMetric<T>[];
  };
  where?: WhereClause;
}

================
File: packages/schemas/src/time-range.ts
================
import { z } from 'zod';

export const TimeRangeSchema = z.object({
  start: z.date(),
  end: z.date(),
});

export type TimeRange = z.infer<typeof TimeRangeSchema>;

================
File: packages/schemas/src/where.ts
================
import { z } from 'zod';

export const WhereOperatorSchema = z.enum(['=', '>', '<', '>=', '<=', 'IN', 'NOT IN']);
export type WhereOperator = z.infer<typeof WhereOperatorSchema>;

export const WhereValueSchema = z.union([
  z.string(),
  z.number(),
  z.date(),
  z.array(z.union([z.string(), z.number(), z.date()])),
]);
export type WhereValue = z.infer<typeof WhereValueSchema>;

export const WhereConditionSchema = z.union([WhereValueSchema, z.record(WhereOperatorSchema, WhereValueSchema)]);
export type WhereCondition = z.infer<typeof WhereConditionSchema>;

export const WhereClauseSchema = z.record(z.string(), WhereConditionSchema);
export type WhereClause = z.infer<typeof WhereClauseSchema>;

================
File: packages/schemas/package.json
================
{
  "name": "@timescaledb/schemas",
  "version": "0.0.0-alpha.1",
  "main": "dist/index.js",
  "types": "dist/index.d.ts",
  "homepage": "https://github.com/timescale/timescaledb-ts",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/timescale/timescaledb-ts.git"
  },
  "keywords": [
    "timescaledb",
    "timeseries",
    "database",
    "typescript",
    "schemas",
    "zod",
    "types"
  ],
  "author": "Timescale",
  "license": "MIT",
  "bugs": {
    "url": "https://github.com/timescale/timescaledb-ts/issues"
  },
  "typesVersions": {
    "*": {
      "*": [
        "src/*"
      ]
    }
  },
  "files": [
    "dist"
  ],
  "scripts": {
    "build": "tsc"
  },
  "dependencies": {
    "zod": "^3.24.1"
  }
}

================
File: packages/schemas/README.md
================
# @timescaledb/schemas

This package contains Zod schemas and types for all TimescaleDB objects.

================
File: packages/schemas/tsconfig.json
================
{
  "compilerOptions": {
    "target": "ES2020",
    "lib": ["esnext"],
    "allowJs": true,
    "sourceMap": true,
    "declaration": true,
    "skipLibCheck": true,
    "esModuleInterop": true,
    "allowSyntheticDefaultImports": true,
    "strict": true,
    "module": "commonjs",
    "moduleResolution": "node",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "noEmit": false,
    "outDir": "./dist",
    "paths": {
      "@timescaledb/*": ["../*/src"]
    }
  },
  "include": ["src"]
}

================
File: packages/typeorm/src/decorators/AggregateColumn.ts
================
/// <reference types="reflect-metadata" />
import { ViewColumn } from 'typeorm';
import { AggregateColumnOptions } from '@timescaledb/schemas';

export const AGGREGATE_COLUMN_METADATA_KEY = Symbol('timescale:aggregate-field');

export function AggregateColumn(options: AggregateColumnOptions) {
  return function (target: any, propertyKey: string | symbol) {
    const aggregates = Reflect.getMetadata(AGGREGATE_COLUMN_METADATA_KEY, target) || {};

    aggregates[propertyKey] = {
      type: options.type,
      column: options.column,
      column_alias: propertyKey,
    };

    Reflect.defineMetadata(AGGREGATE_COLUMN_METADATA_KEY, aggregates, target);
    Reflect.defineMetadata(AGGREGATE_COLUMN_METADATA_KEY, aggregates, target.constructor);

    ViewColumn({
      name: propertyKey.toString(),
      transformer: {
        from: (value: string) => Number(value),
        to: (value: number) => value,
      },
    })(target, propertyKey);

    const storageKey = `_${propertyKey.toString()}`;
    Object.defineProperty(target, propertyKey, {
      get: function () {
        return this[storageKey];
      },
      set: function (value) {
        this[storageKey] = value;
      },
      enumerable: false,
      configurable: true,
    });

    return target;
  };
}

================
File: packages/typeorm/src/decorators/BucketColumn.ts
================
/// <reference types="reflect-metadata" />
import { ViewColumn } from 'typeorm';

export const BUCKET_COLUMN_METADATA_KEY = Symbol('timescale:bucket-column');

export interface BucketColumnOptions {
  source_column: string;
}

export function BucketColumn(options: BucketColumnOptions) {
  return function (target: any, propertyKey: string | symbol) {
    const existingBucketColumn = Reflect.getMetadata(BUCKET_COLUMN_METADATA_KEY, target.constructor);

    if (existingBucketColumn) {
      throw new Error('Only one @BucketColumn is allowed per continuous aggregate');
    }

    Reflect.defineMetadata(
      BUCKET_COLUMN_METADATA_KEY,
      {
        propertyKey,
        source_column: options.source_column,
      },
      target.constructor,
    );

    ViewColumn()(target, propertyKey);

    const storageKey = `_${String(propertyKey)}`;
    Object.defineProperty(target, propertyKey, {
      get: function () {
        return this[storageKey];
      },
      set: function (value) {
        this[storageKey] = value;
      },
      enumerable: true,
      configurable: true,
    });
  };
}

export function validateBucketColumn(target: Function): { propertyKey: string | symbol; source_column: string } {
  const metadata = Reflect.getMetadata(BUCKET_COLUMN_METADATA_KEY, target);

  if (!metadata) {
    throw new Error('Continuous aggregates must have exactly one column decorated with @BucketColumn');
  }

  return metadata;
}

================
File: packages/typeorm/src/decorators/ContinuousAggregate.ts
================
/// <reference types="reflect-metadata" />
import { CreateContinuousAggregateOptions } from '@timescaledb/schemas';
import { getMetadataArgsStorage, ViewEntity } from 'typeorm';
import { AGGREGATE_COLUMN_METADATA_KEY } from './AggregateColumn';
import { validateBucketColumn } from './BucketColumn';

export const CONTINUOUS_AGGREGATE_METADATA_KEY = Symbol('timescale:continuous_aggregate');

export interface ContinuousAggregateMetadata {
  sourceModel: Function;
  options: CreateContinuousAggregateOptions;
  bucketColumn: string | symbol;
}

export function ContinuousAggregate<T extends { new (...args: any[]): any }>(
  sourceModel: Function,
  options: Omit<CreateContinuousAggregateOptions, 'time_column'>,
) {
  return function (target: T): T {
    const bucketMetadata = validateBucketColumn(target);

    const sourceMetadata = getMetadataArgsStorage().tables.find((table) => table.target === sourceModel);
    if (!sourceMetadata) {
      throw new Error('Source model is not a TypeORM entity');
    }

    const metadata: ContinuousAggregateMetadata = {
      sourceModel,
      options: {
        ...options,
        time_column: bucketMetadata.source_column,
      },
      bucketColumn: bucketMetadata.propertyKey,
    };

    Reflect.defineMetadata(CONTINUOUS_AGGREGATE_METADATA_KEY, metadata, target);
    Reflect.defineMetadata(AGGREGATE_COLUMN_METADATA_KEY, sourceModel, target);

    target.prototype.toJSON = function () {
      const jsonObj: { [key: string]: any } = {};
      for (const key in this) {
        if (key.startsWith('_')) {
          jsonObj[key.substring(1)] = this[key];
        } else {
          jsonObj[key] = this[key];
        }
      }
      return jsonObj;
    };

    return ViewEntity({
      name: options.name,
      materialized: true,
      synchronize: false,
    })(target) as T;
  };
}

================
File: packages/typeorm/src/decorators/Hypertable.ts
================
/// <reference types="reflect-metadata" />
import { CreateHypertableOptions } from '@timescaledb/schemas';
import { timescaleMethods } from '../repository/TimescaleRepository';

export const HYPERTABLE_METADATA_KEY = Symbol('timescale:hypertable');

export function Hypertable(options: CreateHypertableOptions) {
  return function (target: Function) {
    Reflect.defineMetadata(HYPERTABLE_METADATA_KEY, options, target);

    Reflect.defineMetadata('typeorm:repository:extend', timescaleMethods, target);
  };
}

================
File: packages/typeorm/src/hooks/migration.ts
================
import { DataSource, getMetadataArgsStorage } from 'typeorm';
import { TimescaleDB } from '@timescaledb/core';
import { HYPERTABLE_METADATA_KEY } from '../decorators/Hypertable';
import { timescaleMethods } from '../repository/TimescaleRepository';
import { CONTINUOUS_AGGREGATE_METADATA_KEY, ContinuousAggregateMetadata } from '../decorators/ContinuousAggregate';
import { AGGREGATE_COLUMN_METADATA_KEY } from '../decorators/AggregateColumn';
import { AggregateColumnOptions } from '@timescaledb/schemas';
import { validateBucketColumn } from '../decorators/BucketColumn';

const originalRunMigrations = DataSource.prototype.runMigrations;
const originalUndoLastMigration = DataSource.prototype.undoLastMigration;
const originalSynchronize = DataSource.prototype.synchronize;
const originalInitialize = DataSource.prototype.initialize;

DataSource.prototype.initialize = async function () {
  const connection = await originalInitialize.call(this);

  for (const entity of this.entityMetadatas) {
    const hypertableOptions = Reflect.getMetadata(HYPERTABLE_METADATA_KEY, entity.target);
    const aggregateOptions = Reflect.getMetadata(CONTINUOUS_AGGREGATE_METADATA_KEY, entity.target);

    if (hypertableOptions || aggregateOptions) {
      const repository = this.getRepository(entity.target);
      Object.assign(repository, timescaleMethods);
    }
  }

  return connection;
};

async function setupTimescaleExtension(dataSource: DataSource) {
  try {
    const extension = TimescaleDB.createExtension();
    await dataSource.query(extension.up().build());
  } catch (error) {
    if (!(error as Error).message.includes('extension "timescaledb" already exists')) {
      throw error;
    }
  }
}

DataSource.prototype.runMigrations = async function (options?: { transaction?: 'all' | 'none' | 'each' }) {
  const migrations = await originalRunMigrations.call(this, options);

  await setupTimescaleExtension(this);
  await setupHypertables(this);
  await setupContinuousAggregates(this);

  return migrations;
};

DataSource.prototype.undoLastMigration = async function (options?: { transaction?: 'all' | 'none' | 'each' }) {
  await removeTimescaleObjects(this);
  return originalUndoLastMigration.call(this, options);
};

DataSource.prototype.synchronize = async function (dropBeforeSync: boolean = false) {
  if (dropBeforeSync) {
    await removeTimescaleObjects(this);
  }

  await originalSynchronize.call(this, dropBeforeSync);
  await setupTimescaleObjects(this);
};

async function setupHypertables(dataSource: DataSource) {
  const entities = dataSource.entityMetadatas;

  for await (const entity of entities) {
    const options = Reflect.getMetadata(HYPERTABLE_METADATA_KEY, entity.target);

    if (options) {
      const hypertable = TimescaleDB.createHypertable(entity.tableName, options);
      const hypertableCheck = await dataSource.query(hypertable.inspect().build());

      if (!hypertableCheck[0].table_exists) {
        continue;
      }

      if (hypertableCheck[0].is_hypertable) {
        continue;
      }

      await dataSource.query(hypertable.up().build());

      const repository = dataSource.getRepository(entity.target);
      Object.assign(repository, timescaleMethods);
    }
  }
}

async function removeHypertables(dataSource: DataSource) {
  const entities = dataSource.entityMetadatas;

  for await (const entity of entities) {
    const options = Reflect.getMetadata(HYPERTABLE_METADATA_KEY, entity.target);

    if (options) {
      const hypertable = TimescaleDB.createHypertable(entity.tableName, options);
      const hypertableCheck = await dataSource.query(hypertable.inspect().build());

      if (!hypertableCheck[0].is_hypertable) {
        continue;
      }

      await dataSource.query(hypertable.down().build());
    }
  }
}

async function setupTimescaleObjects(dataSource: DataSource) {
  if (!dataSource.isInitialized) {
    throw new Error('DataSource must be initialized before setting up TimescaleDB objects');
  }

  const extension = TimescaleDB.createExtension();
  const extensionSql = extension.up().build();

  try {
    await dataSource.query(extensionSql);
  } catch (error) {
    if (!(error as Error).message.includes('extension "timescaledb" already exists')) {
      throw error;
    }
  }

  await setupHypertables(dataSource);
}

async function removeContinuousAggregates(dataSource: DataSource) {
  const entities = dataSource.entityMetadatas;

  for (const entity of entities) {
    const aggregateMetadata = Reflect.getMetadata(
      CONTINUOUS_AGGREGATE_METADATA_KEY,
      entity.target,
    ) as ContinuousAggregateMetadata;

    if (!aggregateMetadata) continue;

    const aggregate = TimescaleDB.createContinuousAggregate(
      entity.tableName,
      '', // Source table not needed for down()
      aggregateMetadata.options,
    );

    const statements = aggregate.down().build();
    for (const sql of statements) {
      await dataSource.query(sql);
    }
  }
}

async function removeTimescaleObjects(dataSource: DataSource) {
  if (!dataSource.isInitialized) {
    throw new Error('DataSource must be initialized before removing TimescaleDB objects');
  }

  await removeContinuousAggregates(dataSource);
  await removeHypertables(dataSource);
}

async function validateAggregateColumns(dataSource: DataSource) {
  for (const entity of dataSource.entityMetadatas) {
    // Try both the prototype and constructor
    const aggregateColumns =
      // @ts-ignore
      Reflect.getMetadata(AGGREGATE_COLUMN_METADATA_KEY, entity.target.prototype) ||
      Reflect.getMetadata(AGGREGATE_COLUMN_METADATA_KEY, entity.target);

    if (aggregateColumns) {
      const continuousAggregateMetadata = Reflect.getMetadata(CONTINUOUS_AGGREGATE_METADATA_KEY, entity.target);
      if (!continuousAggregateMetadata) {
        throw new Error(`Class ${entity.name} uses @AggregateColumn but is not decorated with @ContinuousAggregate`);
      }

      const { sourceModel } = continuousAggregateMetadata;
      const sourceMetadata = getMetadataArgsStorage().tables.find((table) => table.target === sourceModel);
      if (!sourceMetadata) {
        throw new Error(`Source model for ${entity.name} is not a valid TypeORM entity`);
      }
    }
  }
}

async function setupContinuousAggregates(dataSource: DataSource) {
  const entities = dataSource.entityMetadatas;

  for (const entity of entities) {
    const aggregateMetadata = Reflect.getMetadata(
      CONTINUOUS_AGGREGATE_METADATA_KEY,
      entity.target,
    ) as ContinuousAggregateMetadata;

    if (!aggregateMetadata) continue;

    const sourceMetadata = dataSource.getMetadata(aggregateMetadata.sourceModel);
    const sourceTableName = sourceMetadata.tableName;

    const sourceOptions = Reflect.getMetadata(HYPERTABLE_METADATA_KEY, aggregateMetadata.sourceModel);
    const sourceHypertable = TimescaleDB.createHypertable(sourceTableName, sourceOptions);

    const hypertableCheck = await dataSource.query(sourceHypertable.inspect().build());
    if (!hypertableCheck[0].is_hypertable) continue;

    await validateAggregateColumns(dataSource);

    const aggregateColumns =
      // @ts-ignore
      Reflect.getMetadata(AGGREGATE_COLUMN_METADATA_KEY, entity.target.prototype) ||
      (Reflect.getMetadata(AGGREGATE_COLUMN_METADATA_KEY, entity.target) as Record<string, AggregateColumnOptions>);

    if (!aggregateColumns) {
      throw new Error('No aggregates defined for continuous aggregate');
    }

    // @ts-ignore
    const bucketMetadata = validateBucketColumn(entity.target);

    // @ts-ignore
    aggregateMetadata.options.aggregates = {
      [bucketMetadata.propertyKey.toString()]: {
        type: 'bucket',
        column: bucketMetadata.source_column,
        column_alias: bucketMetadata.propertyKey.toString(),
      },
      ...aggregateMetadata.options.aggregates,
      ...Object.entries(aggregateColumns as Record<string, AggregateColumnOptions>).reduce(
        (acc: { [key: string]: AggregateColumnOptions }, [key, value]: [string, AggregateColumnOptions]) => {
          acc[key] = {
            type: value.type,
            column: value.column,
            column_alias: key,
          };
          return acc;
        },
        {},
      ),
    };

    const aggregate = TimescaleDB.createContinuousAggregate(
      entity.tableName,
      sourceTableName,
      aggregateMetadata.options,
    );

    const exists = await dataSource.query(aggregate.inspect().build());
    if (!exists[0].hypertable_exists) {
      await dataSource.query(aggregate.up().build());

      const refreshPolicy = aggregate.up().getRefreshPolicy();
      if (refreshPolicy) {
        await dataSource.query(refreshPolicy);
      }
    }
  }
}

================
File: packages/typeorm/src/repository/get-candlesticks.ts
================
import { Repository, ObjectLiteral } from 'typeorm';
import { TimescaleDB } from '@timescaledb/core';
import { GetCandlesticksOptions, CandlesticksResult } from '@timescaledb/schemas';
import { HYPERTABLE_METADATA_KEY } from '../decorators/Hypertable';

export async function getCandlesticks<T extends ObjectLiteral>(
  this: Repository<T>,
  options: GetCandlesticksOptions,
): Promise<CandlesticksResult[]> {
  const target = this.target as Function;
  const hypertableOptions = Reflect.getMetadata(HYPERTABLE_METADATA_KEY, target);

  if (!hypertableOptions?.by_range?.column_name) {
    throw new Error('Entity is not a hypertable');
  }

  const candlestick = TimescaleDB.createCandlestickAggregate(this.metadata.tableName, {
    ...options.config,
    time_column: hypertableOptions.by_range.column_name,
  });

  const { sql, params } = candlestick.build({
    range: options.timeRange,
    where: options.where,
  });

  const results = await this.query(sql, params);

  return results.map((row: any) => ({
    bucket_time: new Date(row.bucket_time),
    open: Number(row.open),
    high: Number(row.high),
    low: Number(row.low),
    close: Number(row.close),
    open_time: new Date(row.open_time),
    high_time: new Date(row.high_time),
    low_time: new Date(row.low_time),
    close_time: new Date(row.close_time),
    ...(row.volume
      ? {
          volume: Number(row.volume),
          vwap: Number(row.vwap),
        }
      : {}),
  }));
}

================
File: packages/typeorm/src/repository/get-compression-stats.ts
================
import { Repository, ObjectLiteral } from 'typeorm';
import { TimescaleDB } from '@timescaledb/core';
import { CompressionStats } from '@timescaledb/schemas';
import { HYPERTABLE_METADATA_KEY } from '../decorators/Hypertable';

export async function getCompressionStats(this: Repository<ObjectLiteral>): Promise<CompressionStats> {
  try {
    const target = this.target as Function;
    const options = Reflect.getMetadata(HYPERTABLE_METADATA_KEY, target);
    if (!options) {
      throw new Error(`Entity is not a hypertable`);
    }

    const hypertable = TimescaleDB.createHypertable(this.metadata.tableName, options);

    const sql = hypertable
      .compression()
      .stats({
        select: {
          total_chunks: true,
          compressed_chunks: true,
        },
      })
      .build();

    const [stats] = await this.query(sql);

    return {
      compressed_chunks: stats?.compressed_chunks ?? 0,
      total_chunks: stats?.total_chunks ?? 0,
    };
  } catch (error) {
    console.error('Error getting compression stats:', error);
    return {
      compressed_chunks: 0,
      total_chunks: 0,
    };
  }
}

================
File: packages/typeorm/src/repository/get-time-bucket.ts
================
import { HYPERTABLE_METADATA_KEY } from '../decorators/Hypertable';
import { Repository, ObjectLiteral } from 'typeorm';
import { TimescaleDB } from '@timescaledb/core';
import { TimeBucketConfig, TimeBucketConfigSchema, TimeBucketOptions } from '@timescaledb/schemas';

export async function getTimeBucket<T extends ObjectLiteral>(
  this: Repository<T>,
  options: TimeBucketOptions<T>,
): Promise<
  Array<{
    interval: string;
    [key: string]: number | string;
  }>
> {
  const target = this.target as Function;
  const hypertableOptions = Reflect.getMetadata(HYPERTABLE_METADATA_KEY, target);

  if (!hypertableOptions) {
    throw new Error(`Entity is not a hypertable`);
  }

  const hypertable = TimescaleDB.createHypertable(this.metadata.tableName, hypertableOptions);

  const builderConfig: TimeBucketConfig = {
    interval: options.bucket.interval,
    metrics: options.bucket.metrics.map((metric) => ({
      type: metric.type,
      column: metric.column?.toString(),
      alias: metric.alias,
    })),
  };

  TimeBucketConfigSchema.parse(builderConfig);

  const { sql, params } = hypertable.timeBucket(builderConfig).build({
    range: {
      start: options.timeRange.start,
      end: options.timeRange.end,
    },
    where: options.where,
  });
  const results = await this.query(sql, params);

  return results.map((row: any) => {
    const formattedRow: { [key: string]: number | string } = {
      interval: row.interval,
    };

    options.bucket.metrics.forEach((metric) => {
      const alias = metric.alias || 'count';
      formattedRow[alias] = Number(row[alias]);
    });

    return formattedRow;
  });
}

================
File: packages/typeorm/src/repository/TimescaleRepository.ts
================
import { Repository, ObjectLiteral } from 'typeorm';
import { CandlesticksResult, CompressionStats, GetCandlesticksOptions, TimeBucketOptions } from '@timescaledb/schemas';
import { getCompressionStats } from './get-compression-stats';
import { getTimeBucket } from './get-time-bucket';
import { getCandlesticks } from './get-candlesticks';

type GetCandlesticks = <T extends ObjectLiteral>(
  this: Repository<T>,
  options: GetCandlesticksOptions,
) => Promise<CandlesticksResult[]>;

type GetCompressionStats = () => Promise<CompressionStats>;

type GetTimeBucket = <T extends ObjectLiteral>(
  options: TimeBucketOptions<T>,
) => Promise<
  Array<{
    interval: string;
    [key: string]: number | string;
  }>
>;

export interface TimescaleRepository<Entity extends ObjectLiteral> extends Repository<Entity> {
  getCompressionStats: GetCompressionStats;
  getTimeBucket: GetTimeBucket;
  getCandlesticks: GetCandlesticks;
}

export const timescaleMethods = {
  getCompressionStats,
  getTimeBucket,
  getCandlesticks,
};

// Module augmentation for TypeORM
declare module 'typeorm' {
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  interface Repository<Entity extends ObjectLiteral> {
    getCompressionStats: GetCompressionStats;
    getTimeBucket: GetTimeBucket;
    getCandlesticks: GetCandlesticks;
  }
}

================
File: packages/typeorm/src/index.ts
================
import './hooks/migration';

export { Hypertable, HYPERTABLE_METADATA_KEY } from './decorators/Hypertable';
export { ContinuousAggregate, CONTINUOUS_AGGREGATE_METADATA_KEY } from './decorators/ContinuousAggregate';
export { AggregateColumn, AGGREGATE_COLUMN_METADATA_KEY } from './decorators/AggregateColumn';
export { BucketColumn, BUCKET_COLUMN_METADATA_KEY } from './decorators/BucketColumn';

export * from './repository/TimescaleRepository';

================
File: packages/typeorm/babel.config.js
================
module.exports = {
  presets: [['@babel/preset-env', { targets: { node: 'current' } }], '@babel/preset-typescript'],
};

================
File: packages/typeorm/jest.config.js
================
/** @type {import('jest').Config} */
module.exports = {
  preset: 'ts-jest',
  testEnvironment: 'node',
  roots: ['<rootDir>/tests'],
  transform: {
    '^.+\\.tsx?$': [
      'ts-jest',
      {
        tsconfig: 'tsconfig.test.json',
      },
    ],
  },
  moduleFileExtensions: ['ts', 'tsx', 'js', 'jsx', 'json', 'node'],
  testMatch: ['**/tests/**/*.test.ts', '**/tests/**/*-tests.ts'],
  verbose: true,
  testTimeout: 10000,
  clearMocks: true,
  restoreMocks: true,
};

================
File: packages/typeorm/package.json
================
{
  "name": "@timescaledb/typeorm",
  "version": "0.0.0-alpha.1",
  "main": "dist/index.js",
  "types": "dist/index.d.ts",
  "homepage": "https://github.com/timescale/timescaledb-ts",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/timescale/timescaledb-ts.git"
  },
  "keywords": [
    "timescaledb",
    "timeseries",
    "database",
    "typescript",
    "typeorm",
    "orm",
    "plugin",
    "integration",
    "adapter",
    "wrapper"
  ],
  "author": "Timescale",
  "license": "MIT",
  "bugs": {
    "url": "https://github.com/timescale/timescaledb-ts/issues"
  },
  "typesVersions": {
    "*": {
      "*": [
        "src/*"
      ]
    }
  },
  "files": [
    "dist"
  ],
  "scripts": {
    "build": "tsc"
  },
  "dependencies": {
    "@timescaledb/core": "workspace:^",
    "@timescaledb/schemas": "workspace:^",
    "reflect-metadata": "^0.2.2",
    "typeorm": "^0.3.20"
  }
}

================
File: packages/typeorm/README.md
================
# @timescaledb/typeorm

This is the official TimescaleDB plugin for TypeORM.

## Installation

```bash
npm install typeorm @timescaledb/typeorm
```

## Hypertables

### Creating a Hypertable

Use the `@Hypertable` decorator to define your time-series tables:

See:

- https://docs.timescale.com/use-timescale/latest/hypertables/create/

Usage:

```typescript
import { Entity, PrimaryColumn } from 'typeorm';
import { Hypertable } from '@timescaledb/typeorm';

@Entity('page_loads')
@Hypertable({
  by_range: {
    column_name: 'time',
  },
  compression: {
    compress: true,
    compress_orderby: 'time',
    compress_segmentby: 'user_agent',
    policy: {
      schedule_interval: '7 days',
    },
  },
})
export class PageLoad {
  @PrimaryColumn({ name: 'user_agent', type: 'varchar' })
  userAgent!: string;

  @PrimaryColumn({ type: 'timestamp' })
  time!: Date;
}
```

## Hypertable Methods

### `getTimeBucket`

This method allows you to perform time bucketing queries on the hypertable:

See:

- https://docs.timescale.com/api/latest/hyperfunctions/time_bucket/

Usage:

```typescript
import { AppDataSource } from './data-source';
import { PageLoad } from './models/PageLoad';

const repository = AppDataSource.getRepository(PageLoad);

// Basic time bucket query
const stats = await repository.getTimeBucket({
  timeRange: {
    start,
    end,
  },
  bucket: {
    interval: '1 hour',
    metrics: [
      { type: 'count', alias: 'count' },
      { type: 'distinct_count', column: 'user_agent', alias: 'unique_users' },
    ],
  },
});

// With where clause filtering
const filteredStats = await repository.getTimeBucket({
  timeRange: {
    start,
    end,
  },
  bucket: {
    interval: '1 hour',
    metrics: [
      { type: 'count', alias: 'count' },
      { type: 'distinct_count', column: 'user_agent', alias: 'unique_users' },
    ],
  },
  where: {
    user_agent: 'Mozilla/5.0', // Simple equality
    session_duration: { '>': 3600 }, // Comparison operator
    status_code: { IN: [200, 201, 204] }, // IN clause
    country: { 'NOT IN': ['US', 'CA'] }, // NOT IN clause
  },
});

console.log(stats);
// [
//   { interval: '2021-01-01T00:00:00Z', count: 10, unique_users: 5 },
//   { interval: '2021-01-01T01:00:00Z', count: 20, unique_users: 10 },
//   { interval: '2021-01-01T02:00:00Z', count: 30, unique_users: 15 },
//   ...
// ]
```

### `getCompressionStats`

Get compression statistics for a hypertable:

See:

- https://docs.timescale.com/api/latest/compression/hypertable_compression_stats/

Usage:

```typescript
import { AppDataSource } from './data-source';
import { PageLoad } from './models/PageLoad';

const repository = AppDataSource.getRepository(PageLoad);
const stats = await repository.getCompressionStats();

console.log(stats);
// {
//   total_chunks: 100,
//   compressed_chunks: 50,
//   number_compressed_chunks: 10,
// }
```

### `getCandlesticks`

See:

- [Candlestick ](#Candlesticks)

## Continuous Aggregates

### Creating a Continuous Aggregate

Use the `@ContinuousAggregate` decorator to define materialized views that automatically maintain aggregates over time windows, plus the `@AggregateColumn` decorator to define the columns in the materialized view:

See:

- https://docs.timescale.com/use-timescale/latest/continuous-aggregates/create-a-continuous-aggregate/

Usage:

```ts
import { ViewColumn } from 'typeorm';
import { ContinuousAggregate, AggregateColumn, BucketColumn } from '@timescaledb/typeorm';
import { PageLoad } from './PageLoad';

@ContinuousAggregate(PageLoad, {
  name: 'hourly_page_views',
  bucket_interval: '1 hour',
  refresh_policy: {
    start_offset: '3 days',
    end_offset: '1 hour',
    schedule_interval: '1 hour',
  },
})
export class HourlyPageViews {
  @BucketColumn({
    source_column: 'time',
  })
  bucket!: Date;

  @AggregateColumn({
    type: 'count',
  })
  total_views!: number;

  @AggregateColumn({
    type: 'unique_count',
    column: 'user_agent',
  })
  unique_users!: number;
}
```

### Using Continuous Aggregates

Query the materialized view like a regular entity:

See:

- https://orkhan.gitbook.io/typeorm/docs/view-entities

Usage:

```ts
const hourlyStats = await AppDataSource.getRepository(HourlyPageViews)
  .createQueryBuilder()
  .where('bucket >= :start', { start })
  .andWhere('bucket <= :end', { end })
  .orderBy('bucket', 'DESC')
  .getMany();
```

## Candlesticks

Use a Hypertable to define a time-series table, then use the `getCandlesticks` method on the repository to query candlestick data:

See:

- https://docs.timescale.com/api/latest/hyperfunctions/financial-analysis/candlestick_agg/

### Defining a Candlestick Entity

```typescript
import { Entity } from 'typeorm';
import { Hypertable } from '@timescaledb/typeorm';

@Entity('stock_prices')
@Hypertable({
  by_range: {
    column_name: 'timestamp',
  },
})
export class StockPrice {
  @PrimaryColumn({ type: 'varchar' })
  tickerSymbol: string;

  @PrimaryColumn({ type: 'timestamp' })
  timestamp: Date;

  @Column({ type: 'decimal', precision: 10, scale: 2 })
  price: number;

  @Column({ type: 'decimal', precision: 10, scale: 2 })
  volume: number;
}
```

### Querying Candlestick Data

Use the appended `getCandlesticks` method on the repository to query candlestick data:

```typescript
const repository = AppDataSource.getRepository(StockPrice);

// Basic candlestick query
const candlesticks = await repository.getCandlesticks({
  timeRange: {
    start: new Date('2025-01-01'),
    end: new Date('2025-01-02'),
  },
  config: {
    time_column: 'timestamp',
    price_column: 'price',
    volume_column: 'volume', // optional
    bucket_interval: '1 hour', // defaults to '1 hour'
  },
});

// With where clause filtering
const filteredCandlesticks = await repository.getCandlesticks({
  timeRange: {
    start: new Date('2025-01-01'),
    end: new Date('2025-01-02'),
  },
  config: {
    time_column: 'timestamp',
    price_column: 'price',
    volume_column: 'volume',
    bucket_interval: '1 hour',
  },
  where: {
    symbol: 'AAPL', // Simple equality
    volume: { '>': 1000000 }, // Minimum volume
    exchange: { IN: ['NYSE', 'NASDAQ'] }, // Multiple exchanges
    sector: { 'NOT IN': ['CRYPTO', 'OTC'] }, // Exclude sectors
  },
});

console.log(candlesticks);
// Output:
// [
//   {
//     bucket_time: "2025-01-01T00:00:00.000Z",
//     open: 185.25,
//     high: 186.64,
//     low: 183.34,
//     close: 184.87,
//     open_time: "2025-01-01T00:02:15.000Z",
//     high_time: "2025-01-01T00:45:12.000Z",
//     low_time: "2025-01-01T00:15:33.000Z",
//     close_time: "2025-01-01T00:59:45.000Z",
//     volume: 2589100,
//     vwap: 184.95
//   },
//   ...
// ]
```

## Migrations

To hook into the TypeORM migration process, import the library at the top of your `data-source` file:

```typescript
import '@timescaledb/typeorm'; // This should be the first import in your file to hook into the TypeORM migration process

import { DataSource } from 'typeorm';
import { PageLoad, HourlyPageViews } from './models';

export const AppDataSource = new DataSource({
  type: 'postgres',
  url: process.env.DATABASE_URL,
  synchronize: false,
  logging: process.env.NODE_ENV === 'development',
  entities: [PageLoad, HourlyPageViews, StockPrice], // <-- Add your entities here
  migrations: ['migrations/*.ts'],
});
```

Then run your normal TypeORM migration commands:

```bash
typeorm-ts-node-commonjs migration:run -d src/data-source.ts
```

The `@timescaledb/typeorm` library will automatically create the necessary hypertables and other TimescaleDB-specific objects in the database.

If you wish to have more control over the migration process, then please reffer to the `@timescaledb/core` library and how its used in this integration.

================
File: packages/typeorm/tsconfig.json
================
{
  "compilerOptions": {
    "target": "ES2020",
    "lib": ["esnext"],
    "allowJs": true,
    "sourceMap": true,
    "declaration": true,
    "skipLibCheck": true,
    "esModuleInterop": true,
    "allowSyntheticDefaultImports": true,
    "strict": true,
    "module": "commonjs",
    "moduleResolution": "node",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "noEmit": false,
    "outDir": "./dist",
    "baseUrl": ".",
    "paths": {
      "@timescaledb/core": ["../core/dist"],
      "@timescaledb/schemas": ["../schemas/dist"]
    }
  },
  "include": ["src"],
  "exclude": ["node_modules", "dist"]
}

================
File: packages/typeorm/tsconfig.test.json
================
{
  "extends": "./tsconfig.json",
  "compilerOptions": {
    "types": ["jest", "node"],
    "module": "commonjs",
    "target": "ES2020",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "moduleResolution": "node",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "noEmit": true,
    "outDir": "./dist-test"
  },
  "include": ["src/**/*.ts", "tests/**/*.ts"],
  "exclude": ["node_modules"]
}

================
File: packages/utils/src/build-where.ts
================
import { escapeIdentifier } from './sql';
import { WhereClause } from '@timescaledb/schemas';

export function buildWhereClause(where: WhereClause, startParamIndex: number = 1): { sql: string; params: any[] } {
  const conditions: string[] = [];
  const params: any[] = [];
  let paramIndex = startParamIndex;

  for (const [column, condition] of Object.entries(where)) {
    const escapedColumn = escapeIdentifier(column);

    if (typeof condition === 'object' && !Array.isArray(condition) && !(condition instanceof Date)) {
      for (const [operator, value] of Object.entries(condition)) {
        if (Array.isArray(value) && (operator === 'IN' || operator === 'NOT IN')) {
          const placeholders = value.map(() => `$${paramIndex++}`).join(', ');
          conditions.push(`${escapedColumn} ${operator} (${placeholders})`);
          params.push(...value);
        } else {
          conditions.push(`${escapedColumn} ${operator} $${paramIndex++}`);
          params.push(value);
        }
      }
    } else {
      conditions.push(`${escapedColumn} = $${paramIndex++}`);
      params.push(condition);
    }
  }

  return {
    sql: conditions.join(' AND '),
    params,
  };
}

================
File: packages/utils/src/bump-versions.ts
================
import fs from 'fs';
import path from 'path';

const version = process.env.VERSION;
const startPath = process.env.START_PATH;
const shouldIgnoreWorkspace = process.env.IGNORE_WORKSPACE;

function updatePackageJsonVersion(filePath: string, version: string) {
  const content = fs.readFileSync(filePath, 'utf-8');
  const json = JSON.parse(content);
  json.version = version;

  const updatedContent = JSON.stringify(
    json,
    function (key, value) {
      if (key === 'version' || (String(value).includes('workspace:^') && !shouldIgnoreWorkspace)) {
        return version;
      }

      return value;
    },
    2,
  );

  fs.writeFileSync(filePath, updatedContent);
}

export function searchAndReplace(rootDir: string, version: string) {
  const entries = fs.readdirSync(rootDir, { withFileTypes: true });

  for (const entry of entries) {
    const fullPath = path.join(rootDir, entry.name);

    if (fullPath.includes('node_modules')) continue;

    if (entry.isDirectory()) {
      searchAndReplace(fullPath, version);
    } else if (entry.isFile() && entry.name === 'package.json') {
      updatePackageJsonVersion(fullPath, version);
    }
  }
}

if (!version) {
  console.error('Please set the VERSION environment variable.');
  process.exit(1);
}

if (!version.includes('alpha')) {
  console.error('Please set the VERSION environment variable to an alpha version.');
  process.exit(1);
}

if (!startPath) {
  console.error('Please set the START_PATH environment variable.');
  process.exit(1);
}

searchAndReplace(startPath, version);

================
File: packages/utils/src/index.ts
================
export * from './sql';
export * from './build-where';

================
File: packages/utils/src/release.ts
================
import { execSync } from 'child_process';

const version = process.env.VERSION;
const startPath = process.env.START_PATH;

function releaseNewVersion() {
  const branch = execSync('git symbolic-ref --short HEAD').toString().trim();
  if (branch !== 'main') {
    console.error('Error: You must be on the main branch to release a new version.');
    process.exit(1);
  }

  execSync('git pull');

  execSync(
    `VERSION=${version} IGNORE_WORKSPACE=true START_PATH=${startPath} node ./packages/utils/dist/bump-versions.js`,
  );

  execSync('pnpm i');
  execSync('pnpm format');
  execSync('git add .');
  execSync(`git commit -m "${version}"`);
  execSync(`git tag ${version}`);
}

if (!version) {
  console.error('Please set the VERSION environment variable.');
  process.exit(1);
}

if (!version.includes('alpha')) {
  console.error('Please set the VERSION environment variable to an alpha version.');
  process.exit(1);
}

if (!startPath) {
  console.error('Please set the START_PATH environment variable.');
  process.exit(1);
}

releaseNewVersion();

================
File: packages/utils/src/sql.ts
================
// The content of this file was extracted from https://github.com/brianc/node-postgres/blob/master/packages/pg/lib/utils.js

const MAX_IDENTIFIER_LENGTH = 63;

export function checkForControlChars(str: string): void {
  // Check for control characters
  // eslint-disable-next-line no-control-regex
  if (/[\x00-\x1F\x7F]/.test(str)) {
    throw new Error('Control characters not allowed in literals');
  }
}

export function validateIdentifier(str: string, isTableName = false): void {
  if (!str) {
    throw new Error('Identifier cannot be empty');
  }

  // PostgreSQL will truncate identifiers longer than 63 bytes
  if (Buffer.from(str).length > MAX_IDENTIFIER_LENGTH) {
    throw new Error(`Identifier is too long (max ${MAX_IDENTIFIER_LENGTH} bytes)`);
  }

  checkForControlChars(str);

  if (isTableName) {
    const tableNameRegex = /^[a-zA-Z][a-zA-Z0-9_]*(?:\.[a-zA-Z][a-zA-Z0-9_]*)?$/;
    if (!tableNameRegex.test(str)) {
      throw new Error('Table names must start with a letter and can only contain letters, numbers, and underscores');
    }
  }
}

export function escapeIdentifier(str: string): string {
  validateIdentifier(str);

  // Normalize Unicode for consistent handling
  str = str.normalize('NFC');

  // Double up any double quotes and wrap in quotes
  return `"${str.replace(/"/g, '""')}"`;
}

export function escapeLiteral(str: string): string {
  if (!str) {
    throw new Error('Literal value cannot be empty');
  }

  checkForControlChars(str);

  // Normalize Unicode for consistent handling
  str = str.normalize('NFC');

  let hasBackslash = false;
  let escaped = "'";

  for (let i = 0; i < str.length; i++) {
    const c = str[i];
    if (c === "'") {
      escaped += c + c; // Double up single quotes
    } else if (c === '\\') {
      escaped += c + c; // Double up backslashes
      hasBackslash = true;
    } else {
      escaped += c;
    }
  }

  escaped += "'";

  // Add E prefix for strings containing backslashes
  if (hasBackslash) {
    escaped = 'E' + escaped;
  }

  return escaped;
}

================
File: packages/utils/tests/sql.test.ts
================
import { describe, it, expect } from '@jest/globals';
import { escapeIdentifier, escapeLiteral } from '../src/sql';

describe('SQL Escaping', () => {
  describe('escapeIdentifier', () => {
    it('handles basic identifiers', () => {
      expect(escapeIdentifier('column_name')).toBe('"column_name"');
    });

    it('escapes double quotes', () => {
      expect(escapeIdentifier('my"column')).toBe('"my""column"');
    });

    it('allows spaces and special characters', () => {
      expect(escapeIdentifier('my column name!')).toBe('"my column name!"');
    });

    it('handles international characters', () => {
      expect(escapeIdentifier('ber_mned')).toBe('"ber_mned"');
    });

    it('normalizes Unicode', () => {
      //  can be represented two ways:
      // 1.  (\u00E5) - single character
      // 2. a\u030A - letter 'a' with combining ring above
      const withCombiningChar = 'a\u030A';
      const normalized = '';
      expect(escapeIdentifier(withCombiningChar)).toBe(`"${normalized}"`);
    });

    it('rejects empty identifiers', () => {
      expect(() => escapeIdentifier('')).toThrow('Identifier cannot be empty');
    });

    it('rejects too long identifiers', () => {
      expect(() => escapeIdentifier('a'.repeat(64))).toThrow('Identifier is too long');
    });
  });

  describe('escapeLiteral', () => {
    it('handles basic strings', () => {
      expect(escapeLiteral('simple')).toBe("'simple'");
    });

    it('escapes single quotes', () => {
      expect(escapeLiteral("O'Reilly")).toBe("'O''Reilly'");
    });

    it('escapes backslashes', () => {
      expect(escapeLiteral('path\\to\\file')).toBe("E'path\\\\to\\\\file'");
    });

    it('handles international characters', () => {
      expect(escapeLiteral('ber')).toBe("'ber'");
    });

    it('normalizes Unicode', () => {
      //  can be represented two ways:
      // 1.  (\u00E5) - single character
      // 2. a\u030A - letter 'a' with combining ring above
      const withCombiningChar = 'a\u030A';
      const normalized = '';
      expect(escapeLiteral(withCombiningChar)).toBe(`'${normalized}'`);
    });

    it('rejects control characters', () => {
      expect(() => escapeLiteral('bad\x00value')).toThrow('Control characters not allowed');
      expect(() => escapeLiteral('bad\x1Fvalue')).toThrow('Control characters not allowed');
      expect(() => escapeLiteral('bad\x7Fvalue')).toThrow('Control characters not allowed');
    });

    it('rejects empty literals', () => {
      expect(() => escapeLiteral('')).toThrow('Literal value cannot be empty');
    });
  });
});

================
File: packages/utils/babel.config.js
================
module.exports = {
  presets: [['@babel/preset-env', { targets: { node: 'current' } }], '@babel/preset-typescript'],
};

================
File: packages/utils/jest.config.js
================
/** @type {import('jest').Config} */
module.exports = {
  preset: 'ts-jest',
  testEnvironment: 'node',
  roots: ['<rootDir>/tests'],
  transform: {
    '^.+\\.tsx?$': [
      'ts-jest',
      {
        tsconfig: 'tsconfig.test.json',
      },
    ],
  },
  moduleFileExtensions: ['ts', 'tsx', 'js', 'jsx', 'json', 'node'],
  testMatch: ['**/tests/**/*.test.ts', '**/tests/**/*-tests.ts'],
  verbose: true,
  testTimeout: 10000,
  clearMocks: true,
  restoreMocks: true,
};

================
File: packages/utils/package.json
================
{
  "name": "@timescaledb/utils",
  "version": "0.0.0-alpha.1",
  "main": "dist/index.js",
  "types": "dist/index.d.ts",
  "homepage": "https://github.com/timescale/timescaledb-ts",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/timescale/timescaledb-ts.git"
  },
  "keywords": [
    "timescaledb",
    "timeseries",
    "database",
    "typescript",
    "utils"
  ],
  "author": "Timescale",
  "license": "MIT",
  "bugs": {
    "url": "https://github.com/timescale/timescaledb-ts/issues"
  },
  "typesVersions": {
    "*": {
      "*": [
        "src/*"
      ]
    }
  },
  "files": [
    "dist"
  ],
  "scripts": {
    "build": "tsc",
    "test": "jest --runInBand"
  },
  "dependencies": {
    "@timescaledb/schemas": "workspace:^"
  }
}

================
File: packages/utils/README.md
================
# @timescaledb/utils

This package contains utilities like formatting and escaping sql strings plus other helper functions.

================
File: packages/utils/tsconfig.json
================
{
  "compilerOptions": {
    "target": "ES2020",
    "lib": ["esnext"],
    "allowJs": true,
    "sourceMap": true,
    "declaration": true,
    "skipLibCheck": true,
    "esModuleInterop": true,
    "allowSyntheticDefaultImports": true,
    "strict": true,
    "module": "commonjs",
    "moduleResolution": "node",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "noEmit": false,
    "outDir": "./dist",
    "paths": {
      "@timescaledb/schemas": ["../schemas/dist"]
    }
  },
  "include": ["src"]
}

================
File: packages/utils/tsconfig.test.json
================
{
  "extends": "./tsconfig.json",
  "compilerOptions": {
    "types": ["jest", "node"],
    "module": "commonjs",
    "target": "ES2020",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "moduleResolution": "node",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "noEmit": true,
    "outDir": "./dist-test"
  },
  "include": ["src/**/*.ts", "tests/**/*.ts"],
  "exclude": ["node_modules"]
}

================
File: .eslintrc.js
================
module.exports = {
  root: true,
  env: {
    node: true,
    'jest/globals': true,
  },
  extends: ['eslint:recommended', 'plugin:@typescript-eslint/recommended', 'prettier'],
  plugins: ['@typescript-eslint', 'jest'],
  parserOptions: {
    ecmaVersion: 2021,
    sourceType: 'module',
  },
  rules: {
    'linebreak-style': ['error', 'unix'],
    '@typescript-eslint/no-explicit-any': 'off',
    '@typescript-eslint/no-require-imports': 'off',
    '@typescript-eslint/ban-ts-comment': 'off',
    '@typescript-eslint/no-unsafe-function-type': 'off',
  },
  ignorePatterns: ['dist'],
};

================
File: .gitignore
================
.DS_Store
npm-debug.log*
package-lock.json
.npmrc
node_modules/
dist/
.env

================
File: .prettierignore
================
dist/
pnpm-lock.yaml

================
File: .prettierrc
================
{
  "endOfLine": "lf",
  "insertPragma": false,
  "requirePragma": false,
  "trailingComma": "all",
  "tabWidth": 2,
  "useTabs": false,
  "singleQuote": true,
  "printWidth": 120
}

================
File: LICENSE
================
MIT License

Copyright (c) 2025 Timescale

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

================
File: package.json
================
{
  "name": "@timescaledb/monorepo",
  "version": "0.0.0-alpha.1",
  "packageManager": "pnpm@9.15.3",
  "scripts": {
    "lint": "eslint .",
    "build": "pnpm -r run build",
    "test": "pnpm -r run test",
    "clean": "find . -type d \\( -name \"node_modules\" -o -name \"build\" -o -name \"dist\" \\) -exec rm -rf {} + && rm ./pnpm-lock.yaml",
    "format": "prettier . --write --ignore-path .prettierignore",
    "format:check": "prettier . --check --ignore-path .prettierignore",
    "release": "node ./packages/utils/dist/release.js"
  },
  "devDependencies": {
    "@babel/cli": "7.24.8",
    "@babel/core": "7.25.2",
    "@babel/preset-env": "7.25.4",
    "@babel/preset-typescript": "7.24.7",
    "@babel/runtime": "7.25.6",
    "@jest/globals": "29.7.0",
    "@types/express": "5.0.0",
    "@types/jest": "29.5.12",
    "@types/node": "22.4.1",
    "@types/supertest": "6.0.2",
    "@typescript-eslint/eslint-plugin": "8.10.0",
    "@typescript-eslint/parser": "8.10.0",
    "babel-loader": "9.1.3",
    "cross-env": "7.0.3",
    "dotenv": "16.4.5",
    "eslint": "8.57.0",
    "eslint-config-prettier": "9.1.0",
    "eslint-config-standard-with-typescript": "43.0.1",
    "eslint-plugin-import": "2.29.1",
    "eslint-plugin-jest": "28.8.3",
    "eslint-plugin-n": "17.10.2",
    "eslint-plugin-prettier": "5.2.1",
    "eslint-plugin-promise": "7.1.0",
    "jest": "29.7.0",
    "prettier": "3.3.3",
    "supertest": "7.0.0",
    "ts-jest": "29.2.4",
    "ts-loader": "9.5.1",
    "ts-node": "10.9.2",
    "tsx": "4.19.2",
    "typescript": "5.5.4"
  },
  "pnpm": {
    "peerDependencyRules": {
      "ignoreMissing": [
        "@babel/*",
        "typescript",
        "ts-node",
        "@tsconfig/*",
        "@types/*",
        "jest",
        "@jest/*",
        "prettier"
      ]
    }
  },
  "engines": {
    "node": ">=22",
    "pnpm": ">=9"
  },
  "dependencies": {}
}

================
File: pnpm-workspace.yaml
================
packages:
  - 'packages/*'
  - 'examples/*'

================
File: README.md
================
# timescaledb-ts

[![npm version](https://badge.fury.io/js/@timescaledb%2Ftypeorm.svg)](https://badge.fury.io/js/@timescaledb%2Ftypeorm) [![Tests](https://github.com/timescale/timescaledb-ts/actions/workflows/test.yml/badge.svg?branch=main)](https://github.com/timescale/timescaledb-ts/actions/workflows/test.yml) [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Welcome to the [Timescale](https://www.timescale.com/) Typescript library. This library is a collection of packages that help you work with TimescaleDB in a Typescript environment.

If you are looking to setup this project locally, you can follow the instructions in the [CONTRIBUTING.md](./docs/CONTRIBUTING.md) file.

## Packages

- [@timescaledb/typeorm](./packages/typeorm/README.md) - Official TimescaleDB integration for TypeORM.
- [@timescaledb/core](./packages/core/README.md) - Migration and query helpers
- [@timescaledb/schemas](./packages/schemas/README.md) - TimescaleDB object schemas
- [@timescaledb/utils](./packages/utils/README.md) - utilities and helpers

## Examples

- [Node Sequelize Example](./examples/node-sequelize/README.md) - Using TimescaleDB with Node.js and [Sequelize](https://sequelize.org/)
- [Node TypeORM Example](./examples/node-typeorm/README.md) - Using TimescaleDB with Node.js and [TypeORM](https://typeorm.io/)

## Feature Compatibility

| Feature                                                                                                                              | Core | TypeORM | Sequelize            |
| ------------------------------------------------------------------------------------------------------------------------------------ | ---- | ------- | -------------------- |
| **Core Functions**                                                                                                                   |      |         |                      |
| [Create Hypertable](https://docs.timescale.com/api/latest/hypertable/create_hypertable/)                                             |    |  Auto |  Manual (via Core) |
| [Add Compression](https://docs.timescale.com/api/latest/compression/alter_table_compression/)                                        |    |  Auto |  Manual (via Core) |
| [Add Compression Policy](https://docs.timescale.com/api/latest/compression/add_compression_policy/)                                  |    |  Auto |  Manual (via Core) |
| [Add Retention Policy](https://docs.timescale.com/use-timescale/latest/data-retention/create-a-retention-policy/)                    |    |       |                    |
| [Continuous Aggregates](https://docs.timescale.com/api/latest/continuous-aggregates/create_materialized_view/)                       |    |  Auto |  Manual (via Core) |
| **Hyperfunctions**                                                                                                                   |      |         |                      |
| [Time Bucket](https://docs.timescale.com/api/latest/hyperfunctions/time_bucket/)                                                     |    |       |  Manual (via Core) |
| [Candlestick Aggregates](https://docs.timescale.com/api/latest/hyperfunctions/financial-analysis/candlestick_agg/)                   |    |       |  Manual (via Core) |
| [Stats Aggregates](https://docs.timescale.com/api/latest/hyperfunctions/statistical-and-regression-analysis/stats_agg-one-variable/) |    |       |                    |
| [Percentile Approximation](https://docs.timescale.com/api/latest/hyperfunctions/percentile-approximation/uddsketch/)                 |    |       |                    |
| **Info Views**                                                                                                                       |      |         |                      |
| [Chunks](https://docs.timescale.com/api/latest/hypertable/show_chunks/)                                                              |    |       |                    |
| [User Defined Actions](https://docs.timescale.com/api/latest/actions/)                                                               |    |       |                    |
| [Compression Settings](https://docs.timescale.com/api/latest/compression/)                                                           |    |       |  Manual (via Core) |
| [Continuous Aggregates](https://docs.timescale.com/api/latest/continuous-aggregates/create_materialized_view/)                       |    |       |  Manual (via Core) |

Legend:

-  Supported
-  Not Supported at this time
- Auto = Automatic integration with ORM
- Manual = Manual integration using Core package

## Getting Started

- TypeORM: [README](./packages/typeorm/README.md)

To get started with TypeORM simply install the package:

```bash
npm install typeorm @timescaledb/typeorm
```

Then you can use the `@Hypertable` decorator to define your hypertables:

```diff
import { Entity, PrimaryColumn } from 'typeorm';
+ import { Hypertable } from '@timescaledb/typeorm';

+ @Hypertable({ ... })
@Entity('page_loads')
export class PageLoad {
  @PrimaryColumn({ type: 'varchar' })
  user_agent!: string;

  @PrimaryColumn({ type: 'timestamp' })
  time!: Date;
}
```

Then you can query a Hypertable using the attached methods:

```typescript
import { AppDataSource } from './data-source';
import { PageLoad } from './models/PageLoad';

const repository = AppDataSource.getRepository(PageLoad);
const stats = await repository.getTimeBucket({
  timeRange: {
    start: new Date('2025-01-01'),
    end: new Date('2025-01-02'),
  },
  where: {
    user_agent: 'Chrome',
  },
  bucket: {
    interval: '1 hour',
    metrics: [{ type: 'distinct_count', column: 'user_agent', alias: 'unique_users' }],
  },
});

console.log(stats);
// [
//   { time: '2021-01-01T00:00:00.000Z', unique_users: 5 },
//   { time: '2021-01-01T01:00:00.000Z', unique_users: 10 },
//   { time: '2021-01-01T02:00:00.000Z', unique_users: 15 },
//   ...
// ]
```

## License

The library is available as open source under the terms of the MIT License.

## Code of Conduct

Everyone interacting in the Timescale project's codebases, issue trackers, chat rooms and mailing lists is expected to follow the [code of conduct](./docs/CODE_OF_CONDUCT.md).
